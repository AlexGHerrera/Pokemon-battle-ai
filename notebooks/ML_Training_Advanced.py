# %% [markdown]
# # ğŸ¤– Pokemon Battle AI - La BÃºsqueda del Modelo Definitivo
# 
# En el mundo de las batallas Pokemon, cada decisiÃ³n cuenta. Cada movimiento, cada cambio, cada estrategia puede determinar la diferencia entre la victoria y la derrota. Nuestro viaje hasta ahora nos ha llevado desde el anÃ¡lisis exploratorio hasta un baseline sÃ³lido con **ROC-AUC de 0.837**.
# 
# Pero sabemos que podemos hacer mejor. Mucho mejor.
# 
# ## ğŸ¯ La MisiÃ³n: Superar lo Imposible
# 
# Hoy emprendemos la fase mÃ¡s emocionante de nuestro proyecto: **crear el modelo de Machine Learning mÃ¡s avanzado** para predecir batallas Pokemon. No nos conformamos con modelos simples; vamos a desplegar un arsenal completo de algoritmos de Ãºltima generaciÃ³n.
# 
# ### ğŸ—ºï¸ Nuestro Plan de Batalla
# 
# Como entrenadores Pokemon experimentados, sabemos que la preparaciÃ³n es clave. Nuestro plan de entrenamiento seguirÃ¡ una estrategia meticulosa:
# 
# **ğŸ”§ Fase 1: PreparaciÃ³n del Campo de Batalla**
# - Refinamiento de caracterÃ­sticas basado en insights del EDA
# - IngenierÃ­a de features que capturen la esencia de cada batalla
# - SelecciÃ³n inteligente de variables predictivas
# 
# **âš”ï¸ Fase 2: Despliegue del Arsenal Base**
# - Logistic Regression: La elegancia de la simplicidad
# - Random Forest: El poder de la sabidurÃ­a colectiva
# - SVM: La precisiÃ³n matemÃ¡tica en acciÃ³n
# 
# **ğŸš€ Fase 3: Armas de DestrucciÃ³n Masiva**
# - XGBoost: El campeÃ³n de Kaggle
# - LightGBM: Velocidad y precisiÃ³n combinadas
# - Neural Networks: La inteligencia artificial pura
# 
# **âš™ï¸ Fase 4: Perfeccionamiento TÃ¡ctico**
# - Hyperparameter tuning con bÃºsqueda inteligente
# - Cross-validation para robustez mÃ¡xima
# - AnÃ¡lisis profundo de curvas de aprendizaje
# 
# **ğŸ¤ Fase 5: La UniÃ³n Hace la Fuerza**
# - Ensemble de los mejores modelos
# - Voting strategies para decisiones consensuadas
# - Meta-learning para superar lÃ­mites individuales
# 
# **ğŸ† Fase 6: El Momento de la Verdad**
# - EvaluaciÃ³n exhaustiva contra el baseline
# - AnÃ¡lisis de errores y casos lÃ­mite
# - SelecciÃ³n del modelo campeÃ³n
# 
# Â¿Lograremos superar el **ROC-AUC de 0.837**? Â¿CuÃ¡nto podremos mejorar? El viaje comienza ahoraâ€¦

# %% [markdown]
# ## ğŸ“¦ Armando Nuestro Arsenal: Las Herramientas del Maestro
# 
# Como cualquier entrenador Pokemon sabe, tener las herramientas adecuadas es fundamental para el Ã©xito. En nuestro laboratorio de Machine Learning, cada librerÃ­a es como un Pokemon especializado, cada una con sus propias habilidades Ãºnicas.
# 
# Vamos a importar nuestro equipo completo:
# - **Pandas & NumPy**: Nuestros Pikachu y Charizard, confiables y poderosos para manipulaciÃ³n de datos
# - **Scikit-learn**: El Mew de ML, versÃ¡til y con acceso a casi cualquier algoritmo
# - **XGBoost & LightGBM**: Los legendarios Rayquaza y Kyogre del gradient boosting
# - **Matplotlib & Seaborn**: Nuestros artistas Smeargle, creando visualizaciones que cuentan historias
# 
# Cada importaciÃ³n nos acerca mÃ¡s a nuestro objetivo: crear el modelo mÃ¡s poderoso jamÃ¡s visto en batallas Pokemon.

# %%
# LibrerÃ­as bÃ¡sicas
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Machine Learning
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import (
    train_test_split, cross_val_score, GridSearchCV, 
    StratifiedKFold, RandomizedSearchCV
)
from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder
from sklearn.metrics import (
    roc_auc_score, accuracy_score, precision_score, recall_score, 
    f1_score, classification_report, confusion_matrix, roc_curve, auc
)
from sklearn.feature_selection import SelectKBest, f_classif, RFE, SelectFromModel

# Modelos avanzados
import xgboost as xgb
import lightgbm as lgb

# Utilidades
import json
import pickle
from pathlib import Path
from datetime import datetime
import logging

# ConfiguraciÃ³n de visualizaciÃ³n
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")

# Colores Pokemon
POKEMON_COLORS = {
    'fire': '#FF6B35',
    'water': '#4A90E2', 
    'grass': '#7ED321',
    'electric': '#F5A623',
    'psychic': '#BD10E0',
    'ice': '#50E3C2',
    'dragon': '#9013FE',
    'dark': '#4A4A4A',
    'fighting': '#D0021B',
    'poison': '#B8E986'
}

# Detectar entorno de ejecuciÃ³n
import os
IS_KAGGLE = 'KAGGLE_KERNEL_RUN_TYPE' in os.environ
WORKING_DIR = "/kaggle/working" if IS_KAGGLE else "."

print("âœ… LibrerÃ­as importadas correctamente")
print(f"ğŸŒ Entorno detectado: {'Kaggle' if IS_KAGGLE else 'Local'}")
print(f"ğŸ“ Directorio de trabajo: {WORKING_DIR}")

# %% [markdown]
# ## ğŸ“Š El Despertar de los Datos: Liberando el Arsenal Completo
# 
# Cada dataset cuenta una historia, y el nuestro es **absolutamente Ã©pico**. Hemos pasado del entrenamiento con una muestra a desatar **TODO EL PODER** de nuestro arsenal de datos completo. Ya no son solo 2000 batallas - ahora tenemos acceso a **TODAS las batallas Pokemon disponibles**.
# 
# Imagina por un momento: **Miles y miles de enfrentamientos Ãºnicos**, decenas de miles de decisiones crÃ­ticas, cientos de Pokemon diferentes luchando por la gloria en una escala nunca antes vista. Desde batallas rÃ¡pidas y decisivas hasta maratones Ã©picos, tenemos la biblioteca completa de la experiencia competitiva Pokemon.
# 
# ### ğŸ­ Los Protagonistas de Nuestra Historia
# 
# Nuestros datos no son simples nÃºmeros; son las memorias digitales de entrenadores que:
# - Tomaron decisiones bajo presiÃ³n
# - Ejecutaron estrategias complejas
# - Experimentaron la emociÃ³n de la victoria y la amargura de la derrota
# 
# Cada log de batalla es como un pergamino antiguo que debemos descifrar. Cada evento registrado - cada movimiento, cada cambio, cada momento crÃ­tico - contiene pistas sobre quÃ© hace que un entrenador triunfe sobre otro.
# 
# **Â¿QuÃ© secretos revelarÃ¡n estos datos a escala masiva?** Con este arsenal completo de batallas, nuestros modelos tendrÃ¡n acceso a patrones que solo emergen con grandes volÃºmenes de datos. Â¿Descubriremos estrategias meta que solo son visibles con miles de batallas? Â¿Encontraremos correlaciones sutiles que se perdÃ­an en muestras mÃ¡s pequeÃ±as?
# 
# **Â¡La aventura de entrenar con el dataset completo comienza ahora!** ğŸš€

# %%
# Cargar datos con estructura correcta (soluciÃ³n al problema de ganadores)
try:
    # Usar dataset pÃºblico de Kaggle: pokemon-showdown-battles-gen9-randbats (~14,000 batallas)
    import glob
    
    # Usar dataset pÃºblico de Kaggle con estructura correcta (archivos en raÃ­z)
    possible_patterns = [
        "/kaggle/input/pokemon-showdown-battles-gen9-randbats/*.json",        # Dataset pÃºblico (raÃ­z) - CORRECTO
        "../data/battles/*.json",                                             # Archivos locales para desarrollo
        "/kaggle/input/*/parsed/*.json",                                      # Por si hay subcarpeta parsed/
        "/kaggle/input/*/*.json",                                             # Fallback general
    ]
    
    battle_files = []
    for pattern in possible_patterns:
        battle_files = glob.glob(pattern)
        if battle_files:
            print(f"âœ… Encontrados archivos con patrÃ³n: {pattern}")
            break
    
    battles_data = []
    print(f"ğŸ” Encontrados {len(battle_files)} archivos de batalla")
    
    for i, file_path in enumerate(battle_files):
        try:
            with open(file_path, 'r') as f:
                battle = json.load(f)
                battles_data.append(battle)
            
            # Mostrar progreso cada 1000 archivos
            if (i + 1) % 1000 == 0:
                print(f"ğŸ“Š Procesados {i + 1}/{len(battle_files)} archivos...")
                
        except Exception as e:
            print(f"âš ï¸ Error procesando {file_path}: {e}")
            continue
    
    print(f"âœ… Datos cargados desde archivos individuales: {len(battles_data)} batallas")
    
except Exception as e:
    print(f"âš ï¸ Error cargando desde Kaggle: {e}")
    # Fallback local para desarrollo
    import glob
    battle_files = glob.glob("../data/battles/*.json")
    
    battles_data = []
    print(f"ğŸ” Encontrados {len(battle_files)} archivos locales")
    
    for i, file_path in enumerate(battle_files):
        try:
            with open(file_path, 'r') as f:
                battle = json.load(f)
                battles_data.append(battle)
                
            # Mostrar progreso cada 1000 archivos
            if (i + 1) % 1000 == 0:
                print(f"ğŸ“Š Procesados {i + 1}/{len(battle_files)} archivos...")
                
        except Exception as e:
            print(f"âš ï¸ Error procesando {file_path}: {e}")
            continue
    
    print(f"âœ… Dataset local cargado: {len(battles_data)} batallas")
    print(f"ğŸš€ Â¡Usando archivos individuales con diversidad de ganadores garantizada!")

# %% [markdown]
# ### ğŸ”§ La Alquimia de los Datos: Transformando Batallas en SabidurÃ­a
# 
# Ahora viene la parte mÃ¡s artÃ­stica de nuestro proceso: la **ingenierÃ­a de caracterÃ­sticas**. Como un alquimista medieval transformando metales comunes en oro, vamos a convertir logs de batalla crudos en features predictivas poderosas.
# 
# ### ğŸ§¬ Decodificando el ADN de una Batalla
# 
# Cada batalla Pokemon tiene su propio "ADN" - una secuencia Ãºnica de eventos que la define. Nuestro trabajo es extraer la esencia de este ADN y convertirla en nÃºmeros que nuestros algoritmos puedan entender.
# 
# **Â¿QuÃ© hace que una batalla sea Ãºnica?**
# - **Intensidad**: Â¿Fue una batalla rÃ¡pida y brutal o un duelo prolongado de resistencia?
# - **Complejidad**: Â¿CuÃ¡ntos cambios estratÃ©gicos hubo? Â¿QuÃ© tan dinÃ¡mica fue?
# - **Agresividad**: Â¿Los entrenadores fueron directos o cautelosos?
# - **Adaptabilidad**: Â¿QuÃ© tan bien respondieron a las situaciones cambiantes?
# 
# ### ğŸ¯ Las MÃ©tricas que Importan
# 
# BasÃ¡ndonos en nuestro anÃ¡lisis exploratorio previo, sabemos que ciertas mÃ©tricas son cruciales:
# - **Eventos de movimiento**: El corazÃ³n de cada batalla
# - **Ratios de daÃ±o**: La eficiencia ofensiva
# - **Patrones de cambio**: La flexibilidad tÃ¡ctica
# - **DuraciÃ³n e intensidad**: El ritmo de la batalla
# 
# Cada feature que extraemos es como capturar la esencia de miles de decisiones estratÃ©gicas. Â¿Lograremos capturar los patrones que separan a los maestros de los novatos?

# %%
def extract_battle_features(battles_data):
    """
    Extrae caracterÃ­sticas numÃ©ricas de las batallas para ML.
    Basado en los hallazgos del EDA previo y estructura real de datos.
    """
    features_list = []
    
    def get_in(data, keys, default=None):
        """FunciÃ³n auxiliar para acceso seguro a datos anidados."""
        for key in keys:
            if isinstance(data, dict) and key in data:
                data = data[key]
            else:
                return default
        return data
    
    def calculate_battle_metrics(battle: dict) -> dict:
        """Calcula mÃ©tricas clave de una batalla (copiado del EDA)."""
        metadata = battle.get('metadata', {})
        turns = battle.get('turns', [])
        
        # MÃ©tricas bÃ¡sicas
        total_turns = len(turns)
        winner = get_in(metadata, ['outcome', 'winner'])
        reason = get_in(metadata, ['outcome', 'reason'])
        
        # AnÃ¡lisis detallado de eventos
        total_events = 0
        move_events = 0
        switch_events = 0
        damage_events = 0
        effect_events = 0
        heal_events = 0
        status_events = 0
        
        # MÃ©tricas de momentum y timing
        early_game_events = 0  # Primeros 3 turnos
        mid_game_events = 0    # Turnos 4-8
        late_game_events = 0   # Turnos 9+
        
        # Patrones de decisiÃ³n
        consecutive_moves = 0
        consecutive_switches = 0
        last_action_type = None
        current_streak = 0
        
        for turn_idx, turn in enumerate(turns):
            turn_events = turn.get('events', [])
            turn_event_count = len(turn_events)
            total_events += turn_event_count
            
            # Clasificar eventos por fase del juego
            if turn_idx < 3:
                early_game_events += turn_event_count
            elif turn_idx < 8:
                mid_game_events += turn_event_count
            else:
                late_game_events += turn_event_count
            
            # Analizar tipos de eventos
            for event in turn_events:
                event_type = event.get('type', '').lower()
                
                if event_type == 'move':
                    move_events += 1
                elif event_type == 'switch':
                    switch_events += 1
                elif 'damage' in event_type:
                    damage_events += 1
                elif 'heal' in event_type:
                    heal_events += 1
                elif 'faint' in event_type:
                    status_events += 1
                else:
                    effect_events += 1
                
                # Rastrear patrones consecutivos
                if event_type in ['move', 'switch']:
                    if event_type == last_action_type:
                        current_streak += 1
                    else:
                        if last_action_type == 'move':
                            consecutive_moves = max(consecutive_moves, current_streak)
                        elif last_action_type == 'switch':
                            consecutive_switches = max(consecutive_switches, current_streak)
                        current_streak = 1
                        last_action_type = event_type
        
        # Finalizar rastreo de patrones
        if last_action_type == 'move':
            consecutive_moves = max(consecutive_moves, current_streak)
        elif last_action_type == 'switch':
            consecutive_switches = max(consecutive_switches, current_streak)
        
        return {
            'total_turns': total_turns,
            'winner': winner,
            'reason': reason,
            'total_events': total_events,
            'move_events': move_events,
            'switch_events': switch_events,
            'damage_events': damage_events,
            'heal_events': heal_events,
            'status_events': status_events,
            'effect_events': effect_events,
            'events_per_turn': total_events / max(total_turns, 1),
            'early_game_intensity': early_game_events / max(min(total_turns, 3), 1),
            'mid_game_intensity': mid_game_events / max(min(total_turns - 3, 5), 1) if total_turns > 3 else 0,
            'late_game_intensity': late_game_events / max(total_turns - 8, 1) if total_turns > 8 else 0,
            'move_switch_ratio': move_events / max(switch_events, 1),
            'consecutive_moves': consecutive_moves,
            'consecutive_switches': consecutive_switches,
            'action_diversity': len(set([e.get('type') for turn in turns for e in turn.get('events', [])]))
        }
    
    def extract_team_composition_features(battle: dict) -> dict:
        """Extrae features de composiciÃ³n de equipos (copiado del EDA)."""
        teams = get_in(battle, ["team_revelation", "teams"], {})
        features = {}
        
        for player_id in ['p1', 'p2']:
            team = teams.get(player_id, [])
            if isinstance(team, list) and team:
                # MÃ©tricas bÃ¡sicas del equipo
                levels = [p.get('level', 0) for p in team if p.get('level')]
                hps = [get_in(p, ['base_stats', 'hp']) for p in team if get_in(p, ['base_stats', 'hp'])]
                
                # EstadÃ­sticas de nivel
                avg_level = np.mean(levels) if levels else 0
                level_std = np.std(levels) if len(levels) > 1 else 0
                
                # EstadÃ­sticas de HP
                avg_hp = np.mean(hps) if hps else 0
                hp_std = np.std(hps) if len(hps) > 1 else 0
                total_hp = sum(hps) if hps else 0
                
                # Diversidad y revelaciÃ³n
                species_count = len(set(p.get('species') for p in team if p.get('species')))
                fully_revealed = sum(1 for p in team if p.get('revelation_status') == 'fully_revealed')
                partially_revealed = sum(1 for p in team if p.get('revelation_status') == 'partially_revealed')
                
                # InformaciÃ³n conocida
                known_abilities = sum(1 for p in team if p.get('known_ability'))
                known_items = sum(1 for p in team if p.get('known_item'))
                total_known_moves = sum(len(p.get('known_moves', [])) for p in team)
                
                features.update({
                    f'{player_id}_team_size': len(team),
                    f'{player_id}_avg_level': avg_level,
                    f'{player_id}_level_std': level_std,
                    f'{player_id}_min_level': min(levels) if levels else 0,
                    f'{player_id}_max_level': max(levels) if levels else 0,
                    f'{player_id}_avg_hp': avg_hp,
                    f'{player_id}_hp_std': hp_std,
                    f'{player_id}_total_hp': total_hp,
                    f'{player_id}_species_diversity': species_count,
                    f'{player_id}_fully_revealed': fully_revealed,
                    f'{player_id}_partially_revealed': partially_revealed,
                    f'{player_id}_known_abilities': known_abilities,
                    f'{player_id}_known_items': known_items,
                    f'{player_id}_total_known_moves': total_known_moves,
                    f'{player_id}_info_advantage': fully_revealed + partially_revealed * 0.5
                })
            else:
                # Valores por defecto si no hay datos del equipo
                for metric in ['team_size', 'avg_level', 'level_std', 'min_level', 'max_level', 
                              'avg_hp', 'hp_std', 'total_hp', 'species_diversity', 
                              'fully_revealed', 'partially_revealed', 'known_abilities', 
                              'known_items', 'total_known_moves', 'info_advantage']:
                    features[f'{player_id}_{metric}'] = 0
        
        return features
    
    # Procesar cada batalla
    for i, battle in enumerate(battles_data):
        try:
            # MÃ©tricas bÃ¡sicas mejoradas
            metrics = calculate_battle_metrics(battle)
            
            # Features de composiciÃ³n de equipos
            team_features = extract_team_composition_features(battle)
            
            # Combinar todas las features
            features = {
                'battle_id': battle.get('battle_id'),
                'format': battle.get('format_id', ''),
                'turns': metrics['total_turns'],
                'winner': metrics['winner'],
                'reason': metrics['reason'],
                'total_events': metrics['total_events'],
                'move_events': metrics['move_events'],
                'switch_events': metrics['switch_events'],
                'damage_events': metrics['damage_events'],
                'heal_events': metrics['heal_events'],
                'status_events': metrics['status_events'],
                'effect_events': metrics['effect_events'],
                'events_per_turn': metrics['events_per_turn'],
                'early_game_intensity': metrics['early_game_intensity'],
                'mid_game_intensity': metrics['mid_game_intensity'],
                'late_game_intensity': metrics['late_game_intensity'],
                'move_switch_ratio': metrics['move_switch_ratio'],
                'consecutive_moves': metrics['consecutive_moves'],
                'consecutive_switches': metrics['consecutive_switches'],
                'action_diversity': metrics['action_diversity']
            }
            
            # InformaciÃ³n de jugadores
            players = battle.get('players', {})
            for player_id in ['p1', 'p2']:
                player_info = players.get(player_id, {})
                features[f'{player_id}_rating'] = player_info.get('ladder_rating_pre', 0)
            
            # Agregar features de composiciÃ³n de equipos
            features.update(team_features)
            
            # Features de ventaja competitiva
            if features['p1_rating'] and features['p2_rating']:
                features['rating_difference'] = abs(features['p1_rating'] - features['p2_rating'])
                features['rating_advantage_p1'] = features['p1_rating'] - features['p2_rating']
            else:
                features['rating_difference'] = 0
                features['rating_advantage_p1'] = 0
            
            # Features de balance de equipos
            features['team_size_difference'] = abs(features['p1_team_size'] - features['p2_team_size'])
            features['level_advantage_p1'] = features['p1_avg_level'] - features['p2_avg_level']
            features['hp_advantage_p1'] = features['p1_total_hp'] - features['p2_total_hp']
            features['info_advantage_p1'] = features['p1_info_advantage'] - features['p2_info_advantage']
            
            # Ratios importantes (corregidos)
            if features['total_events'] > 0:
                features['switch_ratio'] = features['switch_events'] / features['total_events']
                features['move_ratio'] = features['move_events'] / features['total_events']
                features['damage_ratio'] = features['damage_events'] / features['total_events']
            else:
                features['switch_ratio'] = 0
                features['move_ratio'] = 0
                features['damage_ratio'] = 0
            
            # MÃ©tricas de intensidad
            features['battle_intensity'] = (features['damage_events'] + features['status_events']) / max(features['turns'], 1)
            
            features_list.append(features)
            
        except Exception as e:
            print(f"Error procesando batalla {battle.get('battle_id', 'unknown')}: {e}")
            continue
    
    return pd.DataFrame(features_list)

# Extraer caracterÃ­sticas
print("ğŸ”§ Extrayendo caracterÃ­sticas de las batallas...")
df_features = extract_battle_features(battles_data)

# Codificar variables categÃ³ricas
label_encoders = {}
categorical_cols = ['format', 'winner']

for col in categorical_cols:
    if col in df_features.columns:
        le = LabelEncoder()
        df_features[f'{col}_encoded'] = le.fit_transform(df_features[col].astype(str))
        label_encoders[col] = le

print(f"âœ… CaracterÃ­sticas extraÃ­das: {df_features.shape}")
print(f"ğŸ“Š Columnas: {list(df_features.columns)}")

# %% [markdown]
# ### ğŸ“ˆ El Primer Vistazo: Â¿QuÃ© Nos Susurran los Datos?
# 
# Antes de lanzarnos a entrenar modelos complejos, necesitamos escuchar lo que nuestros datos tienen que decirnos. Como un entrenador Pokemon experimentado que observa el campo antes de la batalla, vamos a hacer un reconocimiento rÃ¡pido pero crucial.
# 
# ### ğŸ² El Equilibrio del Universo Pokemon
# 
# Una pregunta fundamental: **Â¿Nuestros datos estÃ¡n balanceados?** En el mundo real de las batallas Pokemon, Â¿hay un sesgo hacia algÃºn tipo de ganador? Â¿O vivimos en un universo perfectamente equilibrado donde la habilidad es el Ãºnico factor determinante?
# 
# ### ğŸ” Los Primeros Indicios del Ã‰xito
# 
# TambiÃ©n vamos a echar un vistazo a las correlaciones iniciales. Â¿QuÃ© caracterÃ­sticas muestran las primeras seÃ±ales de ser predictivas? Es como observar las primeras cartas en una partida de poker - no nos dice todo, pero nos da pistas valiosas sobre quÃ© esperar.
# 
# **Â¿QuÃ© patrones emergerÃ¡n?** Â¿ConfirmarÃ¡n nuestras hipÃ³tesis del EDA o nos sorprenderÃ¡n con revelaciones inesperadas? Los nÃºmeros estÃ¡n a punto de hablarâ€¦

# %%
# Verificar distribuciÃ³n del target
if 'winner_encoded' in df_features.columns:
    # Debug: Verificar valores Ãºnicos del winner original
    print("Valores Ãºnicos de 'winner':", df_features['winner'].unique())
    print("Conteo de valores de 'winner':")
    print(df_features['winner'].value_counts())
    
    # Verificar si hay al menos 2 clases diferentes
    unique_winners = df_features['winner'].nunique()
    if unique_winners < 2:
        print(f"âš ï¸  ADVERTENCIA: Solo hay {unique_winners} clase(s) Ãºnica(s) en 'winner'")
        print("Esto causarÃ¡ errores en el entrenamiento de ML")
        print("Verificando datos de batalla...")
        
        # Mostrar algunas batallas de ejemplo para debug
        print("\nEjemplos de datos de batalla:")
        for i, battle in enumerate(battles_data[:5]):
            print(f"Batalla {i+1}: winner = {battle.get('winner', 'N/A')}")
    
    winner_dist = df_features['winner_encoded'].value_counts()
    print("DistribuciÃ³n del ganador:")
    print(winner_dist)
    
    # Visualizar distribuciÃ³n
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    winner_dist.plot(kind='bar', color=[POKEMON_COLORS['fire'], POKEMON_COLORS['water']], alpha=0.8)
    plt.title('DistribuciÃ³n de Ganadores', fontsize=14, fontweight='bold')
    plt.xlabel('Ganador Codificado')
    plt.ylabel('Frecuencia')
    plt.xticks(rotation=0)
    
    plt.subplot(1, 2, 2)
    # Correlaciones importantes
    numeric_cols = df_features.select_dtypes(include=[np.number]).columns.tolist()
    # Remover el target de las correlaciones para evitar correlaciÃ³n perfecta consigo mismo
    feature_cols = [col for col in numeric_cols if col not in ['winner_encoded']]
    
    if len(feature_cols) > 0 and 'winner_encoded' in df_features.columns:
        # Calcular correlaciones solo con las caracterÃ­sticas, no con el target
        corr_matrix = df_features[feature_cols + ['winner_encoded']].corr()
        corr_with_target = corr_matrix['winner_encoded'].abs().drop('winner_encoded').sort_values(ascending=False)
        top_corr = corr_with_target.head(8)
        
        top_corr.plot(kind='barh', color=POKEMON_COLORS['electric'], alpha=0.8)
        plt.title('Top Correlaciones con Ganador', fontsize=14, fontweight='bold')
        plt.xlabel('CorrelaciÃ³n Absoluta')
        
        # Debug: Mostrar las correlaciones mÃ¡s altas
        print(f"\nğŸ” TOP CORRELACIONES CON GANADOR:")
        print("-" * 50)
        for feature, corr in top_corr.head(5).items():
            print(f"   {feature:20} | CorrelaciÃ³n: {corr:.4f}")
    else:
        plt.text(0.5, 0.5, 'No hay datos suficientes\npara correlaciones', 
                ha='center', va='center', transform=plt.gca().transAxes)
    
    plt.tight_layout()
    
    # Guardar grÃ¡fico para documentaciÃ³n tÃ©cnica
    if IS_KAGGLE:
        plots_dir = Path(f"{WORKING_DIR}/plots")
    else:
        plots_dir = Path("../plots")
    
    plots_dir.mkdir(parents=True, exist_ok=True)
    plt.savefig(plots_dir / "00_data_distribution_analysis.png", 
                dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
    print(f"ğŸ’¾ GrÃ¡fico guardado: {plots_dir / '00_data_distribution_analysis.png'}")
    
    plt.show()

# %% [markdown]
# ## ğŸ¤– El Laboratorio del Dr. Frankenstein: Creando Nuestros Monstruos de ML
# 
# Ha llegado el momento mÃ¡s emocionante: **crear nuestros modelos de Machine Learning**. Como el Dr. Frankenstein en su laboratorio, vamos a dar vida a siete criaturas diferentes, cada una con sus propias fortalezas, debilidades y personalidades Ãºnicas.
# 
# ### ğŸ§ª La Clase PokemonMLTrainer: Nuestro Laboratorio Personal
# 
# Hemos diseÃ±ado una clase especial que actuarÃ¡ como nuestro laboratorio de experimentaciÃ³n. Esta no es una clase ordinaria; es un **centro de comando avanzado** que:
# 
# - **Gestiona mÃºltiples experimentos simultÃ¡neamente**
# - **EvalÃºa el rendimiento con mÃ©tricas sofisticadas**
# - **Genera visualizaciones que cuentan historias**
# - **Optimiza automÃ¡ticamente los hiperparÃ¡metros**
# - **Crea ensembles inteligentes**
# - **Analiza errores como un detective**
# 
# ### ğŸ­ Conoce a Nuestros Siete Gladiadores
# 
# Cada modelo que vamos a entrenar tiene su propia "personalidad" y enfoque para resolver el problema:
# 
# **ğŸ¯ Logistic Regression**: El estratega clÃ¡sico, elegante y directo
# **ğŸŒ³ Random Forest**: El consejo de ancianos, sabidurÃ­a colectiva
# **âš¡ Gradient Boosting**: El perfeccionista, aprende de cada error
# **ğŸš€ XGBoost**: El campeÃ³n de competencias, optimizado para ganar
# **ğŸ’¨ LightGBM**: El velocista inteligente, rÃ¡pido pero preciso
# **ğŸ§  Neural Network**: El cerebro artificial, patrones complejos
# **âš”ï¸ SVM**: El matemÃ¡tico puro, fronteras de decisiÃ³n perfectas
# 
# **Â¿CuÃ¡l de estos gladiadores se alzarÃ¡ como campeÃ³n?** Â¿O serÃ¡ que la verdadera magia ocurre cuando trabajen juntos? El torneo estÃ¡ a punto de comenzarâ€¦

# %%
# Importar librerÃ­as adicionales para anÃ¡lisis avanzado
from sklearn.model_selection import learning_curve, validation_curve
from sklearn.calibration import calibration_curve, CalibratedClassifierCV
from sklearn.inspection import permutation_importance
import shap
from scipy import stats

class PokemonMLTrainer:
    """Entrenador avanzado de Machine Learning para batallas Pokemon."""
    
    def __init__(self, random_state=42, save_plots=True, plots_dir=None):
        self.random_state = random_state
        self.models = {}
        self.results = {}
        self.best_model = None
        self.best_score = 0.0
        self.scaler = StandardScaler()
        self.learning_curves = {}
        self.roc_curves = {}
        self.save_plots = save_plots
        
        # Detectar entorno y configurar rutas apropiadas
        if IS_KAGGLE:
            # Entorno Kaggle
            self.plots_dir = Path(f"{WORKING_DIR}/plots")
        elif plots_dir is not None:
            # Ruta personalizada
            self.plots_dir = Path(plots_dir)
        else:
            # Desarrollo local
            self.plots_dir = Path("../plots")
        
        # Crear directorio de plots si no existe
        if self.save_plots:
            self.plots_dir.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ Directorio de grÃ¡ficos creado: {self.plots_dir}")
    
    def save_plot(self, filename, dpi=300, bbox_inches='tight'):
        """Guarda el plot actual con alta calidad para documentaciÃ³n tÃ©cnica."""
        if self.save_plots:
            filepath = self.plots_dir / f"{filename}.png"
            plt.savefig(filepath, dpi=dpi, bbox_inches=bbox_inches, 
                       facecolor='white', edgecolor='none')
            print(f"ğŸ’¾ GrÃ¡fico guardado: {filepath}")
        return filepath if self.save_plots else None
    
    def generate_plots_index(self):
        """Genera un Ã­ndice de todos los grÃ¡ficos exportados para documentaciÃ³n tÃ©cnica."""
        if not self.save_plots:
            return
            
        plots_info = [
            ("00_data_distribution_analysis.png", "DistribuciÃ³n de Datos y Correlaciones", "AnÃ¡lisis inicial de la distribuciÃ³n de ganadores y correlaciones con el target"),
            ("01_roc_curves_comparison.png", "Curvas ROC - ComparaciÃ³n de Modelos", "ComparaciÃ³n del rendimiento de todos los modelos usando curvas ROC"),
            ("02_precision_recall_curves.png", "Curvas Precision-Recall", "AnÃ¡lisis de precisiÃ³n y recall para cada modelo"),
            ("03_calibration_curves.png", "Curvas de CalibraciÃ³n", "EvaluaciÃ³n de la confiabilidad de las probabilidades predichas"),
            ("04_feature_importance_analysis.png", "AnÃ¡lisis de Importancia de CaracterÃ­sticas", "Consenso entre modelos sobre las caracterÃ­sticas mÃ¡s importantes"),
            ("05_prediction_errors_analysis.png", "AnÃ¡lisis de Errores de PredicciÃ³n", "InvestigaciÃ³n detallada de los patrones de error del mejor modelo")
        ]
        
        index_path = self.plots_dir / "README_PLOTS.md"
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write("# ğŸ“Š Ãndice de GrÃ¡ficos - Pokemon Battle AI\n\n")
            f.write("Este directorio contiene todos los grÃ¡ficos generados durante el entrenamiento del modelo de ML para batallas Pokemon.\n\n")
            f.write("## ğŸ“ˆ GrÃ¡ficos Disponibles\n\n")
            
            for filename, title, description in plots_info:
                f.write(f"### {title}\n")
                f.write(f"**Archivo:** `{filename}`\n\n")
                f.write(f"**DescripciÃ³n:** {description}\n\n")
                f.write(f"![{title}]({filename})\n\n")
                f.write("---\n\n")
            
            f.write("## ğŸ¯ Uso en DocumentaciÃ³n TÃ©cnica\n\n")
            f.write("Todos los grÃ¡ficos estÃ¡n guardados en alta resoluciÃ³n (300 DPI) con fondo blanco, ")
            f.write("optimizados para su inclusiÃ³n en documentos tÃ©cnicos, presentaciones y reportes.\n\n")
            f.write("**Formato:** PNG con transparencia\n")
            f.write("**ResoluciÃ³n:** 300 DPI\n")
            f.write("**Colores:** Paleta Pokemon temÃ¡tica\n")
        
        print(f"ğŸ“‹ Ãndice de grÃ¡ficos creado: {index_path}")
        
    def setup_models(self):
        """Configura todos los modelos a entrenar."""
        models = {
            'logistic_regression': LogisticRegression(
                random_state=self.random_state,
                max_iter=1000,
                class_weight='balanced'
            ),
            
            'random_forest': RandomForestClassifier(
                n_estimators=200,
                max_depth=15,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=self.random_state,
                class_weight='balanced',
                n_jobs=-1
            ),
            
            'gradient_boosting': GradientBoostingClassifier(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=6,
                random_state=self.random_state
            ),
            
            'xgboost': xgb.XGBClassifier(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=6,
                random_state=self.random_state,
                eval_metric='logloss',
                use_label_encoder=False
            ),
            
            'lightgbm': lgb.LGBMClassifier(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=6,
                random_state=self.random_state,
                verbose=-1
            ),
            
            'neural_network': MLPClassifier(
                hidden_layer_sizes=(256, 128, 64),
                activation='relu',
                solver='adam',
                learning_rate_init=0.001,
                max_iter=500,
                random_state=self.random_state,
                early_stopping=True,
                validation_fraction=0.1
            ),
            
            'svm': SVC(
                kernel='rbf',
                probability=True,
                random_state=self.random_state,
                class_weight='balanced'
            )
        }
        
        return models
    
    def prepare_data(self, df, target_col='winner_encoded', test_size=0.2):
        """Prepara los datos para entrenamiento."""
        # Seleccionar caracterÃ­sticas numÃ©ricas
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        if target_col in numeric_cols:
            numeric_cols.remove(target_col)
        
        # Remover columnas no Ãºtiles
        exclude_cols = ['battle_id']
        numeric_cols = [col for col in numeric_cols if col not in exclude_cols]
        
        X = df[numeric_cols].copy()
        y = df[target_col].copy()
        
        # Manejar valores faltantes
        X = X.fillna(X.median())
        
        # DivisiÃ³n de datos
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=self.random_state, stratify=y
        )
        
        return X_train, X_test, y_train, y_test, numeric_cols
    
    def calculate_advanced_metrics(self, y_true, y_pred, y_pred_proba, model_name):
        """Calcula mÃ©tricas avanzadas especÃ­ficas por tipo de modelo."""
        
        # MÃ©tricas bÃ¡sicas
        basic_metrics = {
            'accuracy': accuracy_score(y_true, y_pred),
            'precision': precision_score(y_true, y_pred, average='weighted'),
            'recall': recall_score(y_true, y_pred, average='weighted'),
            'f1': f1_score(y_true, y_pred, average='weighted'),
            'roc_auc': roc_auc_score(y_true, y_pred_proba)
        }
        
        # MÃ©tricas avanzadas
        advanced_metrics = {}
        
        # Brier Score (calibraciÃ³n de probabilidades)
        from sklearn.metrics import brier_score_loss
        advanced_metrics['brier_score'] = brier_score_loss(y_true, y_pred_proba)
        
        # Log Loss
        from sklearn.metrics import log_loss
        try:
            advanced_metrics['log_loss'] = log_loss(y_true, y_pred_proba)
        except:
            advanced_metrics['log_loss'] = np.nan
        
        # Matthews Correlation Coefficient
        from sklearn.metrics import matthews_corrcoef
        advanced_metrics['mcc'] = matthews_corrcoef(y_true, y_pred)
        
        # Balanced Accuracy
        from sklearn.metrics import balanced_accuracy_score
        advanced_metrics['balanced_accuracy'] = balanced_accuracy_score(y_true, y_pred)
        
        # MÃ©tricas especÃ­ficas por clase
        precision_per_class = precision_score(y_true, y_pred, average=None)
        recall_per_class = recall_score(y_true, y_pred, average=None)
        
        advanced_metrics['precision_class_0'] = precision_per_class[0] if len(precision_per_class) > 0 else 0
        advanced_metrics['precision_class_1'] = precision_per_class[1] if len(precision_per_class) > 1 else 0
        advanced_metrics['recall_class_0'] = recall_per_class[0] if len(recall_per_class) > 0 else 0
        advanced_metrics['recall_class_1'] = recall_per_class[1] if len(recall_per_class) > 1 else 0
        
        # Combinar mÃ©tricas
        all_metrics = {**basic_metrics, **advanced_metrics}
        
        return all_metrics
    
    def plot_learning_curves(self, model, X, y, model_name, cv=5):
        """Genera curvas de aprendizaje para un modelo."""
        
        train_sizes, train_scores, val_scores = learning_curve(
            model, X, y, cv=cv, n_jobs=-1, 
            train_sizes=np.linspace(0.1, 1.0, 10),
            scoring='roc_auc', random_state=self.random_state
        )
        
        # Calcular medias y desviaciones estÃ¡ndar
        train_mean = np.mean(train_scores, axis=1)
        train_std = np.std(train_scores, axis=1)
        val_mean = np.mean(val_scores, axis=1)
        val_std = np.std(val_scores, axis=1)
        
        # Guardar para anÃ¡lisis posterior
        self.learning_curves[model_name] = {
            'train_sizes': train_sizes,
            'train_mean': train_mean,
            'train_std': train_std,
            'val_mean': val_mean,
            'val_std': val_std
        }
        
        return train_sizes, train_mean, train_std, val_mean, val_std
    
    def plot_roc_curves(self, models_results, X_test, y_test):
        """Genera curvas ROC para todos los modelos."""
        
        plt.figure(figsize=(12, 8))
        
        colors = [POKEMON_COLORS['fire'], POKEMON_COLORS['water'], 
                 POKEMON_COLORS['grass'], POKEMON_COLORS['electric'],
                 POKEMON_COLORS['psychic'], POKEMON_COLORS['ice'],
                 POKEMON_COLORS['dragon']]
        
        for i, (model_name, result) in enumerate(models_results.items()):
            if i >= len(colors):
                break
                
            y_pred_proba = result['probabilities']
            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
            roc_auc = auc(fpr, tpr)
            
            # Guardar curva ROC
            self.roc_curves[model_name] = {'fpr': fpr, 'tpr': tpr, 'auc': roc_auc}
            
            plt.plot(fpr, tpr, color=colors[i], lw=2, alpha=0.8,
                    label=f'{model_name} (AUC = {roc_auc:.3f})')
        
        # LÃ­nea diagonal (clasificador aleatorio)
        plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', alpha=0.8)
        
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('Tasa de Falsos Positivos', fontsize=12)
        plt.ylabel('Tasa de Verdaderos Positivos', fontsize=12)
        plt.title('Curvas ROC - ComparaciÃ³n de Modelos', fontsize=16, fontweight='bold')
        plt.legend(loc="lower right")
        plt.grid(alpha=0.3)
        
        # AÃ±adir lÃ­nea de baseline
        baseline_auc = 0.837
        plt.axhline(y=baseline_auc, color='red', linestyle=':', alpha=0.7, 
                   label=f'Baseline AUC = {baseline_auc}')
        
        plt.tight_layout()
        
        # Guardar grÃ¡fico
        self.save_plot("01_roc_curves_comparison")
        
        plt.show()
    
    def plot_precision_recall_curves(self, models_results, X_test, y_test):
        """Genera curvas Precision-Recall para todos los modelos."""
        
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        plt.figure(figsize=(12, 8))
        
        colors = [POKEMON_COLORS['fire'], POKEMON_COLORS['water'], 
                 POKEMON_COLORS['grass'], POKEMON_COLORS['electric'],
                 POKEMON_COLORS['psychic'], POKEMON_COLORS['ice'],
                 POKEMON_COLORS['dragon']]
        
        for i, (model_name, result) in enumerate(models_results.items()):
            if i >= len(colors):
                break
                
            y_pred_proba = result['probabilities']
            precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
            avg_precision = average_precision_score(y_test, y_pred_proba)
            
            plt.plot(recall, precision, color=colors[i], lw=2, alpha=0.8,
                    label=f'{model_name} (AP = {avg_precision:.3f})')
        
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('Recall', fontsize=12)
        plt.ylabel('Precision', fontsize=12)
        plt.title('Curvas Precision-Recall - ComparaciÃ³n de Modelos', fontsize=16, fontweight='bold')
        plt.legend(loc="lower left")
        plt.grid(alpha=0.3)
        
        plt.tight_layout()
        
        # Guardar grÃ¡fico
        self.save_plot("02_precision_recall_curves")
        
        plt.show()
    
    def plot_calibration_curves(self, models_results, X_test, y_test):
        """Genera curvas de calibraciÃ³n para evaluar la confiabilidad de las probabilidades."""
        
        plt.figure(figsize=(12, 8))
        
        colors = [POKEMON_COLORS['fire'], POKEMON_COLORS['water'], 
                 POKEMON_COLORS['grass'], POKEMON_COLORS['electric'],
                 POKEMON_COLORS['psychic'], POKEMON_COLORS['ice'],
                 POKEMON_COLORS['dragon']]
        
        for i, (model_name, result) in enumerate(models_results.items()):
            if i >= len(colors):
                break
                
            y_pred_proba = result['probabilities']
            fraction_of_positives, mean_predicted_value = calibration_curve(
                y_test, y_pred_proba, n_bins=10
            )
            
            plt.plot(mean_predicted_value, fraction_of_positives, "s-",
                    color=colors[i], alpha=0.8, label=f'{model_name}')
        
        # LÃ­nea de calibraciÃ³n perfecta
        plt.plot([0, 1], [0, 1], "k:", label="CalibraciÃ³n perfecta")
        
        plt.xlabel('Probabilidad Predicha Promedio', fontsize=12)
        plt.ylabel('FracciÃ³n de Positivos', fontsize=12)
        plt.title('Curvas de CalibraciÃ³n - Confiabilidad de Probabilidades', fontsize=16, fontweight='bold')
        plt.legend()
        plt.grid(alpha=0.3)
        
        plt.tight_layout()
        
        # Guardar grÃ¡fico
        self.save_plot("03_calibration_curves")
        
        plt.show()
    
    def plot_feature_importance_analysis(self, models_results, feature_names):
        """Analiza y visualiza la importancia de caracterÃ­sticas con consenso entre modelos."""
        
        # Recopilar importancias de todos los modelos
        feature_importances = {}
        
        for model_name, result in models_results.items():
            model = result['model']
            
            # Obtener importancias segÃºn el tipo de modelo
            if hasattr(model, 'feature_importances_'):
                # Tree-based models
                importances = model.feature_importances_
            elif hasattr(model, 'coef_'):
                # Linear models
                importances = np.abs(model.coef_[0])
            else:
                # Para otros modelos, usar permutation importance
                continue
            
            feature_importances[model_name] = importances
        
        if not feature_importances:
            print("âš ï¸ No se pudieron extraer importancias de caracterÃ­sticas")
            return None
        
        # Crear DataFrame de importancias
        importance_df = pd.DataFrame(feature_importances, index=feature_names)
        
        # Calcular estadÃ­sticas de consenso
        importance_df['mean'] = importance_df.mean(axis=1)
        importance_df['std'] = importance_df.std(axis=1)
        importance_df['stability'] = 1 - (importance_df['std'] / (importance_df['mean'] + 1e-8))
        
        # Ordenar por importancia promedio
        importance_df = importance_df.sort_values('mean', ascending=False)
        
        # VisualizaciÃ³n
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. Top 10 caracterÃ­sticas por importancia promedio
        top_features = importance_df.head(10)
        axes[0, 0].barh(range(len(top_features)), top_features['mean'], 
                       color=POKEMON_COLORS['fire'], alpha=0.8)
        axes[0, 0].set_yticks(range(len(top_features)))
        axes[0, 0].set_yticklabels(top_features.index)
        axes[0, 0].set_title('Top 10 CaracterÃ­sticas - Importancia Promedio', fontweight='bold')
        axes[0, 0].set_xlabel('Importancia Promedio')
        
        # 2. Estabilidad vs Importancia
        axes[0, 1].scatter(importance_df['mean'], importance_df['stability'], 
                          c=POKEMON_COLORS['water'], alpha=0.7, s=60)
        axes[0, 1].set_xlabel('Importancia Promedio')
        axes[0, 1].set_ylabel('Estabilidad (1 - CV)')
        axes[0, 1].set_title('Estabilidad vs Importancia', fontweight='bold')
        
        # Anotar caracterÃ­sticas mÃ¡s estables e importantes
        stable_important = importance_df[(importance_df['stability'] > 0.7) & 
                                       (importance_df['mean'] > importance_df['mean'].median())]
        for idx, row in stable_important.head(5).iterrows():
            axes[0, 1].annotate(idx, (row['mean'], row['stability']), 
                              xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        # 3. Heatmap de importancias por modelo
        models_to_plot = list(feature_importances.keys())[:5]  # Top 5 modelos
        features_to_plot = top_features.index[:8]  # Top 8 caracterÃ­sticas
        
        heatmap_data = importance_df.loc[features_to_plot, models_to_plot]
        im = axes[1, 0].imshow(heatmap_data.values, cmap='YlOrRd', aspect='auto')
        axes[1, 0].set_xticks(range(len(models_to_plot)))
        axes[1, 0].set_xticklabels(models_to_plot, rotation=45)
        axes[1, 0].set_yticks(range(len(features_to_plot)))
        axes[1, 0].set_yticklabels(features_to_plot)
        axes[1, 0].set_title('Heatmap de Importancias por Modelo', fontweight='bold')
        
        # AÃ±adir colorbar
        plt.colorbar(im, ax=axes[1, 0])
        
        # 4. DistribuciÃ³n de importancias
        axes[1, 1].hist(importance_df['mean'], bins=20, color=POKEMON_COLORS['grass'], 
                       alpha=0.7, edgecolor='black')
        axes[1, 1].axvline(importance_df['mean'].mean(), color='red', linestyle='--', 
                          label=f'Media: {importance_df["mean"].mean():.4f}')
        axes[1, 1].set_xlabel('Importancia Promedio')
        axes[1, 1].set_ylabel('Frecuencia')
        axes[1, 1].set_title('DistribuciÃ³n de Importancias', fontweight='bold')
        axes[1, 1].legend()
        
        plt.tight_layout()
        
        # Guardar grÃ¡fico
        self.save_plot("04_feature_importance_analysis")
        
        plt.show()
        
        # Reporte de caracterÃ­sticas mÃ¡s importantes
        print("\nğŸ† TOP 10 CARACTERÃSTICAS MÃS IMPORTANTES:")
        print("-" * 60)
        for i, (feature, row) in enumerate(top_features.iterrows(), 1):
            stability_emoji = "ğŸ”’" if row['stability'] > 0.8 else "ğŸ“Š" if row['stability'] > 0.6 else "ğŸ“ˆ"
            print(f"{i:2d}. {stability_emoji} {feature:25} | Importancia: {row['mean']:.4f} | Estabilidad: {row['stability']:.3f}")
        
        print(f"\nğŸ¯ CARACTERÃSTICAS MÃS ESTABLES (Estabilidad > 0.7): {len(importance_df[importance_df['stability'] > 0.7])}")
        print(f"âš¡ CARACTERÃSTICAS ALTAMENTE PREDICTIVAS (Importancia > media): {len(importance_df[importance_df['mean'] > importance_df['mean'].mean()])}")
        
        return importance_df
    
    def hyperparameter_optimization(self, X_train, y_train, top_models=3):
        """Optimiza hiperparÃ¡metros para los mejores modelos."""
        
        print(f"\nâš™ï¸ Optimizando hiperparÃ¡metros para los top {top_models} modelos...")
        
        # Obtener los mejores modelos por ROC-AUC
        model_scores = [(name, result['metrics']['roc_auc']) for name, result in self.results.items()]
        model_scores.sort(key=lambda x: x[1], reverse=True)
        top_model_names = [name for name, _ in model_scores[:top_models]]
        
        optimized_models = {}
        
        # Definir espacios de bÃºsqueda para cada modelo
        param_grids = {
            'random_forest': {
                'n_estimators': [100, 200, 300],
                'max_depth': [10, 15, 20, None],
                'min_samples_split': [2, 5, 10],
                'min_samples_leaf': [1, 2, 4],
                'max_features': ['sqrt', 'log2', None]
            },
            'xgboost': {
                'n_estimators': [100, 200, 300],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 6, 9],
                'subsample': [0.8, 0.9, 1.0],
                'colsample_bytree': [0.8, 0.9, 1.0]
            },
            'lightgbm': {
                'n_estimators': [100, 200, 300],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 6, 9],
                'num_leaves': [31, 50, 100],
                'subsample': [0.8, 0.9, 1.0]
            },
            'gradient_boosting': {
                'n_estimators': [100, 200, 300],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 6, 9],
                'subsample': [0.8, 0.9, 1.0]
            },
            'logistic_regression': {
                'C': [0.1, 1.0, 10.0, 100.0],
                'penalty': ['l1', 'l2'],
                'solver': ['liblinear', 'saga']
            }
        }
        
        for model_name in top_model_names:
            if model_name not in param_grids:
                print(f"âš ï¸ No hay parÃ¡metros definidos para {model_name}")
                continue
                
            print(f"\nğŸ”§ Optimizando {model_name}...")
            
            try:
                # Obtener modelo base
                base_model = self.setup_models()[model_name]
                
                # Preparar datos
                if model_name in ['neural_network', 'svm', 'logistic_regression']:
                    X_train_final = self.scaler.fit_transform(X_train)
                else:
                    X_train_final = X_train
                
                # BÃºsqueda aleatoria
                random_search = RandomizedSearchCV(
                    base_model,
                    param_grids[model_name],
                    n_iter=20,  # Reducido para velocidad
                    cv=3,       # Reducido para velocidad
                    scoring='roc_auc',
                    random_state=self.random_state,
                    n_jobs=-1,
                    verbose=0
                )
                
                random_search.fit(X_train_final, y_train)
                
                optimized_models[f"{model_name}_optimized"] = {
                    'model': random_search.best_estimator_,
                    'best_params': random_search.best_params_,
                    'best_score': random_search.best_score_,
                    'cv_results': random_search.cv_results_
                }
                
                print(f"âœ… {model_name} optimizado - CV Score: {random_search.best_score_:.4f}")
                print(f"   Mejores parÃ¡metros: {random_search.best_params_}")
                
            except Exception as e:
                print(f"âŒ Error optimizando {model_name}: {str(e)}")
                continue
        
        return optimized_models
    
    def create_ensemble(self, models_results, X_train, y_train):
        """Crea un modelo ensemble con los mejores modelos."""
        
        print("\nğŸ¤ Creando modelo ensemble...")
        
        try:
            # Seleccionar los mejores modelos (top 5)
            model_scores = [(name, result['metrics']['roc_auc']) for name, result in models_results.items()]
            model_scores.sort(key=lambda x: x[1], reverse=True)
            top_models = model_scores[:5]
            
            print(f"   Modelos seleccionados para ensemble:")
            for name, score in top_models:
                print(f"   - {name}: {score:.4f}")
            
            # Crear lista de estimadores para el ensemble
            estimators = []
            for name, _ in top_models:
                model = models_results[name]['model']
                estimators.append((name, model))
            
            # Crear VotingClassifier con soft voting
            ensemble = VotingClassifier(
                estimators=estimators,
                voting='soft'
            )
            
            # Entrenar ensemble
            ensemble.fit(X_train, y_train)
            
            print("âœ… Modelo ensemble creado exitosamente")
            return ensemble
            
        except Exception as e:
            print(f"âŒ Error creando ensemble: {str(e)}")
            return None
    
    def analyze_prediction_errors(self, models_results, X_test, y_test, feature_names):
        """Analiza los errores de predicciÃ³n para entender patrones de fallo."""
        
        print("\nğŸ” Analizando errores de predicciÃ³n...")
        
        # Obtener el mejor modelo
        best_model_name = max(models_results.keys(), 
                             key=lambda x: models_results[x]['metrics']['roc_auc'])
        best_result = models_results[best_model_name]
        
        y_pred = best_result['predictions']
        y_pred_proba = best_result['probabilities']
        
        # Crear DataFrame de anÃ¡lisis
        error_df = pd.DataFrame({
            'true_label': y_test,
            'predicted_label': y_pred,
            'predicted_proba': y_pred_proba,
            'correct': y_test == y_pred
        })
        
        # AÃ±adir caracterÃ­sticas
        for i, feature in enumerate(feature_names):
            error_df[feature] = X_test.iloc[:, i].values
        
        # Calcular mÃ©tricas de error
        error_df['prediction_confidence'] = np.abs(error_df['predicted_proba'] - 0.5)
        error_df['error_type'] = 'Correct'
        error_df.loc[(error_df['true_label'] == 1) & (error_df['predicted_label'] == 0), 'error_type'] = 'False Negative'
        error_df.loc[(error_df['true_label'] == 0) & (error_df['predicted_label'] == 1), 'error_type'] = 'False Positive'
        
        # Visualizaciones
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. DistribuciÃ³n de confianza por tipo de error
        error_types = error_df['error_type'].unique()
        colors = [POKEMON_COLORS['grass'], POKEMON_COLORS['fire'], POKEMON_COLORS['water']]
        
        for i, error_type in enumerate(error_types):
            if i < len(colors):
                subset = error_df[error_df['error_type'] == error_type]
                axes[0, 0].hist(subset['prediction_confidence'], alpha=0.7, 
                              label=error_type, color=colors[i], bins=20)
        
        axes[0, 0].set_xlabel('Confianza de PredicciÃ³n')
        axes[0, 0].set_ylabel('Frecuencia')
        axes[0, 0].set_title('DistribuciÃ³n de Confianza por Tipo de Error', fontweight='bold')
        axes[0, 0].legend()
        
        # 2. Probabilidades predichas vs reales
        axes[0, 1].scatter(error_df[error_df['correct']]['predicted_proba'], 
                          error_df[error_df['correct']]['true_label'], 
                          alpha=0.6, color=POKEMON_COLORS['grass'], label='Correctas', s=30)
        axes[0, 1].scatter(error_df[~error_df['correct']]['predicted_proba'], 
                          error_df[~error_df['correct']]['true_label'], 
                          alpha=0.8, color=POKEMON_COLORS['fire'], label='Incorrectas', s=30)
        axes[0, 1].set_xlabel('Probabilidad Predicha')
        axes[0, 1].set_ylabel('Etiqueta Real')
        axes[0, 1].set_title('Probabilidades Predichas vs Etiquetas Reales', fontweight='bold')
        axes[0, 1].legend()
        
        # 3. Matriz de confusiÃ³n
        from sklearn.metrics import confusion_matrix
        cm = confusion_matrix(y_test, y_pred)
        im = axes[1, 0].imshow(cm, interpolation='nearest', cmap='Blues')
        axes[1, 0].set_title('Matriz de ConfusiÃ³n', fontweight='bold')
        
        # AÃ±adir texto a la matriz
        thresh = cm.max() / 2.
        for i in range(cm.shape[0]):
            for j in range(cm.shape[1]):
                axes[1, 0].text(j, i, format(cm[i, j], 'd'),
                               ha="center", va="center",
                               color="white" if cm[i, j] > thresh else "black")
        
        axes[1, 0].set_ylabel('Etiqueta Real')
        axes[1, 0].set_xlabel('Etiqueta Predicha')
        
        # 4. CaracterÃ­sticas mÃ¡s diferentes en errores
        incorrect_cases = error_df[~error_df['correct']]
        correct_cases = error_df[error_df['correct']]
        
        feature_diffs = []
        for feature in feature_names[:10]:  # Top 10 caracterÃ­sticas
            if feature in error_df.columns:
                diff = abs(incorrect_cases[feature].mean() - correct_cases[feature].mean())
                feature_diffs.append((feature, diff))
        
        feature_diffs.sort(key=lambda x: x[1], reverse=True)
        features, diffs = zip(*feature_diffs[:8])
        
        axes[1, 1].barh(range(len(features)), diffs, color=POKEMON_COLORS['psychic'], alpha=0.8)
        axes[1, 1].set_yticks(range(len(features)))
        axes[1, 1].set_yticklabels(features)
        axes[1, 1].set_xlabel('Diferencia Promedio')
        axes[1, 1].set_title('CaracterÃ­sticas MÃ¡s Diferentes en Errores', fontweight='bold')
        
        plt.tight_layout()
        
        # Guardar grÃ¡fico
        self.save_plot("05_prediction_errors_analysis")
        
        plt.show()
        
        # EstadÃ­sticas de error
        print(f"\nğŸ“Š ESTADÃSTICAS DE ERROR ({best_model_name}):")
        print("-" * 50)
        print(f"Total de predicciones: {len(error_df)}")
        print(f"Predicciones correctas: {error_df['correct'].sum()} ({error_df['correct'].mean()*100:.1f}%)")
        print(f"Falsos positivos: {len(error_df[error_df['error_type'] == 'False Positive'])}")
        print(f"Falsos negativos: {len(error_df[error_df['error_type'] == 'False Negative'])}")
        
        # Casos de baja confianza
        low_confidence = error_df[error_df['prediction_confidence'] < 0.1]
        print(f"\nCasos de baja confianza (< 0.1): {len(low_confidence)} ({len(low_confidence)/len(error_df)*100:.1f}%)")
        print(f"PrecisiÃ³n en casos de baja confianza: {low_confidence['correct'].mean()*100:.1f}%")
        
        return error_df
    
    def train_models(self, X_train, X_test, y_train, y_test, feature_names):
        """Entrena todos los modelos con anÃ¡lisis avanzado."""
        print("ğŸš€ Iniciando entrenamiento de modelos con anÃ¡lisis avanzado...")
        
        # Escalado para modelos que lo necesitan
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        models = self.setup_models()
        results = {}
        
        for model_name, model in models.items():
            print(f"\nğŸ”„ Entrenando {model_name}...")
            
            try:
                # Seleccionar datos apropiados
                if model_name in ['neural_network', 'svm', 'logistic_regression']:
                    X_train_final = X_train_scaled
                    X_test_final = X_test_scaled
                else:
                    X_train_final = X_train
                    X_test_final = X_test
                
                # Entrenar modelo
                model.fit(X_train_final, y_train)
                
                # Predicciones
                y_pred = model.predict(X_test_final)
                y_pred_proba = model.predict_proba(X_test_final)[:, 1]
                
                # MÃ©tricas avanzadas
                metrics = self.calculate_advanced_metrics(y_test, y_pred, y_pred_proba, model_name)
                
                # Cross-validation
                cv_scores = cross_val_score(
                    model, X_train_final, y_train, 
                    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=self.random_state),
                    scoring='roc_auc'
                )
                
                metrics['cv_mean'] = cv_scores.mean()
                metrics['cv_std'] = cv_scores.std()
                
                # Curvas de aprendizaje (solo para modelos rÃ¡pidos)
                if model_name in ['logistic_regression', 'random_forest', 'gradient_boosting']:
                    print(f"   ğŸ“ˆ Generando curvas de aprendizaje para {model_name}...")
                    self.plot_learning_curves(model, X_train_final, y_train, model_name)
                
                results[model_name] = {
                    'model': model,
                    'metrics': metrics,
                    'predictions': y_pred,
                    'probabilities': y_pred_proba
                }
                
                print(f"âœ… {model_name} - ROC-AUC: {metrics['roc_auc']:.4f} | MCC: {metrics['mcc']:.4f} | Brier: {metrics['brier_score']:.4f}")
                
                # Actualizar mejor modelo
                if metrics['roc_auc'] > self.best_score:
                    self.best_score = metrics['roc_auc']
                    self.best_model = model_name
                
            except Exception as e:
                print(f"âŒ Error entrenando {model_name}: {str(e)}")
                continue
        
        self.models = {name: result['model'] for name, result in results.items()}
        self.results = results
        
        # Generar visualizaciones comparativas
        print("\nğŸ“Š Generando visualizaciones comparativas...")
        self.plot_roc_curves(results, X_test, y_test)
        self.plot_precision_recall_curves(results, X_test, y_test)
        self.plot_calibration_curves(results, X_test, y_test)
        
        return results

# %% [markdown]
# ## ğŸš€ Â¡Que Comience el EspectÃ¡culo! El Gran Torneo de Algoritmos
# 
# **Ladies and gentlemen, trainers and Pokemon masters!** Ha llegado el momento que todos estÃ¡bamos esperando. DespuÃ©s de semanas de preparaciÃ³n, anÃ¡lisis y diseÃ±o, nuestros siete gladiadores estÃ¡n listos para enfrentarse en la arena mÃ¡s desafiante: **predecir el resultado de batallas Pokemon reales**.
# 
# ### ğŸª El Escenario EstÃ¡ Preparado
# 
# Nuestros datos estÃ¡n pulidos y listos. Nuestras caracterÃ­sticas han sido cuidadosamente seleccionadas y engineered. Nuestros modelos estÃ¡n configurados con parÃ¡metros iniciales inteligentes. Todo estÃ¡ en su lugar para el espectÃ¡culo del siglo.
# 
# ### âš¡ La TensiÃ³n en el Aire
# 
# Podemos sentir la electricidad en el ambiente. Cada algoritmo "sabe" que estÃ¡ compitiendo no solo contra los datos, sino contra otros seis competidores igualmente determinados. El baseline de **ROC-AUC 0.837** se alza como el dragÃ³n final que todos deben derrotar.
# 
# **Â¿QuiÃ©n serÃ¡ el primero en caer?** Â¿QuÃ© modelo sorprenderÃ¡ con un rendimiento inesperado? Â¿Veremos una batalla reÃ±ida o habrÃ¡ un claro dominador desde el principio?
# 
# La preparaciÃ³n ha terminado. Los dados estÃ¡n echados. **Â¡Que comience la batalla!**

# %%
# Inicializar entrenador
trainer = PokemonMLTrainer(random_state=42)
print("âœ… Entrenador ML avanzado inicializado")
print("ğŸš€ Â¡Listo para comenzar el entrenamiento!")

# %%
# Preparar datos
print("ğŸ“Š Preparando datos para entrenamiento...")
X_train, X_test, y_train, y_test, feature_names = trainer.prepare_data(df_features)

print(f"âœ… Datos preparados:")
print(f"   - Entrenamiento: {X_train.shape}")
print(f"   - Prueba: {X_test.shape}")
print(f"   - CaracterÃ­sticas: {len(feature_names)}")

# %% [markdown]
# ### ğŸ¤– Round 1: Los Gladiadores Entran en AcciÃ³n
# 
# **Â¡DING DING DING!** Suena la campana y nuestros siete gladiadores saltan al ring. Este es el momento de la verdad - despuÃ©s de toda la preparaciÃ³n, finalmente veremos de quÃ© estÃ¡n hechos nuestros modelos.
# 
# ### ğŸ­ El Drama se Desarrolla
# 
# Cada modelo aborda el problema desde su perspectiva Ãºnica:
# - **Logistic Regression** entra con confianza clÃ¡sica, buscando relaciones lineales claras
# - **Random Forest** despliega su ejÃ©rcito de Ã¡rboles, cada uno votando por su predicciÃ³n favorita
# - **Gradient Boosting** comienza lentamente, aprendiendo meticulosamente de cada error
# - **XGBoost** llega con toda la experiencia de miles de competencias de Kaggle
# - **LightGBM** se mueve con agilidad felina, optimizando cada cÃ¡lculo
# - **Neural Network** activa sus neuronas, buscando patrones que otros no pueden ver
# - **SVM** traza fronteras de decisiÃ³n con precisiÃ³n matemÃ¡tica
# 
# ### ğŸ“Š Las MÃ©tricas Que Importan
# 
# No nos conformamos con una sola mÃ©trica. Como jueces experimentados, evaluamos cada modelo desde mÃºltiples Ã¡ngulos:
# - **ROC-AUC**: Â¿QuÃ© tan bien separa ganadores de perdedores?
# - **MCC**: Â¿QuÃ© tan balanceado es su rendimiento?
# - **Brier Score**: Â¿QuÃ© tan calibradas estÃ¡n sus probabilidades?
# - **Cross-validation**: Â¿Es consistente o solo tuvo suerte?
# 
# **Â¿QuiÃ©n tomarÃ¡ la delantera inicial?** Los primeros resultados estÃ¡n a punto de revelarseâ€¦

# %%
# Entrenar modelos
results = trainer.train_models(X_train, X_test, y_train, y_test, feature_names)

print(f"\nğŸ† Mejor modelo base: {trainer.best_model} (ROC-AUC: {trainer.best_score:.4f})")

# %% [markdown]
# ### ğŸ” Los Secretos Revelados: Â¿QuÃ© Hace Ganar una Batalla?
# 
# Ahora que nuestros modelos han mostrado sus cartas, es momento de la **gran revelaciÃ³n**. Como detectives investigando un misterio, vamos a descubrir quÃ© caracterÃ­sticas son realmente importantes para predecir el Ã©xito en las batallas Pokemon.
# 
# ### ğŸ•µï¸ La InvestigaciÃ³n Comienza
# 
# No todos los modelos "ven" las mismas cosas. Algunos se enfocan en patrones sutiles, otros en seÃ±ales obvias. Pero cuando mÃºltiples modelos coinciden en que una caracterÃ­stica es importante, sabemos que hemos encontrado algo especial.
# 
# ### ğŸ¯ El Consenso de los Maestros
# 
# Vamos a realizar un anÃ¡lisis de consenso - como reunir a los mejores entrenadores Pokemon del mundo y preguntarles: **"Â¿En quÃ© se fijan cuando predicen quiÃ©n ganarÃ¡ una batalla?"**
# 
# **Â¿SerÃ¡ la intensidad de la batalla?** Â¿La cantidad de movimientos ejecutados? Â¿Los patrones de cambio? Â¿O descubriremos algo completamente inesperado?
# 
# ### ğŸ† Las CaracterÃ­sticas MÃ¡s Estables
# 
# TambiÃ©n buscaremos las caracterÃ­sticas mÃ¡s "estables" - aquellas en las que todos los modelos confÃ­an consistentemente. Estas son como las reglas fundamentales del universo Pokemon, principios que trascienden algoritmos especÃ­ficos.
# 
# **Â¿QuÃ© secretos del Ã©xito en batallas Pokemon estÃ¡n a punto de ser revelados?**

# %%
# AnÃ¡lisis de importancia de caracterÃ­sticas
print("\nğŸ” Analizando importancia de caracterÃ­sticas...")
importance_analysis = trainer.plot_feature_importance_analysis(results, feature_names)

# %% [markdown]
# ### âš™ï¸ Round 2: Los Gladiadores Evolucionan
# 
# **Â¡Plot twist!** Como en cualquier buena historia de Pokemon, nuestros competidores estÃ¡n a punto de **evolucionar**. Los tres mejores modelos del primer round han ganado el derecho a una transformaciÃ³n especial: optimizaciÃ³n de hiperparÃ¡metros.
# 
# ### ğŸ§¬ La EvoluciÃ³n No Es Solo Suerte
# 
# En el mundo Pokemon, la evoluciÃ³n requiere las condiciones exactas. De manera similar, nuestros modelos necesitan los hiperparÃ¡metros perfectos para alcanzar su mÃ¡ximo potencial. No es magia - es **ciencia pura y bÃºsqueda inteligente**.
# 
# ### ğŸ¯ La BÃºsqueda del Santo Grial
# 
# Cada modelo tiene su propio "cÃ³digo genÃ©tico" de hiperparÃ¡metros:
# - **Random Forest**: Â¿CuÃ¡ntos Ã¡rboles? Â¿QuÃ© profundidad? Â¿CuÃ¡ntas muestras por hoja?
# - **XGBoost**: Â¿QuÃ© learning rate? Â¿CuÃ¡nta regularizaciÃ³n? Â¿QuÃ© subsample?
# - **LightGBM**: Â¿CuÃ¡ntas hojas? Â¿QuÃ© profundidad mÃ¡xima? Â¿CuÃ¡ntos estimadores?
# 
# ### ğŸ”¬ RandomizedSearchCV: Nuestro Laboratorio de EvoluciÃ³n
# 
# No vamos a probar cada combinaciÃ³n posible (eso tomarÃ­a aÃ±os). En su lugar, usamos **bÃºsqueda aleatoria inteligente** - como un entrenador Pokemon experimentado que sabe exactamente quÃ© condiciones probar para cada evoluciÃ³n.
# 
# **Â¿Veremos mejoras dramÃ¡ticas?** Â¿AlgÃºn modelo darÃ¡ un salto cuÃ¡ntico en rendimiento? Â¿O descubriremos que ya estaban cerca de su potencial mÃ¡ximo?
# 
# **Â¡La evoluciÃ³n comienza ahora!**

# %%
# OptimizaciÃ³n de hiperparÃ¡metros
optimized_models = trainer.hyperparameter_optimization(X_train, y_train, top_models=3)

# Evaluar modelos optimizados
print("\nğŸ“Š Evaluando modelos optimizados...")
optimized_results = {}

for opt_name, opt_data in optimized_models.items():
    model = opt_data['model']
    
    # Seleccionar datos apropiados
    base_name = opt_name.replace('_optimized', '')
    if base_name in ['neural_network', 'svm', 'logistic_regression']:
        X_test_final = trainer.scaler.transform(X_test)
    else:
        X_test_final = X_test
    
    # Predicciones
    y_pred = model.predict(X_test_final)
    y_pred_proba = model.predict_proba(X_test_final)[:, 1]
    
    # MÃ©tricas
    metrics = trainer.calculate_advanced_metrics(y_test, y_pred, y_pred_proba, opt_name)
    
    optimized_results[opt_name] = {
        'model': model,
        'metrics': metrics,
        'predictions': y_pred,
        'probabilities': y_pred_proba
    }
    
    print(f"âœ… {opt_name} - ROC-AUC: {metrics['roc_auc']:.4f} | MCC: {metrics['mcc']:.4f}")
    
    # Actualizar mejor modelo si es necesario
    if metrics['roc_auc'] > trainer.best_score:
        trainer.best_score = metrics['roc_auc']
        trainer.best_model = opt_name

# %% [markdown]
# ### ğŸ¤ La Alianza Definitiva: Cuando los Rivales se Unen
# 
# En las mejores historias Ã©picas, llega un momento cuando los antiguos rivales deben unir fuerzas para enfrentar un desafÃ­o mayor. **Este es ese momento.**
# 
# ### ğŸŒŸ El Poder de la UniÃ³n
# 
# Hemos visto lo que cada modelo puede lograr individualmente. Algunos brillan en ciertos aspectos, otros dominan diferentes patrones. Pero Â¿quÃ© pasarÃ­a si combinÃ¡ramos sus fortalezas Ãºnicas en una **sÃºper-alianza**?
# 
# ### ğŸ­ Los Avengers del Machine Learning
# 
# Como los Avengers, cada modelo aporta algo Ãºnico al equipo:
# - **Random Forest**: La sabidurÃ­a colectiva y estabilidad
# - **XGBoost**: La precisiÃ³n competitiva y optimizaciÃ³n
# - **LightGBM**: La velocidad y eficiencia
# - **Neural Network**: La capacidad de ver patrones complejos
# - **Gradient Boosting**: El aprendizaje meticuloso de errores
# 
# ### ğŸ—³ï¸ Democracia en AcciÃ³n: Soft Voting
# 
# Nuestro ensemble no es una dictadura donde un modelo domina. Es una **democracia perfecta** donde cada modelo vota con sus probabilidades, y la decisiÃ³n final emerge del consenso colectivo.
# 
# ### ğŸ¯ La Pregunta del MillÃ³n
# 
# **Â¿SerÃ¡ el ensemble superior a cualquier modelo individual?** En teorÃ­a, deberÃ­a ser asÃ­ - la diversidad de enfoques deberÃ­a crear un predictor mÃ¡s robusto y preciso.
# 
# Pero la teorÃ­a y la realidad a veces divergen. **Â¿Nuestros gladiadores trabajarÃ¡n mejor juntos o en solitario?**
# 
# **Â¡La alianza definitiva estÃ¡ a punto de formarse!**

# %%
# Crear ensemble
ensemble_model = trainer.create_ensemble(results, X_train, y_train)

if ensemble_model is not None:
    # Evaluar ensemble
    print("\nğŸ“Š Evaluando modelo ensemble...")
    
    # Predicciones del ensemble
    y_pred_ensemble = ensemble_model.predict(X_test)
    y_pred_proba_ensemble = ensemble_model.predict_proba(X_test)[:, 1]
    
    # MÃ©tricas del ensemble
    ensemble_metrics = trainer.calculate_advanced_metrics(
        y_test, y_pred_ensemble, y_pred_proba_ensemble, 'ensemble'
    )
    
    print(f"ğŸ¤ Ensemble - ROC-AUC: {ensemble_metrics['roc_auc']:.4f} | MCC: {ensemble_metrics['mcc']:.4f}")
    
    # Actualizar mejor modelo si el ensemble es superior
    if ensemble_metrics['roc_auc'] > trainer.best_score:
        trainer.best_score = ensemble_metrics['roc_auc']
        trainer.best_model = 'ensemble'
        
        # AÃ±adir ensemble a resultados
        optimized_results['ensemble'] = {
            'model': ensemble_model,
            'metrics': ensemble_metrics,
            'predictions': y_pred_ensemble,
            'probabilities': y_pred_proba_ensemble
        }

# %% [markdown]
# ### ğŸ” CSI: Pokemon Battle Edition - Investigando los Misterios del Fracaso
# 
# Incluso los mejores entrenadores Pokemon pierden batallas. Incluso los mejores modelos de ML cometen errores. Pero la diferencia entre un buen entrenador y un **maestro** estÃ¡ en cÃ³mo aprende de esas derrotas.
# 
# ### ğŸ•µï¸ ConvirtiÃ©ndonos en Detectives de Datos
# 
# Cada predicciÃ³n incorrecta es como una escena del crimen que debemos investigar. **Â¿Por quÃ© fallÃ³ nuestro modelo?** Â¿Fue mala suerte, informaciÃ³n insuficiente, o hay patrones sistemÃ¡ticos en nuestros errores?
# 
# ### ğŸ­ Los Cuatro Tipos de Drama
# 
# En el teatro del Machine Learning, hay cuatro tipos de drama:
# - **True Positives**: Las victorias bien predichas (Â¡Ã©xito!)
# - **True Negatives**: Las derrotas bien predichas (Â¡tambiÃ©n Ã©xito!)
# - **False Positives**: Predijimos victoria pero hubo derrota (Â¡optimismo excesivo!)
# - **False Negatives**: Predijimos derrota pero hubo victoria (Â¡pesimismo injustificado!)
# 
# ### ğŸŒŠ La Zona de Incertidumbre
# 
# Hay batallas que son genuinamente difÃ­ciles de predecir - aquellas donde nuestro modelo dice "no estoy seguro" (probabilidades cerca de 0.5). **Â¿QuÃ© hace que estas batallas sean tan impredecibles?** Â¿Son genuinamente aleatorias o hay patrones sutiles que aÃºn no capturamos?
# 
# ### ğŸ”¬ AnatomÃ­a de un Error
# 
# Vamos a diseccionar nuestros errores como cientÃ­ficos forenses:
# - **Â¿En quÃ© caracterÃ­sticas difieren los casos mal clasificados?**
# - **Â¿Hay patrones en las probabilidades de predicciÃ³n?**
# - **Â¿Algunos tipos de batalla son mÃ¡s difÃ­ciles que otros?**
# 
# **Â¿QuÃ© secretos revelarÃ¡n nuestros errores?** A veces, los fracasos enseÃ±an mÃ¡s que los Ã©xitosâ€¦

# %%
# AnÃ¡lisis de errores
all_results = {**results, **optimized_results}
error_analysis = trainer.analyze_prediction_errors(all_results, X_test, y_test, feature_names)

# %% [markdown]
# ## ğŸ“Š El Momento de la Verdad: Â¿Hemos Hecho Historia?
# 
# **SeÃ±oras y seÃ±ores, el momento que todos hemos estado esperando ha llegado.** DespuÃ©s de horas de entrenamiento, optimizaciÃ³n y anÃ¡lisis, es hora de responder la pregunta fundamental:
# 
# ### ğŸ¯ Â¿Hemos Superado lo Imposible?
# 
# Nuestro baseline de **ROC-AUC 0.837** ha sido nuestro dragÃ³n final desde el principio. Un nÃºmero que parecÃ­a formidable, casi inalcanzable. Pero hemos reunido el mejor arsenal de Machine Learning disponible y lo hemos lanzado contra este desafÃ­o.
# 
# ### ğŸ† El Podio de Campeones
# 
# Como en cualquier competencia Ã©pica, vamos a coronar a nuestros campeones:
# - **ğŸ¥‡ Medalla de Oro**: El modelo supremo que reinarÃ¡ sobre todos
# - **ğŸ¥ˆ Medalla de Plata**: El digno segundo lugar
# - **ğŸ¥‰ Medalla de Bronce**: El tercer puesto honorable
# 
# ### ğŸ“ˆ La Historia en NÃºmeros
# 
# Pero esto no es solo sobre ganar o perder. Es sobre **cuÃ¡nto hemos mejorado**. Â¿Fue una mejora marginal del 1%? Â¿O logramos un salto cuÃ¡ntico del 10% o mÃ¡s?
# 
# ### ğŸ­ El Drama del Resultado
# 
# **Â¿CuÃ¡l serÃ¡ el veredicto final?** Â¿Celebraremos una victoria aplastante sobre el baseline? Â¿O descubriremos que el baseline era mÃ¡s formidable de lo que pensÃ¡bamos?
# 
# **Â¿HabrÃ¡ sorpresas?** Â¿AlgÃºn modelo underdog que nadie esperaba se alzarÃ¡ como campeÃ³n? Â¿O el favorito cumplirÃ¡ las expectativas?
# 
# **El suspenso estÃ¡ matando... Â¡Veamos los resultados!**

# %%
# Reporte final
print("\n" + "="*80)
print("ğŸ† REPORTE FINAL - POKEMON BATTLE AI ML TRAINING")
print("="*80)

baseline_auc = 0.837
print(f"\nğŸ“Š BASELINE ROC-AUC: {baseline_auc:.4f}")
print(f"ğŸ¯ MEJOR MODELO: {trainer.best_model}")
print(f"ğŸ† MEJOR ROC-AUC: {trainer.best_score:.4f}")

improvement = ((trainer.best_score - baseline_auc) / baseline_auc) * 100
if trainer.best_score > baseline_auc:
    print(f"âœ… MEJORA: +{improvement:.2f}% sobre baseline")
else:
    print(f"âŒ RENDIMIENTO: {improvement:.2f}% respecto al baseline")

print(f"\nğŸ“ˆ RESUMEN DE TODOS LOS MODELOS:")
print("-" * 60)

# Combinar todos los resultados
all_model_scores = []

# Modelos base
for name, result in results.items():
    all_model_scores.append((name, result['metrics']['roc_auc'], result['metrics']['mcc']))

# Modelos optimizados
for name, result in optimized_results.items():
    all_model_scores.append((name, result['metrics']['roc_auc'], result['metrics']['mcc']))

# Ordenar por ROC-AUC
all_model_scores.sort(key=lambda x: x[1], reverse=True)

for i, (name, auc, mcc) in enumerate(all_model_scores, 1):
    status = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "  "
    vs_baseline = "âœ…" if auc > baseline_auc else "âŒ"
    print(f"{status} {name:25} | ROC-AUC: {auc:.4f} | MCC: {mcc:.4f} | {vs_baseline}")

print("\n" + "="*80)

# %% [markdown]
# ### ğŸ’¾ Preservando la Historia: El Legado de Nuestros Campeones
# 
# Como arqueÃ³logos del futuro, debemos preservar cuidadosamente nuestros descubrimientos. El modelo campeÃ³n que hemos creado no es solo cÃ³digo - es **historia en el making**, el resultado de un viaje Ã©pico de descubrimiento y optimizaciÃ³n.
# 
# ### ğŸ›ï¸ El Museo de Nuestros Logros
# 
# Vamos a crear un "museo digital" completo de nuestro proyecto:
# - **El Modelo CampeÃ³n**: Serializado y listo para la posteridad
# - **Los Resultados Completos**: Cada mÃ©trica, cada comparaciÃ³n, cada insight
# - **El Scaler**: Si nuestro campeÃ³n lo necesita, tambiÃ©n lo preservamos
# - **Los Metadatos**: La fecha, las condiciones, el contexto completo
# 
# ### ğŸ“œ El Pergamino de los Resultados
# 
# Nuestro archivo JSON serÃ¡ como un pergamino antiguo que cuenta la historia completa:
# - Â¿QuiÃ©n fue el campeÃ³n?
# - Â¿CuÃ¡l fue su puntuaciÃ³n final?
# - Â¿CuÃ¡nto mejorÃ³ sobre el baseline?
# - Â¿CuÃ¡les fueron las caracterÃ­sticas mÃ¡s importantes?
# - Â¿CuÃ¡ndo ocurriÃ³ este momento histÃ³rico?
# 
# ### ğŸš€ Listo para la ProducciÃ³n
# 
# Este no es el final de nuestro viaje - es el **comienzo de una nueva era**. Nuestro modelo campeÃ³n estÃ¡ listo para:
# - Predecir batallas Pokemon en tiempo real
# - Ayudar a entrenadores a tomar mejores decisiones
# - Revelar patrones ocultos en el mundo competitivo Pokemon
# 
# **Â¡La historia ha sido escrita, el legado estÃ¡ asegurado!**

# %%
# Crear directorio de salida - detectar entorno
if IS_KAGGLE:
    output_dir = Path(f"{WORKING_DIR}/models/trained")
else:
    output_dir = Path("../models/trained")

output_dir.mkdir(parents=True, exist_ok=True)

# Guardar mejor modelo
if trainer.best_model in all_results:
    best_model_obj = all_results[trainer.best_model]['model']
    
    # Guardar modelo
    model_path = output_dir / f"best_model_{trainer.best_model}.pkl"
    with open(model_path, 'wb') as f:
        pickle.dump(best_model_obj, f)
    
    # Guardar scaler si es necesario
    if trainer.best_model in ['neural_network', 'svm', 'logistic_regression']:
        scaler_path = output_dir / f"scaler_{trainer.best_model}.pkl"
        with open(scaler_path, 'wb') as f:
            pickle.dump(trainer.scaler, f)
    
    print(f"âœ… Mejor modelo guardado: {model_path}")

# Guardar resultados completos
results_data = {
    'best_model': trainer.best_model,
    'best_score': trainer.best_score,
    'baseline_auc': baseline_auc,
    'improvement': improvement,
    'feature_names': feature_names,
    'model_scores': all_model_scores,
    'training_date': datetime.now().isoformat()
}

results_path = output_dir / "training_results.json"
with open(results_path, 'w') as f:
    json.dump(results_data, f, indent=2)

print(f"âœ… Resultados guardados: {results_path}")

# Generar Ã­ndice de grÃ¡ficos para documentaciÃ³n tÃ©cnica
trainer.generate_plots_index()

print("\nğŸ‰ Â¡Entrenamiento completado exitosamente!")
print("ğŸš€ El modelo estÃ¡ listo para hacer predicciones en batallas Pokemon!")
print("ğŸ“Š Todos los grÃ¡ficos han sido exportados para documentaciÃ³n tÃ©cnica")

# Mostrar resumen de archivos generados
print(f"\nğŸ“ ARCHIVOS GENERADOS EN {output_dir.parent}:")
print("-" * 50)

# Listar archivos de modelos
if output_dir.exists():
    model_files = list(output_dir.glob("*"))
    if model_files:
        print("ğŸ¤– MODELOS:")
        for file in model_files:
            print(f"   ğŸ“„ {file.name}")
    else:
        print("âš ï¸  No se encontraron archivos de modelos")

# Listar archivos de grÃ¡ficos
if IS_KAGGLE:
    plots_dir = Path(f"{WORKING_DIR}/plots")
else:
    plots_dir = Path("../plots")

if plots_dir.exists():
    plot_files = list(plots_dir.glob("*.png"))
    if plot_files:
        print("\nğŸ“Š GRÃFICOS:")
        for file in plot_files:
            print(f"   ğŸ–¼ï¸  {file.name}")
    
    # Mostrar README de plots si existe
    readme_plots = plots_dir / "README_PLOTS.md"
    if readme_plots.exists():
        print(f"   ğŸ“‹ README_PLOTS.md")
else:
    print("âš ï¸  No se encontraron archivos de grÃ¡ficos")

print(f"\nğŸŒ Entorno: {'Kaggle' if IS_KAGGLE else 'Local'}")
print(f"ğŸ“‚ Directorio base: {WORKING_DIR}")
