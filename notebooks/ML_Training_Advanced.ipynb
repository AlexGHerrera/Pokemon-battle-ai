{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57628de1",
   "metadata": {},
   "source": [
    "# ü§ñ Pokemon Battle AI - La B√∫squeda del Modelo Definitivo\n",
    "\n",
    "En el mundo de las batallas Pokemon, cada decisi√≥n cuenta. Cada movimiento, cada cambio, cada estrategia puede determinar la diferencia entre la victoria y la derrota. Nuestro viaje hasta ahora nos ha llevado desde el an√°lisis exploratorio hasta un baseline s√≥lido con **ROC-AUC de 0.837**.\n",
    "\n",
    "Pero sabemos que podemos hacer mejor. Mucho mejor.\n",
    "\n",
    "## üéØ La Misi√≥n: Superar lo Imposible\n",
    "\n",
    "Hoy emprendemos la fase m√°s emocionante de nuestro proyecto: **crear el modelo de Machine Learning m√°s avanzado** para predecir batallas Pokemon. No nos conformamos con modelos simples; vamos a desplegar un arsenal completo de algoritmos de √∫ltima generaci√≥n.\n",
    "\n",
    "### üó∫Ô∏è Nuestro Plan de Batalla\n",
    "\n",
    "Como entrenadores Pokemon experimentados, sabemos que la preparaci√≥n es clave. Nuestro plan de entrenamiento seguir√° una estrategia meticulosa:\n",
    "\n",
    "**üîß Fase 1: Preparaci√≥n del Campo de Batalla**\n",
    "- Refinamiento de caracter√≠sticas basado en insights del EDA\n",
    "- Ingenier√≠a de features que capturen la esencia de cada batalla\n",
    "- Selecci√≥n inteligente de variables predictivas\n",
    "\n",
    "**‚öîÔ∏è Fase 2: Despliegue del Arsenal Base**\n",
    "- Logistic Regression: La elegancia de la simplicidad\n",
    "- Random Forest: El poder de la sabidur√≠a colectiva\n",
    "- SVM: La precisi√≥n matem√°tica en acci√≥n\n",
    "\n",
    "**üöÄ Fase 3: Armas de Destrucci√≥n Masiva**\n",
    "- XGBoost: El campe√≥n de Kaggle\n",
    "- LightGBM: Velocidad y precisi√≥n combinadas\n",
    "- Neural Networks: La inteligencia artificial pura\n",
    "\n",
    "**‚öôÔ∏è Fase 4: Perfeccionamiento T√°ctico**\n",
    "- Hyperparameter tuning con b√∫squeda inteligente\n",
    "- Cross-validation para robustez m√°xima\n",
    "- An√°lisis profundo de curvas de aprendizaje\n",
    "\n",
    "**ü§ù Fase 5: La Uni√≥n Hace la Fuerza**\n",
    "- Ensemble de los mejores modelos\n",
    "- Voting strategies para decisiones consensuadas\n",
    "- Meta-learning para superar l√≠mites individuales\n",
    "\n",
    "**üèÜ Fase 6: El Momento de la Verdad**\n",
    "- Evaluaci√≥n exhaustiva contra el baseline\n",
    "- An√°lisis de errores y casos l√≠mite\n",
    "- Selecci√≥n del modelo campe√≥n\n",
    "\n",
    "¬øLograremos superar el **ROC-AUC de 0.837**? ¬øCu√°nto podremos mejorar? El viaje comienza ahora..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6221b2",
   "metadata": {},
   "source": [
    "## üì¶ Armando Nuestro Arsenal: Las Herramientas del Maestro\n",
    "\n",
    "Como cualquier entrenador Pokemon sabe, tener las herramientas adecuadas es fundamental para el √©xito. En nuestro laboratorio de Machine Learning, cada librer√≠a es como un Pokemon especializado, cada una con sus propias habilidades √∫nicas.\n",
    "\n",
    "Vamos a importar nuestro equipo completo:\n",
    "- **Pandas & NumPy**: Nuestros Pikachu y Charizard, confiables y poderosos para manipulaci√≥n de datos\n",
    "- **Scikit-learn**: El Mew de ML, vers√°til y con acceso a casi cualquier algoritmo\n",
    "- **XGBoost & LightGBM**: Los legendarios Rayquaza y Kyogre del gradient boosting\n",
    "- **Matplotlib & Seaborn**: Nuestros artistas Smeargle, creando visualizaciones que cuentan historias\n",
    "\n",
    "Cada importaci√≥n nos acerca m√°s a nuestro objetivo: crear el modelo m√°s poderoso jam√°s visto en batallas Pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c43757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as b√°sicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, GridSearchCV, \n",
    "    StratifiedKFold, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, precision_score, recall_score, \n",
    "    f1_score, classification_report, confusion_matrix, roc_curve, auc\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE, SelectFromModel\n",
    "\n",
    "# Modelos avanzados\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Utilidades\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Colores Pokemon\n",
    "POKEMON_COLORS = {\n",
    "    'fire': '#FF6B35',\n",
    "    'water': '#4A90E2', \n",
    "    'grass': '#7ED321',\n",
    "    'electric': '#F5A623',\n",
    "    'psychic': '#BD10E0',\n",
    "    'ice': '#50E3C2',\n",
    "    'dragon': '#9013FE',\n",
    "    'dark': '#4A4A4A',\n",
    "    'fighting': '#D0021B',\n",
    "    'poison': '#B8E986'\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86051626",
   "metadata": {},
   "source": [
    "## üìä El Despertar de los Datos: Liberando el Arsenal Completo\n",
    "\n",
    "Cada dataset cuenta una historia, y el nuestro es **absolutamente √©pico**. Hemos pasado del entrenamiento con una muestra a desatar **TODO EL PODER** de nuestro arsenal de datos completo. Ya no son solo 2000 batallas - ahora tenemos acceso a **TODAS las batallas Pokemon disponibles**.\n",
    "\n",
    "Imagina por un momento: **Miles y miles de enfrentamientos √∫nicos**, decenas de miles de decisiones cr√≠ticas, cientos de Pokemon diferentes luchando por la gloria en una escala nunca antes vista. Desde batallas r√°pidas y decisivas hasta maratones √©picos, tenemos la biblioteca completa de la experiencia competitiva Pokemon.\n",
    "\n",
    "### üé≠ Los Protagonistas de Nuestra Historia\n",
    "\n",
    "Nuestros datos no son simples n√∫meros; son las memorias digitales de entrenadores que:\n",
    "- Tomaron decisiones bajo presi√≥n\n",
    "- Ejecutaron estrategias complejas\n",
    "- Experimentaron la emoci√≥n de la victoria y la amargura de la derrota\n",
    "\n",
    "Cada log de batalla es como un pergamino antiguo que debemos descifrar. Cada evento registrado - cada movimiento, cada cambio, cada momento cr√≠tico - contiene pistas sobre qu√© hace que un entrenador triunfe sobre otro.\n",
    "\n",
    "**¬øQu√© secretos revelar√°n estos datos a escala masiva?** Con este arsenal completo de batallas, nuestros modelos tendr√°n acceso a patrones que solo emergen con grandes vol√∫menes de datos. ¬øDescubriremos estrategias meta que solo son visibles con miles de batallas? ¬øEncontraremos correlaciones sutiles que se perd√≠an en muestras m√°s peque√±as?\n",
    "\n",
    "**¬°La aventura de entrenar con el dataset completo comienza ahora!** üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17a581",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Cargar datos completos para entrenamiento\n",
    "try:\n",
    "    # En Kaggle, ajustar la ruta seg√∫n sea necesario\n",
    "    data_path = \"/kaggle/input/pokemon-battles/all_battles.json\"\n",
    "    \n",
    "    # Cargar datos JSON\n",
    "    with open(data_path, 'r') as f:\n",
    "        battles_data = json.load(f)\n",
    "    \n",
    "    print(f\"‚úÖ Datos completos cargados: {len(battles_data)} batallas\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    # Ruta local para desarrollo - usar dataset completo\n",
    "    data_path = \"../data/all_battles.json\"\n",
    "    with open(data_path, 'r') as f:\n",
    "        battles_data = json.load(f)\n",
    "    print(f\"‚úÖ Dataset completo cargado localmente: {len(battles_data)} batallas\")\n",
    "    print(f\"üöÄ ¬°Ahora entrenamos con TODAS las batallas disponibles!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e6866c",
   "metadata": {},
   "source": [
    "### üîß La Alquimia de los Datos: Transformando Batallas en Sabidur√≠a\n",
    "\n",
    "Ahora viene la parte m√°s art√≠stica de nuestro proceso: la **ingenier√≠a de caracter√≠sticas**. Como un alquimista medieval transformando metales comunes en oro, vamos a convertir logs de batalla crudos en features predictivas poderosas.\n",
    "\n",
    "### üß¨ Decodificando el ADN de una Batalla\n",
    "\n",
    "Cada batalla Pokemon tiene su propio \"ADN\" - una secuencia √∫nica de eventos que la define. Nuestro trabajo es extraer la esencia de este ADN y convertirla en n√∫meros que nuestros algoritmos puedan entender.\n",
    "\n",
    "**¬øQu√© hace que una batalla sea √∫nica?**\n",
    "- **Intensidad**: ¬øFue una batalla r√°pida y brutal o un duelo prolongado de resistencia?\n",
    "- **Complejidad**: ¬øCu√°ntos cambios estrat√©gicos hubo? ¬øQu√© tan din√°mica fue?\n",
    "- **Agresividad**: ¬øLos entrenadores fueron directos o cautelosos?\n",
    "- **Adaptabilidad**: ¬øQu√© tan bien respondieron a las situaciones cambiantes?\n",
    "\n",
    "### üéØ Las M√©tricas que Importan\n",
    "\n",
    "Bas√°ndonos en nuestro an√°lisis exploratorio previo, sabemos que ciertas m√©tricas son cruciales:\n",
    "- **Eventos de movimiento**: El coraz√≥n de cada batalla\n",
    "- **Ratios de da√±o**: La eficiencia ofensiva\n",
    "- **Patrones de cambio**: La flexibilidad t√°ctica\n",
    "- **Duraci√≥n e intensidad**: El ritmo de la batalla\n",
    "\n",
    "Cada feature que extraemos es como capturar la esencia de miles de decisiones estrat√©gicas. ¬øLograremos capturar los patrones que separan a los maestros de los novatos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_battle_features(battles_data):\n",
    "    \"\"\"\n",
    "    Extrae caracter√≠sticas num√©ricas de las batallas para ML.\n",
    "    Basado en los hallazgos del EDA previo.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    \n",
    "    for battle in battles_data:\n",
    "        try:\n",
    "            # Informaci√≥n b√°sica de la batalla\n",
    "            features = {\n",
    "                'battle_id': battle.get('id', ''),\n",
    "                'format': battle.get('format', ''),\n",
    "                'turns': len(battle.get('log', [])),\n",
    "                'winner': battle.get('winner', 'unknown')\n",
    "            }\n",
    "            \n",
    "            # Procesar eventos de la batalla\n",
    "            events = []\n",
    "            for log_entry in battle.get('log', []):\n",
    "                if isinstance(log_entry, str):\n",
    "                    events.append(log_entry)\n",
    "            \n",
    "            # M√©tricas de eventos\n",
    "            features['total_events'] = len(events)\n",
    "            features['switch_events'] = sum(1 for event in events if 'switch' in event.lower())\n",
    "            features['move_events'] = sum(1 for event in events if 'move' in event.lower())\n",
    "            features['damage_events'] = sum(1 for event in events if 'damage' in event.lower())\n",
    "            features['heal_events'] = sum(1 for event in events if 'heal' in event.lower())\n",
    "            features['faint_events'] = sum(1 for event in events if 'faint' in event.lower())\n",
    "            \n",
    "            # Ratios importantes\n",
    "            if features['total_events'] > 0:\n",
    "                features['switch_ratio'] = features['switch_events'] / features['total_events']\n",
    "                features['move_ratio'] = features['move_events'] / features['total_events']\n",
    "                features['damage_ratio'] = features['damage_events'] / features['total_events']\n",
    "            else:\n",
    "                features['switch_ratio'] = 0\n",
    "                features['move_ratio'] = 0\n",
    "                features['damage_ratio'] = 0\n",
    "            \n",
    "            # Informaci√≥n de equipos (si est√° disponible)\n",
    "            p1_team = battle.get('p1team', [])\n",
    "            p2_team = battle.get('p2team', [])\n",
    "            \n",
    "            features['p1_team_size'] = len(p1_team) if p1_team else 6\n",
    "            features['p2_team_size'] = len(p2_team) if p2_team else 6\n",
    "            \n",
    "            # M√©tricas de duraci√≥n\n",
    "            features['events_per_turn'] = features['total_events'] / max(features['turns'], 1)\n",
    "            features['battle_intensity'] = (features['damage_events'] + features['faint_events']) / max(features['turns'], 1)\n",
    "            \n",
    "            features_list.append(features)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando batalla: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "# Extraer caracter√≠sticas\n",
    "print(\"üîß Extrayendo caracter√≠sticas de las batallas...\")\n",
    "df_features = extract_battle_features(battles_data)\n",
    "\n",
    "# Codificar variables categ√≥ricas\n",
    "label_encoders = {}\n",
    "categorical_cols = ['format', 'winner']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df_features.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_features[f'{col}_encoded'] = le.fit_transform(df_features[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "print(f\"‚úÖ Caracter√≠sticas extra√≠das: {df_features.shape}\")\n",
    "print(f\"üìä Columnas: {list(df_features.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060e1020",
   "metadata": {},
   "source": [
    "### üìà El Primer Vistazo: ¬øQu√© Nos Susurran los Datos?\n",
    "\n",
    "Antes de lanzarnos a entrenar modelos complejos, necesitamos escuchar lo que nuestros datos tienen que decirnos. Como un entrenador Pokemon experimentado que observa el campo antes de la batalla, vamos a hacer un reconocimiento r√°pido pero crucial.\n",
    "\n",
    "### üé≤ El Equilibrio del Universo Pokemon\n",
    "\n",
    "Una pregunta fundamental: **¬øNuestros datos est√°n balanceados?** En el mundo real de las batallas Pokemon, ¬øhay un sesgo hacia alg√∫n tipo de ganador? ¬øO vivimos en un universo perfectamente equilibrado donde la habilidad es el √∫nico factor determinante?\n",
    "\n",
    "### üîç Los Primeros Indicios del √âxito\n",
    "\n",
    "Tambi√©n vamos a echar un vistazo a las correlaciones iniciales. ¬øQu√© caracter√≠sticas muestran las primeras se√±ales de ser predictivas? Es como observar las primeras cartas en una partida de poker - no nos dice todo, pero nos da pistas valiosas sobre qu√© esperar.\n",
    "\n",
    "**¬øQu√© patrones emerger√°n?** ¬øConfirmar√°n nuestras hip√≥tesis del EDA o nos sorprender√°n con revelaciones inesperadas? Los n√∫meros est√°n a punto de hablar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c9300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar distribuci√≥n del target\n",
    "if 'winner_encoded' in df_features.columns:\n",
    "    winner_dist = df_features['winner_encoded'].value_counts()\n",
    "    print(\"Distribuci√≥n del ganador:\")\n",
    "    print(winner_dist)\n",
    "    \n",
    "    # Visualizar distribuci√≥n\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    winner_dist.plot(kind='bar', color=[POKEMON_COLORS['fire'], POKEMON_COLORS['water']], alpha=0.8)\n",
    "    plt.title('Distribuci√≥n de Ganadores', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Ganador Codificado')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.xticks(rotation=0)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    # Correlaciones importantes\n",
    "    numeric_cols = df_features.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr_with_target = df_features[numeric_cols].corr()['winner_encoded'].abs().sort_values(ascending=False)\n",
    "        top_corr = corr_with_target.head(8)\n",
    "        \n",
    "        top_corr.plot(kind='barh', color=POKEMON_COLORS['electric'], alpha=0.8)\n",
    "        plt.title('Top Correlaciones con Ganador', fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Correlaci√≥n Absoluta')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b5b26",
   "metadata": {},
   "source": [
    "## ü§ñ El Laboratorio del Dr. Frankenstein: Creando Nuestros Monstruos de ML\n",
    "\n",
    "Ha llegado el momento m√°s emocionante: **crear nuestros modelos de Machine Learning**. Como el Dr. Frankenstein en su laboratorio, vamos a dar vida a siete criaturas diferentes, cada una con sus propias fortalezas, debilidades y personalidades √∫nicas.\n",
    "\n",
    "### üß™ La Clase PokemonMLTrainer: Nuestro Laboratorio Personal\n",
    "\n",
    "Hemos dise√±ado una clase especial que actuar√° como nuestro laboratorio de experimentaci√≥n. Esta no es una clase ordinaria; es un **centro de comando avanzado** que:\n",
    "\n",
    "- **Gestiona m√∫ltiples experimentos simult√°neamente**\n",
    "- **Eval√∫a el rendimiento con m√©tricas sofisticadas**\n",
    "- **Genera visualizaciones que cuentan historias**\n",
    "- **Optimiza autom√°ticamente los hiperpar√°metros**\n",
    "- **Crea ensembles inteligentes**\n",
    "- **Analiza errores como un detective**\n",
    "\n",
    "### üé≠ Conoce a Nuestros Siete Gladiadores\n",
    "\n",
    "Cada modelo que vamos a entrenar tiene su propia \"personalidad\" y enfoque para resolver el problema:\n",
    "\n",
    "**üéØ Logistic Regression**: El estratega cl√°sico, elegante y directo\n",
    "**üå≥ Random Forest**: El consejo de ancianos, sabidur√≠a colectiva\n",
    "**‚ö° Gradient Boosting**: El perfeccionista, aprende de cada error\n",
    "**üöÄ XGBoost**: El campe√≥n de competencias, optimizado para ganar\n",
    "**üí® LightGBM**: El velocista inteligente, r√°pido pero preciso\n",
    "**üß† Neural Network**: El cerebro artificial, patrones complejos\n",
    "**‚öîÔ∏è SVM**: El matem√°tico puro, fronteras de decisi√≥n perfectas\n",
    "\n",
    "**¬øCu√°l de estos gladiadores se alzar√° como campe√≥n?** ¬øO ser√° que la verdadera magia ocurre cuando trabajen juntos? El torneo est√° a punto de comenzar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e113394",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Importar librer√≠as adicionales para an√°lisis avanzado\n",
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "import shap\n",
    "from scipy import stats\n",
    "\n",
    "class PokemonMLTrainer:\n",
    "    \"\"\"Entrenador avanzado de Machine Learning para batallas Pokemon.\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.models = {}\n",
    "        self.results = {}\n",
    "        self.best_model = None\n",
    "        self.best_score = 0.0\n",
    "        self.scaler = StandardScaler()\n",
    "        self.learning_curves = {}\n",
    "        self.roc_curves = {}\n",
    "        \n",
    "    def setup_models(self):\n",
    "        \"\"\"Configura todos los modelos a entrenar.\"\"\"\n",
    "        models = {\n",
    "            'logistic_regression': LogisticRegression(\n",
    "                random_state=self.random_state,\n",
    "                max_iter=1000,\n",
    "                class_weight='balanced'\n",
    "            ),\n",
    "            \n",
    "            'random_forest': RandomForestClassifier(\n",
    "                n_estimators=200,\n",
    "                max_depth=15,\n",
    "                min_samples_split=5,\n",
    "                min_samples_leaf=2,\n",
    "                random_state=self.random_state,\n",
    "                class_weight='balanced',\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            \n",
    "            'gradient_boosting': GradientBoostingClassifier(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                random_state=self.random_state\n",
    "            ),\n",
    "            \n",
    "            'xgboost': xgb.XGBClassifier(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                random_state=self.random_state,\n",
    "                eval_metric='logloss',\n",
    "                use_label_encoder=False\n",
    "            ),\n",
    "            \n",
    "            'lightgbm': lgb.LGBMClassifier(\n",
    "                n_estimators=200,\n",
    "                learning_rate=0.1,\n",
    "                max_depth=6,\n",
    "                random_state=self.random_state,\n",
    "                verbose=-1\n",
    "            ),\n",
    "            \n",
    "            'neural_network': MLPClassifier(\n",
    "                hidden_layer_sizes=(256, 128, 64),\n",
    "                activation='relu',\n",
    "                solver='adam',\n",
    "                learning_rate_init=0.001,\n",
    "                max_iter=500,\n",
    "                random_state=self.random_state,\n",
    "                early_stopping=True,\n",
    "                validation_fraction=0.1\n",
    "            ),\n",
    "            \n",
    "            'svm': SVC(\n",
    "                kernel='rbf',\n",
    "                probability=True,\n",
    "                random_state=self.random_state,\n",
    "                class_weight='balanced'\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        return models\n",
    "    \n",
    "    def prepare_data(self, df, target_col='winner_encoded', test_size=0.2):\n",
    "        \"\"\"Prepara los datos para entrenamiento.\"\"\"\n",
    "        # Seleccionar caracter√≠sticas num√©ricas\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        if target_col in numeric_cols:\n",
    "            numeric_cols.remove(target_col)\n",
    "        \n",
    "        # Remover columnas no √∫tiles\n",
    "        exclude_cols = ['battle_id']\n",
    "        numeric_cols = [col for col in numeric_cols if col not in exclude_cols]\n",
    "        \n",
    "        X = df[numeric_cols].copy()\n",
    "        y = df[target_col].copy()\n",
    "        \n",
    "        # Manejar valores faltantes\n",
    "        X = X.fillna(X.median())\n",
    "        \n",
    "        # Divisi√≥n de datos\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=self.random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test, numeric_cols\n",
    "    \n",
    "    def calculate_advanced_metrics(self, y_true, y_pred, y_pred_proba, model_name):\n",
    "        \"\"\"Calcula m√©tricas avanzadas espec√≠ficas por tipo de modelo.\"\"\"\n",
    "        \n",
    "        # M√©tricas b√°sicas\n",
    "        basic_metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, average='weighted'),\n",
    "            'recall': recall_score(y_true, y_pred, average='weighted'),\n",
    "            'f1': f1_score(y_true, y_pred, average='weighted'),\n",
    "            'roc_auc': roc_auc_score(y_true, y_pred_proba)\n",
    "        }\n",
    "        \n",
    "        # M√©tricas avanzadas\n",
    "        advanced_metrics = {}\n",
    "        \n",
    "        # Brier Score (calibraci√≥n de probabilidades)\n",
    "        from sklearn.metrics import brier_score_loss\n",
    "        advanced_metrics['brier_score'] = brier_score_loss(y_true, y_pred_proba)\n",
    "        \n",
    "        # Log Loss\n",
    "        from sklearn.metrics import log_loss\n",
    "        try:\n",
    "            advanced_metrics['log_loss'] = log_loss(y_true, y_pred_proba)\n",
    "        except:\n",
    "            advanced_metrics['log_loss'] = np.nan\n",
    "        \n",
    "        # Matthews Correlation Coefficient\n",
    "        from sklearn.metrics import matthews_corrcoef\n",
    "        advanced_metrics['mcc'] = matthews_corrcoef(y_true, y_pred)\n",
    "        \n",
    "        # Balanced Accuracy\n",
    "        from sklearn.metrics import balanced_accuracy_score\n",
    "        advanced_metrics['balanced_accuracy'] = balanced_accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        # M√©tricas espec√≠ficas por clase\n",
    "        precision_per_class = precision_score(y_true, y_pred, average=None)\n",
    "        recall_per_class = recall_score(y_true, y_pred, average=None)\n",
    "        \n",
    "        advanced_metrics['precision_class_0'] = precision_per_class[0] if len(precision_per_class) > 0 else 0\n",
    "        advanced_metrics['precision_class_1'] = precision_per_class[1] if len(precision_per_class) > 1 else 0\n",
    "        advanced_metrics['recall_class_0'] = recall_per_class[0] if len(recall_per_class) > 0 else 0\n",
    "        advanced_metrics['recall_class_1'] = recall_per_class[1] if len(recall_per_class) > 1 else 0\n",
    "        \n",
    "        # Combinar m√©tricas\n",
    "        all_metrics = {**basic_metrics, **advanced_metrics}\n",
    "        \n",
    "        return all_metrics\n",
    "    \n",
    "    def plot_learning_curves(self, model, X, y, model_name, cv=5):\n",
    "        \"\"\"Genera curvas de aprendizaje para un modelo.\"\"\"\n",
    "        \n",
    "        train_sizes, train_scores, val_scores = learning_curve(\n",
    "            model, X, y, cv=cv, n_jobs=-1, \n",
    "            train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "            scoring='roc_auc', random_state=self.random_state\n",
    "        )\n",
    "        \n",
    "        # Calcular medias y desviaciones est√°ndar\n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        val_mean = np.mean(val_scores, axis=1)\n",
    "        val_std = np.std(val_scores, axis=1)\n",
    "        \n",
    "        # Guardar para an√°lisis posterior\n",
    "        self.learning_curves[model_name] = {\n",
    "            'train_sizes': train_sizes,\n",
    "            'train_mean': train_mean,\n",
    "            'train_std': train_std,\n",
    "            'val_mean': val_mean,\n",
    "            'val_std': val_std\n",
    "        }\n",
    "        \n",
    "        return train_sizes, train_mean, train_std, val_mean, val_std\n",
    "    \n",
    "    def plot_roc_curves(self, models_results, X_test, y_test):\n",
    "        \"\"\"Genera curvas ROC para todos los modelos.\"\"\"\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        colors = [POKEMON_COLORS['fire'], POKEMON_COLORS['water'], \n",
    "                 POKEMON_COLORS['grass'], POKEMON_COLORS['electric'],\n",
    "                 POKEMON_COLORS['psychic'], POKEMON_COLORS['ice'],\n",
    "                 POKEMON_COLORS['dragon']]\n",
    "        \n",
    "        for i, (model_name, result) in enumerate(models_results.items()):\n",
    "            if i >= len(colors):\n",
    "                break\n",
    "                \n",
    "            y_pred_proba = result['probabilities']\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            # Guardar curva ROC\n",
    "            self.roc_curves[model_name] = {'fpr': fpr, 'tpr': tpr, 'auc': roc_auc}\n",
    "            \n",
    "            plt.plot(fpr, tpr, color=colors[i], lw=2, alpha=0.8,\n",
    "                    label=f'{model_name} (AUC = {roc_auc:.3f})')\n",
    "        \n",
    "        # L√≠nea diagonal (clasificador aleatorio)\n",
    "        plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', alpha=0.8)\n",
    "        \n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Tasa de Falsos Positivos', fontsize=12)\n",
    "        plt.ylabel('Tasa de Verdaderos Positivos', fontsize=12)\n",
    "        plt.title('Curvas ROC - Comparaci√≥n de Modelos', fontsize=16, fontweight='bold')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # A√±adir l√≠nea de baseline\n",
    "        baseline_auc = 0.837\n",
    "        plt.axhline(y=baseline_auc, color='red', linestyle=':', alpha=0.7, \n",
    "                   label=f'Baseline AUC = {baseline_auc}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_precision_recall_curves(self, models_results, X_test, y_test):\n",
    "        \"\"\"Genera curvas Precision-Recall para todos los modelos.\"\"\"\n",
    "        \n",
    "        from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        colors = [POKEMON_COLORS['fire'], POKEMON_COLORS['water'], \n",
    "                 POKEMON_COLORS['grass'], POKEMON_COLORS['electric'],\n",
    "                 POKEMON_COLORS['psychic'], POKEMON_COLORS['ice'],\n",
    "                 POKEMON_COLORS['dragon']]\n",
    "        \n",
    "        for i, (model_name, result) in enumerate(models_results.items()):\n",
    "            if i >= len(colors):\n",
    "                break\n",
    "                \n",
    "            y_pred_proba = result['probabilities']\n",
    "            precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "            avg_precision = average_precision_score(y_test, y_pred_proba)\n",
    "            \n",
    "            plt.plot(recall, precision, color=colors[i], lw=2, alpha=0.8,\n",
    "                    label=f'{model_name} (AP = {avg_precision:.3f})')\n",
    "        \n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('Recall', fontsize=12)\n",
    "        plt.ylabel('Precision', fontsize=12)\n",
    "        plt.title('Curvas Precision-Recall - Comparaci√≥n de Modelos', fontsize=16, fontweight='bold')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_calibration_curves(self, models_results, X_test, y_test):\n",
    "        \"\"\"Genera curvas de calibraci√≥n para evaluar la confiabilidad de las probabilidades.\"\"\"\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        colors = [POKEMON_COLORS['fire'], POKEMON_COLORS['water'], \n",
    "                 POKEMON_COLORS['grass'], POKEMON_COLORS['electric'],\n",
    "                 POKEMON_COLORS['psychic'], POKEMON_COLORS['ice'],\n",
    "                 POKEMON_COLORS['dragon']]\n",
    "        \n",
    "        for i, (model_name, result) in enumerate(models_results.items()):\n",
    "            if i >= len(colors):\n",
    "                break\n",
    "                \n",
    "            y_pred_proba = result['probabilities']\n",
    "            fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "                y_test, y_pred_proba, n_bins=10\n",
    "            )\n",
    "            \n",
    "            plt.plot(mean_predicted_value, fraction_of_positives, \"s-\",\n",
    "                    color=colors[i], alpha=0.8, label=f'{model_name}')\n",
    "        \n",
    "        # L√≠nea de calibraci√≥n perfecta\n",
    "        plt.plot([0, 1], [0, 1], \"k:\", label=\"Calibraci√≥n perfecta\")\n",
    "        \n",
    "        plt.xlabel('Probabilidad Predicha Promedio', fontsize=12)\n",
    "        plt.ylabel('Fracci√≥n de Positivos', fontsize=12)\n",
    "        plt.title('Curvas de Calibraci√≥n - Confiabilidad de Probabilidades', fontsize=16, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def train_models(self, X_train, X_test, y_train, y_test, feature_names):\n",
    "        \"\"\"Entrena todos los modelos con an√°lisis avanzado.\"\"\"\n",
    "        print(\"üöÄ Iniciando entrenamiento de modelos con an√°lisis avanzado...\")\n",
    "        \n",
    "        # Escalado para modelos que lo necesitan\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        models = self.setup_models()\n",
    "        results = {}\n",
    "        \n",
    "        for model_name, model in models.items():\n",
    "            print(f\"\\nüîÑ Entrenando {model_name}...\")\n",
    "            \n",
    "            try:\n",
    "                # Seleccionar datos apropiados\n",
    "                if model_name in ['neural_network', 'svm', 'logistic_regression']:\n",
    "                    X_train_final = X_train_scaled\n",
    "                    X_test_final = X_test_scaled\n",
    "                else:\n",
    "                    X_train_final = X_train\n",
    "                    X_test_final = X_test\n",
    "                \n",
    "                # Entrenar modelo\n",
    "                model.fit(X_train_final, y_train)\n",
    "                \n",
    "                # Predicciones\n",
    "                y_pred = model.predict(X_test_final)\n",
    "                y_pred_proba = model.predict_proba(X_test_final)[:, 1]\n",
    "                \n",
    "                # M√©tricas avanzadas\n",
    "                metrics = self.calculate_advanced_metrics(y_test, y_pred, y_pred_proba, model_name)\n",
    "                \n",
    "                # Cross-validation\n",
    "                cv_scores = cross_val_score(\n",
    "                    model, X_train_final, y_train, \n",
    "                    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=self.random_state),\n",
    "                    scoring='roc_auc'\n",
    "                )\n",
    "                \n",
    "                metrics['cv_mean'] = cv_scores.mean()\n",
    "                metrics['cv_std'] = cv_scores.std()\n",
    "                \n",
    "                # Curvas de aprendizaje (solo para modelos r√°pidos)\n",
    "                if model_name in ['logistic_regression', 'random_forest', 'gradient_boosting']:\n",
    "                    print(f\"   üìà Generando curvas de aprendizaje para {model_name}...\")\n",
    "                    self.plot_learning_curves(model, X_train_final, y_train, model_name)\n",
    "                \n",
    "                results[model_name] = {\n",
    "                    'model': model,\n",
    "                    'metrics': metrics,\n",
    "                    'predictions': y_pred,\n",
    "                    'probabilities': y_pred_proba\n",
    "                }\n",
    "                \n",
    "                print(f\"‚úÖ {model_name} - ROC-AUC: {metrics['roc_auc']:.4f} | MCC: {metrics['mcc']:.4f} | Brier: {metrics['brier_score']:.4f}\")\n",
    "                \n",
    "                # Actualizar mejor modelo\n",
    "                if metrics['roc_auc'] > self.best_score:\n",
    "                    self.best_score = metrics['roc_auc']\n",
    "                    self.best_model = model_name\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error entrenando {model_name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        self.models = {name: result['model'] for name, result in results.items()}\n",
    "        self.results = results\n",
    "        \n",
    "        # Generar visualizaciones comparativas\n",
    "        print(\"\\nüìä Generando visualizaciones comparativas...\")\n",
    "        self.plot_roc_curves(results, X_test, y_test)\n",
    "        self.plot_precision_recall_curves(results, X_test, y_test)\n",
    "        self.plot_calibration_curves(results, X_test, y_test)\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559db79",
   "metadata": {},
   "source": [
    "## üöÄ ¬°Que Comience el Espect√°culo! El Gran Torneo de Algoritmos\n",
    "\n",
    "**Ladies and gentlemen, trainers and Pokemon masters!** Ha llegado el momento que todos est√°bamos esperando. Despu√©s de semanas de preparaci√≥n, an√°lisis y dise√±o, nuestros siete gladiadores est√°n listos para enfrentarse en la arena m√°s desafiante: **predecir el resultado de batallas Pokemon reales**.\n",
    "\n",
    "### üé™ El Escenario Est√° Preparado\n",
    "\n",
    "Nuestros datos est√°n pulidos y listos. Nuestras caracter√≠sticas han sido cuidadosamente seleccionadas y engineered. Nuestros modelos est√°n configurados con par√°metros iniciales inteligentes. Todo est√° en su lugar para el espect√°culo del siglo.\n",
    "\n",
    "### ‚ö° La Tensi√≥n en el Aire\n",
    "\n",
    "Podemos sentir la electricidad en el ambiente. Cada algoritmo \"sabe\" que est√° compitiendo no solo contra los datos, sino contra otros seis competidores igualmente determinados. El baseline de **ROC-AUC 0.837** se alza como el drag√≥n final que todos deben derrotar.\n",
    "\n",
    "**¬øQui√©n ser√° el primero en caer?** ¬øQu√© modelo sorprender√° con un rendimiento inesperado? ¬øVeremos una batalla re√±ida o habr√° un claro dominador desde el principio?\n",
    "\n",
    "La preparaci√≥n ha terminado. Los dados est√°n echados. **¬°Que comience la batalla!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d7ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar entrenador\n",
    "trainer = PokemonMLTrainer(random_state=42)\n",
    "print(\"‚úÖ Entrenador ML avanzado inicializado\")\n",
    "print(\"üöÄ ¬°Listo para comenzar el entrenamiento!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d982fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos\n",
    "print(\"üìä Preparando datos para entrenamiento...\")\n",
    "X_train, X_test, y_train, y_test, feature_names = trainer.prepare_data(df_features)\n",
    "\n",
    "print(f\"‚úÖ Datos preparados:\")\n",
    "print(f\"   - Entrenamiento: {X_train.shape}\")\n",
    "print(f\"   - Prueba: {X_test.shape}\")\n",
    "print(f\"   - Caracter√≠sticas: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117de575",
   "metadata": {},
   "source": [
    "### ü§ñ Round 1: Los Gladiadores Entran en Acci√≥n\n",
    "\n",
    "**¬°DING DING DING!** Suena la campana y nuestros siete gladiadores saltan al ring. Este es el momento de la verdad - despu√©s de toda la preparaci√≥n, finalmente veremos de qu√© est√°n hechos nuestros modelos.\n",
    "\n",
    "### üé≠ El Drama se Desarrolla\n",
    "\n",
    "Cada modelo aborda el problema desde su perspectiva √∫nica:\n",
    "- **Logistic Regression** entra con confianza cl√°sica, buscando relaciones lineales claras\n",
    "- **Random Forest** despliega su ej√©rcito de √°rboles, cada uno votando por su predicci√≥n favorita\n",
    "- **Gradient Boosting** comienza lentamente, aprendiendo meticulosamente de cada error\n",
    "- **XGBoost** llega con toda la experiencia de miles de competencias de Kaggle\n",
    "- **LightGBM** se mueve con agilidad felina, optimizando cada c√°lculo\n",
    "- **Neural Network** activa sus neuronas, buscando patrones que otros no pueden ver\n",
    "- **SVM** traza fronteras de decisi√≥n con precisi√≥n matem√°tica\n",
    "\n",
    "### üìä Las M√©tricas Que Importan\n",
    "\n",
    "No nos conformamos con una sola m√©trica. Como jueces experimentados, evaluamos cada modelo desde m√∫ltiples √°ngulos:\n",
    "- **ROC-AUC**: ¬øQu√© tan bien separa ganadores de perdedores?\n",
    "- **MCC**: ¬øQu√© tan balanceado es su rendimiento?\n",
    "- **Brier Score**: ¬øQu√© tan calibradas est√°n sus probabilidades?\n",
    "- **Cross-validation**: ¬øEs consistente o solo tuvo suerte?\n",
    "\n",
    "**¬øQui√©n tomar√° la delantera inicial?** Los primeros resultados est√°n a punto de revelarse..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelos\n",
    "results = trainer.train_models(X_train, X_test, y_train, y_test, feature_names)\n",
    "\n",
    "print(f\"\\nüèÜ Mejor modelo base: {trainer.best_model} (ROC-AUC: {trainer.best_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac86272",
   "metadata": {},
   "source": [
    "### üîç Los Secretos Revelados: ¬øQu√© Hace Ganar una Batalla?\n",
    "\n",
    "Ahora que nuestros modelos han mostrado sus cartas, es momento de la **gran revelaci√≥n**. Como detectives investigando un misterio, vamos a descubrir qu√© caracter√≠sticas son realmente importantes para predecir el √©xito en las batallas Pokemon.\n",
    "\n",
    "### üïµÔ∏è La Investigaci√≥n Comienza\n",
    "\n",
    "No todos los modelos \"ven\" las mismas cosas. Algunos se enfocan en patrones sutiles, otros en se√±ales obvias. Pero cuando m√∫ltiples modelos coinciden en que una caracter√≠stica es importante, sabemos que hemos encontrado algo especial.\n",
    "\n",
    "### üéØ El Consenso de los Maestros\n",
    "\n",
    "Vamos a realizar un an√°lisis de consenso - como reunir a los mejores entrenadores Pokemon del mundo y preguntarles: **\"¬øEn qu√© se fijan cuando predicen qui√©n ganar√° una batalla?\"**\n",
    "\n",
    "**¬øSer√° la intensidad de la batalla?** ¬øLa cantidad de movimientos ejecutados? ¬øLos patrones de cambio? ¬øO descubriremos algo completamente inesperado?\n",
    "\n",
    "### üèÜ Las Caracter√≠sticas M√°s Estables\n",
    "\n",
    "Tambi√©n buscaremos las caracter√≠sticas m√°s \"estables\" - aquellas en las que todos los modelos conf√≠an consistentemente. Estas son como las reglas fundamentales del universo Pokemon, principios que trascienden algoritmos espec√≠ficos.\n",
    "\n",
    "**¬øQu√© secretos del √©xito en batallas Pokemon est√°n a punto de ser revelados?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de importancia de caracter√≠sticas\n",
    "print(\"\\nüîç Analizando importancia de caracter√≠sticas...\")\n",
    "importance_analysis = trainer.plot_feature_importance_analysis(results, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d95d36",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Round 2: Los Gladiadores Evolucionan\n",
    "\n",
    "**¬°Plot twist!** Como en cualquier buena historia de Pokemon, nuestros competidores est√°n a punto de **evolucionar**. Los tres mejores modelos del primer round han ganado el derecho a una transformaci√≥n especial: optimizaci√≥n de hiperpar√°metros.\n",
    "\n",
    "### üß¨ La Evoluci√≥n No Es Solo Suerte\n",
    "\n",
    "En el mundo Pokemon, la evoluci√≥n requiere las condiciones exactas. De manera similar, nuestros modelos necesitan los hiperpar√°metros perfectos para alcanzar su m√°ximo potencial. No es magia - es **ciencia pura y b√∫squeda inteligente**.\n",
    "\n",
    "### üéØ La B√∫squeda del Santo Grial\n",
    "\n",
    "Cada modelo tiene su propio \"c√≥digo gen√©tico\" de hiperpar√°metros:\n",
    "- **Random Forest**: ¬øCu√°ntos √°rboles? ¬øQu√© profundidad? ¬øCu√°ntas muestras por hoja?\n",
    "- **XGBoost**: ¬øQu√© learning rate? ¬øCu√°nta regularizaci√≥n? ¬øQu√© subsample?\n",
    "- **LightGBM**: ¬øCu√°ntas hojas? ¬øQu√© profundidad m√°xima? ¬øCu√°ntos estimadores?\n",
    "\n",
    "### üî¨ RandomizedSearchCV: Nuestro Laboratorio de Evoluci√≥n\n",
    "\n",
    "No vamos a probar cada combinaci√≥n posible (eso tomar√≠a a√±os). En su lugar, usamos **b√∫squeda aleatoria inteligente** - como un entrenador Pokemon experimentado que sabe exactamente qu√© condiciones probar para cada evoluci√≥n.\n",
    "\n",
    "**¬øVeremos mejoras dram√°ticas?** ¬øAlg√∫n modelo dar√° un salto cu√°ntico en rendimiento? ¬øO descubriremos que ya estaban cerca de su potencial m√°ximo?\n",
    "\n",
    "**¬°La evoluci√≥n comienza ahora!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf192e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizaci√≥n de hiperpar√°metros\n",
    "optimized_models = trainer.hyperparameter_optimization(X_train, y_train, top_models=3)\n",
    "\n",
    "# Evaluar modelos optimizados\n",
    "print(\"\\nüìä Evaluando modelos optimizados...\")\n",
    "optimized_results = {}\n",
    "\n",
    "for opt_name, opt_data in optimized_models.items():\n",
    "    model = opt_data['model']\n",
    "    \n",
    "    # Seleccionar datos apropiados\n",
    "    base_name = opt_name.replace('_optimized', '')\n",
    "    if base_name in ['neural_network', 'svm', 'logistic_regression']:\n",
    "        X_test_final = trainer.scaler.transform(X_test)\n",
    "    else:\n",
    "        X_test_final = X_test\n",
    "    \n",
    "    # Predicciones\n",
    "    y_pred = model.predict(X_test_final)\n",
    "    y_pred_proba = model.predict_proba(X_test_final)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    metrics = trainer.calculate_advanced_metrics(y_test, y_pred, y_pred_proba, opt_name)\n",
    "    \n",
    "    optimized_results[opt_name] = {\n",
    "        'model': model,\n",
    "        'metrics': metrics,\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ {opt_name} - ROC-AUC: {metrics['roc_auc']:.4f} | MCC: {metrics['mcc']:.4f}\")\n",
    "    \n",
    "    # Actualizar mejor modelo si es necesario\n",
    "    if metrics['roc_auc'] > trainer.best_score:\n",
    "        trainer.best_score = metrics['roc_auc']\n",
    "        trainer.best_model = opt_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279b312c",
   "metadata": {},
   "source": [
    "### ü§ù La Alianza Definitiva: Cuando los Rivales se Unen\n",
    "\n",
    "En las mejores historias √©picas, llega un momento cuando los antiguos rivales deben unir fuerzas para enfrentar un desaf√≠o mayor. **Este es ese momento.**\n",
    "\n",
    "### üåü El Poder de la Uni√≥n\n",
    "\n",
    "Hemos visto lo que cada modelo puede lograr individualmente. Algunos brillan en ciertos aspectos, otros dominan diferentes patrones. Pero ¬øqu√© pasar√≠a si combin√°ramos sus fortalezas √∫nicas en una **s√∫per-alianza**?\n",
    "\n",
    "### üé≠ Los Avengers del Machine Learning\n",
    "\n",
    "Como los Avengers, cada modelo aporta algo √∫nico al equipo:\n",
    "- **Random Forest**: La sabidur√≠a colectiva y estabilidad\n",
    "- **XGBoost**: La precisi√≥n competitiva y optimizaci√≥n\n",
    "- **LightGBM**: La velocidad y eficiencia\n",
    "- **Neural Network**: La capacidad de ver patrones complejos\n",
    "- **Gradient Boosting**: El aprendizaje meticuloso de errores\n",
    "\n",
    "### üó≥Ô∏è Democracia en Acci√≥n: Soft Voting\n",
    "\n",
    "Nuestro ensemble no es una dictadura donde un modelo domina. Es una **democracia perfecta** donde cada modelo vota con sus probabilidades, y la decisi√≥n final emerge del consenso colectivo.\n",
    "\n",
    "### üéØ La Pregunta del Mill√≥n\n",
    "\n",
    "**¬øSer√° el ensemble superior a cualquier modelo individual?** En teor√≠a, deber√≠a ser as√≠ - la diversidad de enfoques deber√≠a crear un predictor m√°s robusto y preciso.\n",
    "\n",
    "Pero la teor√≠a y la realidad a veces divergen. **¬øNuestros gladiadores trabajar√°n mejor juntos o en solitario?**\n",
    "\n",
    "**¬°La alianza definitiva est√° a punto de formarse!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5fcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear ensemble\n",
    "ensemble_model = trainer.create_ensemble(results, X_train, y_train)\n",
    "\n",
    "if ensemble_model is not None:\n",
    "    # Evaluar ensemble\n",
    "    print(\"\\nüìä Evaluando modelo ensemble...\")\n",
    "    \n",
    "    # Predicciones del ensemble\n",
    "    y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "    y_pred_proba_ensemble = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # M√©tricas del ensemble\n",
    "    ensemble_metrics = trainer.calculate_advanced_metrics(\n",
    "        y_test, y_pred_ensemble, y_pred_proba_ensemble, 'ensemble'\n",
    "    )\n",
    "    \n",
    "    print(f\"ü§ù Ensemble - ROC-AUC: {ensemble_metrics['roc_auc']:.4f} | MCC: {ensemble_metrics['mcc']:.4f}\")\n",
    "    \n",
    "    # Actualizar mejor modelo si el ensemble es superior\n",
    "    if ensemble_metrics['roc_auc'] > trainer.best_score:\n",
    "        trainer.best_score = ensemble_metrics['roc_auc']\n",
    "        trainer.best_model = 'ensemble'\n",
    "        \n",
    "        # A√±adir ensemble a resultados\n",
    "        optimized_results['ensemble'] = {\n",
    "            'model': ensemble_model,\n",
    "            'metrics': ensemble_metrics,\n",
    "            'predictions': y_pred_ensemble,\n",
    "            'probabilities': y_pred_proba_ensemble\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a38f6f",
   "metadata": {},
   "source": [
    "### üîç CSI: Pokemon Battle Edition - Investigando los Misterios del Fracaso\n",
    "\n",
    "Incluso los mejores entrenadores Pokemon pierden batallas. Incluso los mejores modelos de ML cometen errores. Pero la diferencia entre un buen entrenador y un **maestro** est√° en c√≥mo aprende de esas derrotas.\n",
    "\n",
    "### üïµÔ∏è Convirti√©ndonos en Detectives de Datos\n",
    "\n",
    "Cada predicci√≥n incorrecta es como una escena del crimen que debemos investigar. **¬øPor qu√© fall√≥ nuestro modelo?** ¬øFue mala suerte, informaci√≥n insuficiente, o hay patrones sistem√°ticos en nuestros errores?\n",
    "\n",
    "### üé≠ Los Cuatro Tipos de Drama\n",
    "\n",
    "En el teatro del Machine Learning, hay cuatro tipos de drama:\n",
    "- **True Positives**: Las victorias bien predichas (¬°√©xito!)\n",
    "- **True Negatives**: Las derrotas bien predichas (¬°tambi√©n √©xito!)\n",
    "- **False Positives**: Predijimos victoria pero hubo derrota (¬°optimismo excesivo!)\n",
    "- **False Negatives**: Predijimos derrota pero hubo victoria (¬°pesimismo injustificado!)\n",
    "\n",
    "### üåä La Zona de Incertidumbre\n",
    "\n",
    "Hay batallas que son genuinamente dif√≠ciles de predecir - aquellas donde nuestro modelo dice \"no estoy seguro\" (probabilidades cerca de 0.5). **¬øQu√© hace que estas batallas sean tan impredecibles?** ¬øSon genuinamente aleatorias o hay patrones sutiles que a√∫n no capturamos?\n",
    "\n",
    "### üî¨ Anatom√≠a de un Error\n",
    "\n",
    "Vamos a diseccionar nuestros errores como cient√≠ficos forenses:\n",
    "- **¬øEn qu√© caracter√≠sticas difieren los casos mal clasificados?**\n",
    "- **¬øHay patrones en las probabilidades de predicci√≥n?**\n",
    "- **¬øAlgunos tipos de batalla son m√°s dif√≠ciles que otros?**\n",
    "\n",
    "**¬øQu√© secretos revelar√°n nuestros errores?** A veces, los fracasos ense√±an m√°s que los √©xitos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f376614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de errores\n",
    "all_results = {**results, **optimized_results}\n",
    "error_analysis = trainer.analyze_prediction_errors(all_results, X_test, y_test, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6abf51",
   "metadata": {},
   "source": [
    "## üìä El Momento de la Verdad: ¬øHemos Hecho Historia?\n",
    "\n",
    "**Se√±oras y se√±ores, el momento que todos hemos estado esperando ha llegado.** Despu√©s de horas de entrenamiento, optimizaci√≥n y an√°lisis, es hora de responder la pregunta fundamental:\n",
    "\n",
    "### üéØ ¬øHemos Superado lo Imposible?\n",
    "\n",
    "Nuestro baseline de **ROC-AUC 0.837** ha sido nuestro drag√≥n final desde el principio. Un n√∫mero que parec√≠a formidable, casi inalcanzable. Pero hemos reunido el mejor arsenal de Machine Learning disponible y lo hemos lanzado contra este desaf√≠o.\n",
    "\n",
    "### üèÜ El Podio de Campeones\n",
    "\n",
    "Como en cualquier competencia √©pica, vamos a coronar a nuestros campeones:\n",
    "- **ü•á Medalla de Oro**: El modelo supremo que reinar√° sobre todos\n",
    "- **ü•à Medalla de Plata**: El digno segundo lugar\n",
    "- **ü•â Medalla de Bronce**: El tercer puesto honorable\n",
    "\n",
    "### üìà La Historia en N√∫meros\n",
    "\n",
    "Pero esto no es solo sobre ganar o perder. Es sobre **cu√°nto hemos mejorado**. ¬øFue una mejora marginal del 1%? ¬øO logramos un salto cu√°ntico del 10% o m√°s?\n",
    "\n",
    "### üé≠ El Drama del Resultado\n",
    "\n",
    "**¬øCu√°l ser√° el veredicto final?** ¬øCelebraremos una victoria aplastante sobre el baseline? ¬øO descubriremos que el baseline era m√°s formidable de lo que pens√°bamos?\n",
    "\n",
    "**¬øHabr√° sorpresas?** ¬øAlg√∫n modelo underdog que nadie esperaba se alzar√° como campe√≥n? ¬øO el favorito cumplir√° las expectativas?\n",
    "\n",
    "**El suspenso est√° matando... ¬°Veamos los resultados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte final\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ REPORTE FINAL - POKEMON BATTLE AI ML TRAINING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "baseline_auc = 0.837\n",
    "print(f\"\\nüìä BASELINE ROC-AUC: {baseline_auc:.4f}\")\n",
    "print(f\"üéØ MEJOR MODELO: {trainer.best_model}\")\n",
    "print(f\"üèÜ MEJOR ROC-AUC: {trainer.best_score:.4f}\")\n",
    "\n",
    "improvement = ((trainer.best_score - baseline_auc) / baseline_auc) * 100\n",
    "if trainer.best_score > baseline_auc:\n",
    "    print(f\"‚úÖ MEJORA: +{improvement:.2f}% sobre baseline\")\n",
    "else:\n",
    "    print(f\"‚ùå RENDIMIENTO: {improvement:.2f}% respecto al baseline\")\n",
    "\n",
    "print(f\"\\nüìà RESUMEN DE TODOS LOS MODELOS:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Combinar todos los resultados\n",
    "all_model_scores = []\n",
    "\n",
    "# Modelos base\n",
    "for name, result in results.items():\n",
    "    all_model_scores.append((name, result['metrics']['roc_auc'], result['metrics']['mcc']))\n",
    "\n",
    "# Modelos optimizados\n",
    "for name, result in optimized_results.items():\n",
    "    all_model_scores.append((name, result['metrics']['roc_auc'], result['metrics']['mcc']))\n",
    "\n",
    "# Ordenar por ROC-AUC\n",
    "all_model_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (name, auc, mcc) in enumerate(all_model_scores, 1):\n",
    "    status = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\" if i == 3 else \"  \"\n",
    "    vs_baseline = \"‚úÖ\" if auc > baseline_auc else \"‚ùå\"\n",
    "    print(f\"{status} {name:25} | ROC-AUC: {auc:.4f} | MCC: {mcc:.4f} | {vs_baseline}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc93d92c",
   "metadata": {},
   "source": [
    "### üíæ Preservando la Historia: El Legado de Nuestros Campeones\n",
    "\n",
    "Como arque√≥logos del futuro, debemos preservar cuidadosamente nuestros descubrimientos. El modelo campe√≥n que hemos creado no es solo c√≥digo - es **historia en el making**, el resultado de un viaje √©pico de descubrimiento y optimizaci√≥n.\n",
    "\n",
    "### üèõÔ∏è El Museo de Nuestros Logros\n",
    "\n",
    "Vamos a crear un \"museo digital\" completo de nuestro proyecto:\n",
    "- **El Modelo Campe√≥n**: Serializado y listo para la posteridad\n",
    "- **Los Resultados Completos**: Cada m√©trica, cada comparaci√≥n, cada insight\n",
    "- **El Scaler**: Si nuestro campe√≥n lo necesita, tambi√©n lo preservamos\n",
    "- **Los Metadatos**: La fecha, las condiciones, el contexto completo\n",
    "\n",
    "### üìú El Pergamino de los Resultados\n",
    "\n",
    "Nuestro archivo JSON ser√° como un pergamino antiguo que cuenta la historia completa:\n",
    "- ¬øQui√©n fue el campe√≥n?\n",
    "- ¬øCu√°l fue su puntuaci√≥n final?\n",
    "- ¬øCu√°nto mejor√≥ sobre el baseline?\n",
    "- ¬øCu√°les fueron las caracter√≠sticas m√°s importantes?\n",
    "- ¬øCu√°ndo ocurri√≥ este momento hist√≥rico?\n",
    "\n",
    "### üöÄ Listo para la Producci√≥n\n",
    "\n",
    "Este no es el final de nuestro viaje - es el **comienzo de una nueva era**. Nuestro modelo campe√≥n est√° listo para:\n",
    "- Predecir batallas Pokemon en tiempo real\n",
    "- Ayudar a entrenadores a tomar mejores decisiones\n",
    "- Revelar patrones ocultos en el mundo competitivo Pokemon\n",
    "\n",
    "**¬°La historia ha sido escrita, el legado est√° asegurado!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio de salida\n",
    "output_dir = Path(\"../models/trained\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Guardar mejor modelo\n",
    "if trainer.best_model in all_results:\n",
    "    best_model_obj = all_results[trainer.best_model]['model']\n",
    "    \n",
    "    # Guardar modelo\n",
    "    model_path = output_dir / f\"best_model_{trainer.best_model}.pkl\"\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(best_model_obj, f)\n",
    "    \n",
    "    # Guardar scaler si es necesario\n",
    "    if trainer.best_model in ['neural_network', 'svm', 'logistic_regression']:\n",
    "        scaler_path = output_dir / f\"scaler_{trainer.best_model}.pkl\"\n",
    "        with open(scaler_path, 'wb') as f:\n",
    "            pickle.dump(trainer.scaler, f)\n",
    "    \n",
    "    print(f\"‚úÖ Mejor modelo guardado: {model_path}\")\n",
    "\n",
    "# Guardar resultados completos\n",
    "results_data = {\n",
    "    'best_model': trainer.best_model,\n",
    "    'best_score': trainer.best_score,\n",
    "    'baseline_auc': baseline_auc,\n",
    "    'improvement': improvement,\n",
    "    'feature_names': feature_names,\n",
    "    'model_scores': all_model_scores,\n",
    "    'training_date': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "results_path = output_dir / \"training_results.json\"\n",
    "with open(results_path, 'w') as f:\n",
    "    json.dump(results_data, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Resultados guardados: {results_path}\")\n",
    "\n",
    "print(\"\\nüéâ ¬°Entrenamiento completado exitosamente!\")\n",
    "print(\"üöÄ El modelo est√° listo para hacer predicciones en batallas Pokemon!\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
