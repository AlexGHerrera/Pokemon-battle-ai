{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7fa302",
   "metadata": {},
   "source": [
    "# Pokemon Battle Dataset - Análisis Exploratorio de Datos (EDA)\n",
    "\n",
    "## La Historia que Vamos a Contar\n",
    "\n",
    "**Imagina que eres un entrenador Pokemon novato** que quiere convertirse en maestro. ¿Cómo aprenderías? Observando a los mejores, analizando sus estrategias, entendiendo qué Pokemon usan y cuándo.\n",
    "\n",
    "**Eso es exactamente lo que haremos con nuestra IA.** A través de aproximadamente 14,000 batallas reales de Pokemon Showdown, descubriremos:\n",
    "\n",
    "- **¿Qué hace que una batalla sea exitosa?**\n",
    "- **¿Cuáles son las estrategias ganadoras?**\n",
    "- **¿Qué Pokemon dominan el meta competitivo?**\n",
    "- **¿Cómo puede nuestra IA aprender estos patrones?**\n",
    "\n",
    "## Nuestro Viaje de Descubrimiento\n",
    "\n",
    "**Capítulo 1**: *¿Son nuestros datos confiables?* - Validación de calidad y integridad\n",
    "**Capítulo 2**: *¿Qué nos dicen las batallas?* - Patrones y métricas de combate\n",
    "**Capítulo 3**: *¿Quiénes son los protagonistas?* - Análisis profundo de Pokemon\n",
    "**Capítulo 4**: *¿Cuándo ocurren las batallas?* - Patrones temporales del meta\n",
    "**Capítulo 5**: *¿Qué debe aprender nuestra IA?* - Ingeniería de características\n",
    "**Epílogo**: *El camino hacia la maestría* - Próximos pasos para el entrenamiento\n",
    "\n",
    "## Alcance del Proyecto\n",
    "\n",
    "Este proyecto tiene como objetivo desarrollar un **modelo de inteligencia artificial capaz de jugar Pokemon de forma autónoma** contra usuarios humanos. Para lograr esto, necesitamos comprender profundamente los patrones de batalla, estrategias ganadoras y comportamientos de los jugadores expertos.\n",
    "\n",
    "### Contexto del Dataset\n",
    "\n",
    "- **Fuente**: Batallas reales de Pokemon Showdown (formato gen9randombattle)\n",
    "- **Volumen**: ~14,000 batallas individuales en formato JSON\n",
    "- **Contenido**: Turnos secuenciales, eventos de batalla, estados del juego, resultados\n",
    "- **Aplicación**: Entrenamiento de modelo de IA para toma de decisiones en tiempo real\n",
    "\n",
    "---\n",
    "\n",
    "# %% [markdown]\n",
    "## Importación de librerías y configuración inicial\n",
    "\n",
    "**Objetivo de esta sección:**\n",
    "- Importamos las librerías necesarias para el análisis de datos y visualización\n",
    "- Configuramos matplotlib y seaborn para generar gráficas consistentes y profesionales\n",
    "- Configuramos el entorno de trabajo para análisis óptimo\n",
    "- Estas configuraciones son fundamentales para un EDA reproducible y visualmente atractivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "# Nota: No suprimimos warnings para mantener visibilidad de posibles problemas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Configuración de visualizaciones con paleta Pokemon temática\n",
    "plt.style.use('seaborn-v0_8-whitegrid')  # Estilo más moderno\n",
    "\n",
    "# Paleta Pokemon temática - colores vibrantes pero profesionales\n",
    "pokemon_colors = {\n",
    "    'fire': '#FF6B35',      # Naranja fuego vibrante\n",
    "    'water': '#4A90E2',     # Azul agua profundo  \n",
    "    'grass': '#7ED321',     # Verde hierba brillante\n",
    "    'electric': '#F5A623',  # Amarillo eléctrico\n",
    "    'psychic': '#BD10E0',   # Púrpura psíquico\n",
    "    'dragon': '#9013FE',    # Púrpura dragón\n",
    "    'dark': '#2C3E50',      # Gris oscuro elegante\n",
    "    'steel': '#95A5A6',     # Gris metálico\n",
    "    'fairy': '#FF69B4',     # Rosa hada\n",
    "    'fighting': '#D0021B',  # Rojo lucha\n",
    "    'poison': '#7B68EE',    # Púrpura veneno\n",
    "    'ground': '#8B4513',    # Marrón tierra\n",
    "    'flying': '#87CEEB',    # Azul cielo\n",
    "    'bug': '#9ACD32',       # Verde insecto\n",
    "    'rock': '#A0522D',      # Marrón roca\n",
    "    'ghost': '#483D8B',     # Púrpura fantasma\n",
    "    'ice': '#B0E0E6',       # Azul hielo\n",
    "    'normal': '#A8A878'     # Beige normal\n",
    "}\n",
    "\n",
    "# Paletas para diferentes tipos de gráficos\n",
    "primary_palette = [pokemon_colors['fire'], pokemon_colors['water'], pokemon_colors['grass'], \n",
    "                  pokemon_colors['electric'], pokemon_colors['psychic'], pokemon_colors['dragon']]\n",
    "\n",
    "secondary_palette = [pokemon_colors['dark'], pokemon_colors['steel'], pokemon_colors['fairy'],\n",
    "                    pokemon_colors['fighting'], pokemon_colors['poison'], pokemon_colors['ground']]\n",
    "\n",
    "# Configurar seaborn con la nueva paleta\n",
    "sns.set_palette(primary_palette)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "\n",
    "# Configuración de colores para gráficos específicos\n",
    "plot_colors = {\n",
    "    'histogram': pokemon_colors['water'],\n",
    "    'scatter': pokemon_colors['fire'], \n",
    "    'line': pokemon_colors['electric'],\n",
    "    'bar': pokemon_colors['grass'],\n",
    "    'boxplot': primary_palette,\n",
    "    'heatmap': 'RdYlBu_r'  # Colormap para matrices de correlación\n",
    "}\n",
    "\n",
    "# Configuración de reproducibilidad\n",
    "import platform\n",
    "import sys\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuración completada - entorno listo para análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1a03e",
   "metadata": {},
   "source": [
    "## Configuración de rutas y constantes\n",
    "\n",
    "**Propósito de la configuración:**\n",
    "- Centralizamos la gestión de archivos para facilitar el mantenimiento del código\n",
    "- `BATTLES_DIR`: Contiene los archivos JSON individuales de cada batalla\n",
    "- `ALL_BATTLES_JSON`: Archivo consolidado que mejora la velocidad de carga\n",
    "- `OUTPUT_DIR`: Directorio donde guardaremos visualizaciones y resultados\n",
    "- Esta organización es crucial para un flujo de trabajo ordenado y escalable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar si estamos ejecutando desde notebooks/ o desde raíz\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\":\n",
    "    DATA_DIR = Path(\"../data\")\n",
    "    OUTPUT_DIR = Path(\"../output\")\n",
    "else:\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    OUTPUT_DIR = Path(\"output\")\n",
    "\n",
    "BATTLES_DIR = DATA_DIR / \"battles\"\n",
    "ALL_BATTLES_JSON = DATA_DIR / \"all_battles.json\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Rutas configuradas correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79392cf",
   "metadata": {},
   "source": [
    "## Funciones auxiliares para procesamiento de datos\n",
    "\n",
    "**Funciones implementadas:**\n",
    "- `get_in()`: Navega estructuras JSON anidadas de forma segura, evitando errores por claves faltantes\n",
    "- `extract_pokemon_info()`: Extrae información específica de Pokemon que será clave para el modelo de IA\n",
    "- `calculate_battle_metrics()`: Calcula métricas estratégicas como eventos por turno, tipos de acciones, etc.\n",
    "- Estas funciones nos permiten transformar datos complejos en features estructuradas para machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d0f33",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_in(d: Any, path: List[str], default: Any = None) -> Any:\n",
    "    \"\"\"Extrae valores anidados de diccionarios de forma segura.\"\"\"\n",
    "    cur = d\n",
    "    for k in path:\n",
    "        if isinstance(cur, dict) and k in cur:\n",
    "            cur = cur[k]\n",
    "        else:\n",
    "            return default\n",
    "    return cur\n",
    "\n",
    "def extract_pokemon_info(battle: dict) -> List[dict]:\n",
    "    \"\"\"Extrae información detallada de Pokemon de una batalla.\"\"\"\n",
    "    pokemon_info = []\n",
    "    teams = get_in(battle, [\"team_revelation\", \"teams\"], {})\n",
    "    \n",
    "    for player_id, team in teams.items():\n",
    "        if isinstance(team, list):\n",
    "            for pokemon in team:\n",
    "                # Extraer todas las estadísticas base disponibles\n",
    "                base_stats = pokemon.get('base_stats', {})\n",
    "                info = {\n",
    "                    'battle_id': battle.get('battle_id'),\n",
    "                    'player': player_id,\n",
    "                    'species': pokemon.get('species'),\n",
    "                    'level': pokemon.get('level'),\n",
    "                    'gender': pokemon.get('gender'),\n",
    "                    'hp': base_stats.get('hp'),\n",
    "                    'attack': base_stats.get('attack'),\n",
    "                    'defense': base_stats.get('defense'),\n",
    "                    'sp_attack': base_stats.get('sp_attack'),\n",
    "                    'sp_defense': base_stats.get('sp_defense'),\n",
    "                    'speed': base_stats.get('speed'),\n",
    "                    'first_seen_turn': pokemon.get('first_seen_turn'),\n",
    "                    'revelation_status': pokemon.get('revelation_status'),\n",
    "                    'known_ability': pokemon.get('known_ability'),\n",
    "                    'known_item': pokemon.get('known_item'),\n",
    "                    'known_tera_type': pokemon.get('known_tera_type'),\n",
    "                    'known_moves_count': len(pokemon.get('known_moves', [])),\n",
    "                    'unknown_move_slots': pokemon.get('unknown_move_slots', 0)\n",
    "                }\n",
    "                pokemon_info.append(info)\n",
    "    return pokemon_info\n",
    "\n",
    "def calculate_battle_metrics(battle: dict) -> dict:\n",
    "    \"\"\"Calcula métricas clave de una batalla para análisis avanzado de IA.\"\"\"\n",
    "    metadata = battle.get('metadata', {})\n",
    "    turns = battle.get('turns', [])\n",
    "    \n",
    "    # Métricas básicas\n",
    "    total_turns = len(turns)\n",
    "    winner = get_in(metadata, ['outcome', 'winner'])\n",
    "    reason = get_in(metadata, ['outcome', 'reason'])\n",
    "    \n",
    "    # Análisis detallado de eventos\n",
    "    total_events = 0\n",
    "    move_events = 0\n",
    "    switch_events = 0\n",
    "    damage_events = 0\n",
    "    effect_events = 0\n",
    "    heal_events = 0\n",
    "    status_events = 0\n",
    "    \n",
    "    # Métricas de momentum y timing\n",
    "    early_game_events = 0  # Primeros 3 turnos\n",
    "    mid_game_events = 0    # Turnos 4-8\n",
    "    late_game_events = 0   # Turnos 9+\n",
    "    \n",
    "    # Patrones de decisión\n",
    "    consecutive_moves = 0\n",
    "    consecutive_switches = 0\n",
    "    last_action = None\n",
    "    \n",
    "    for turn_idx, turn in enumerate(turns, 1):\n",
    "        events = turn.get('events', [])\n",
    "        turn_event_count = len(events)\n",
    "        total_events += turn_event_count\n",
    "        \n",
    "        # Clasificar por fase de batalla\n",
    "        if turn_idx <= 3:\n",
    "            early_game_events += turn_event_count\n",
    "        elif turn_idx <= 8:\n",
    "            mid_game_events += turn_event_count\n",
    "        else:\n",
    "            late_game_events += turn_event_count\n",
    "        \n",
    "        for event in events:\n",
    "            event_type = event.get('type')\n",
    "            \n",
    "            # Conteo de tipos de eventos\n",
    "            if event_type == 'move':\n",
    "                move_events += 1\n",
    "                if last_action == 'move':\n",
    "                    consecutive_moves += 1\n",
    "                last_action = 'move'\n",
    "            elif event_type == 'switch':\n",
    "                switch_events += 1\n",
    "                if last_action == 'switch':\n",
    "                    consecutive_switches += 1\n",
    "                last_action = 'switch'\n",
    "            elif event_type == 'damage':\n",
    "                damage_events += 1\n",
    "            elif event_type == 'effect':\n",
    "                effect_events += 1\n",
    "            elif event_type == 'heal':\n",
    "                heal_events += 1\n",
    "            elif event_type in ['status', 'boost', 'unboost']:\n",
    "                status_events += 1\n",
    "    \n",
    "    return {\n",
    "        'battle_id': battle.get('battle_id'),\n",
    "        'total_turns': total_turns,\n",
    "        'total_events': total_events,\n",
    "        'move_events': move_events,\n",
    "        'switch_events': switch_events,\n",
    "        'damage_events': damage_events,\n",
    "        'effect_events': effect_events,\n",
    "        'heal_events': heal_events,\n",
    "        'status_events': status_events,\n",
    "        'winner': winner,\n",
    "        'reason': reason,\n",
    "        'events_per_turn': total_events / max(total_turns, 1),\n",
    "        'timestamp': metadata.get('timestamp_unix'),\n",
    "        # Métricas de momentum\n",
    "        'early_game_intensity': early_game_events / max(min(total_turns, 3), 1),\n",
    "        'mid_game_intensity': mid_game_events / max(min(total_turns - 3, 5), 1) if total_turns > 3 else 0,\n",
    "        'late_game_intensity': late_game_events / max(total_turns - 8, 1) if total_turns > 8 else 0,\n",
    "        # Patrones de decisión\n",
    "        'move_switch_ratio': move_events / max(switch_events, 1),\n",
    "        'consecutive_moves': consecutive_moves,\n",
    "        'consecutive_switches': consecutive_switches,\n",
    "        'action_diversity': len(set([e.get('type') for turn in turns for e in turn.get('events', [])]))  \n",
    "    }\n",
    "\n",
    "def extract_team_composition_features(battle: dict) -> dict:\n",
    "    \"\"\"Extrae features avanzadas de composición de equipos para IA.\"\"\"\n",
    "    teams = get_in(battle, [\"team_revelation\", \"teams\"], {})\n",
    "    features = {'battle_id': battle.get('battle_id')}\n",
    "    \n",
    "    for player_id in ['p1', 'p2']:\n",
    "        team = teams.get(player_id, [])\n",
    "        if isinstance(team, list) and team:\n",
    "            # Métricas básicas del equipo\n",
    "            levels = [p.get('level', 0) for p in team if p.get('level')]\n",
    "            hps = [get_in(p, ['base_stats', 'hp']) for p in team if get_in(p, ['base_stats', 'hp'])]\n",
    "            \n",
    "            features.update({\n",
    "                f'{player_id}_team_size': len(team),\n",
    "                f'{player_id}_avg_level': np.mean(levels) if levels else 0,\n",
    "                f'{player_id}_level_std': np.std(levels) if len(levels) > 1 else 0,\n",
    "                f'{player_id}_min_level': min(levels) if levels else 0,\n",
    "                f'{player_id}_max_level': max(levels) if levels else 0,\n",
    "                f'{player_id}_avg_hp': np.mean(hps) if hps else 0,\n",
    "                f'{player_id}_hp_std': np.std(hps) if len(hps) > 1 else 0,\n",
    "                f'{player_id}_total_hp': sum(hps) if hps else 0,\n",
    "            })\n",
    "            \n",
    "            # Diversidad de especies\n",
    "            species = [p.get('species') for p in team if p.get('species')]\n",
    "            features[f'{player_id}_species_diversity'] = len(set(species))\n",
    "            \n",
    "            # Información de revelación\n",
    "            revelation_statuses = [p.get('revelation_status') for p in team]\n",
    "            features[f'{player_id}_fully_revealed'] = revelation_statuses.count('fully_revealed')\n",
    "            features[f'{player_id}_partially_revealed'] = revelation_statuses.count('partially_revealed')\n",
    "            \n",
    "            # Información conocida vs desconocida\n",
    "            known_abilities = sum(1 for p in team if p.get('known_ability'))\n",
    "            known_items = sum(1 for p in team if p.get('known_item'))\n",
    "            total_known_moves = sum(len(p.get('known_moves', [])) for p in team)\n",
    "            \n",
    "            features.update({\n",
    "                f'{player_id}_known_abilities': known_abilities,\n",
    "                f'{player_id}_known_items': known_items,\n",
    "                f'{player_id}_total_known_moves': total_known_moves,\n",
    "                f'{player_id}_info_advantage': (known_abilities + known_items + total_known_moves) / max(len(team), 1)\n",
    "            })\n",
    "        else:\n",
    "            # Valores por defecto si no hay datos del equipo\n",
    "            for metric in ['team_size', 'avg_level', 'level_std', 'min_level', 'max_level', \n",
    "                          'avg_hp', 'hp_std', 'total_hp', 'species_diversity', \n",
    "                          'fully_revealed', 'partially_revealed', 'known_abilities', \n",
    "                          'known_items', 'total_known_moves', 'info_advantage']:\n",
    "                features[f'{player_id}_{metric}'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Funciones auxiliares listas para procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8530d8e4",
   "metadata": {},
   "source": [
    "## Funciones de optimización para datasets grandes\n",
    "\n",
    "**Estrategias implementadas:**\n",
    "- Muestreo aleatorio para desarrollo rápido\n",
    "- Conversión a formato Parquet (más eficiente)\n",
    "- Carga por chunks para evitar problemas de memoria\n",
    "- Procesamiento incremental de batallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dedbc3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_sample_dataset(sample_size: int = 1000, force_recreate: bool = False) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Crea un dataset de muestra para desarrollo rápido.\n",
    "    \n",
    "    Args:\n",
    "        sample_size: Número de batallas a incluir en la muestra\n",
    "        force_recreate: Si True, recrea la muestra aunque ya exista\n",
    "    \"\"\"\n",
    "    sample_path = DATA_DIR / f\"battles_sample_{sample_size}.json\"\n",
    "    \n",
    "    if sample_path.exists() and not force_recreate:\n",
    "        print(f\"Cargando muestra existente: {sample_path}\")\n",
    "        with open(sample_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    print(f\"Creando nueva muestra de {sample_size} batallas...\")\n",
    "    \n",
    "    # Cargar dataset completo y tomar muestra aleatoria\n",
    "    with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "        all_battles = json.load(f)\n",
    "    \n",
    "    import random\n",
    "    random.seed(42)  # Para reproducibilidad\n",
    "    sample_battles = random.sample(all_battles, min(sample_size, len(all_battles)))\n",
    "    \n",
    "    # Guardar muestra\n",
    "    with open(sample_path, \"w\") as f:\n",
    "        json.dump(sample_battles, f, indent=2)\n",
    "    \n",
    "    print(f\"Muestra guardada: {sample_path}\")\n",
    "    print(f\"Tamaño de muestra: {len(sample_battles)} batallas\")\n",
    "    \n",
    "    return sample_battles\n",
    "\n",
    "def convert_to_parquet() -> None:\n",
    "    \"\"\"\n",
    "    Convierte el dataset a formato Parquet para acceso más rápido.\n",
    "    \"\"\"\n",
    "    parquet_path = DATA_DIR / \"battles_optimized.parquet\"\n",
    "    \n",
    "    if parquet_path.exists():\n",
    "        print(f\"Archivo Parquet ya existe: {parquet_path}\")\n",
    "        return\n",
    "    \n",
    "    print(\"Convirtiendo a formato Parquet...\")\n",
    "    \n",
    "    # Cargar y procesar por chunks\n",
    "    chunk_size = 1000\n",
    "    all_metrics = []\n",
    "    \n",
    "    with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "        battles = json.load(f)\n",
    "    \n",
    "    print(f\" Procesando {len(battles)} batallas para extracción de características...\")\n",
    "    for i in range(0, len(battles), 500):\n",
    "        chunk = battles[i:i+500]\n",
    "        chunk_features = [extract_team_composition_features(battle) for battle in chunk]\n",
    "        all_metrics.extend(chunk_features)\n",
    "        if (i + 500) % 1000 == 0:  # Reducir prints\n",
    "            print(f\"   • {min(i+500, len(battles))} batallas procesadas\")\n",
    "    \n",
    "    # Convertir a DataFrame y guardar\n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "    \n",
    "    print(f\"Dataset convertido a Parquet: {parquet_path}\")\n",
    "    print(f\"Tamaño original JSON: {ALL_BATTLES_JSON.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "    print(f\"Tamaño Parquet: {parquet_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "def load_battles_optimized(use_sample: bool = True, sample_size: int = 1000) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Carga optimizada de datos con opciones de muestreo.\n",
    "    \n",
    "    Args:\n",
    "        use_sample: Si True, usa una muestra para desarrollo rápido\n",
    "        sample_size: Tamaño de la muestra si use_sample=True\n",
    "    \"\"\"\n",
    "    if use_sample:\n",
    "        print(f\"Modo desarrollo: usando muestra de {sample_size} batallas\")\n",
    "        return create_sample_dataset(sample_size)\n",
    "    else:\n",
    "        print(\"Modo producción: cargando dataset completo\")\n",
    "        if ALL_BATTLES_JSON.exists():\n",
    "            with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "                return json.load(f)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No existe {ALL_BATTLES_JSON}\")\n",
    "\n",
    "def load_parquet_if_exists() -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Carga el archivo Parquet si existe, para análisis rápido.\n",
    "    \"\"\"\n",
    "    parquet_path = DATA_DIR / \"battles_optimized.parquet\"\n",
    "    \n",
    "    if parquet_path.exists():\n",
    "        print(f\"Cargando datos desde Parquet: {parquet_path}\")\n",
    "        return pd.read_parquet(parquet_path)\n",
    "    else:\n",
    "        print(\"Archivo Parquet no encontrado. Usa convert_to_parquet() primero.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42acc5",
   "metadata": {},
   "source": [
    "## 1. Carga y consolidación de datos\n",
    "\n",
    "**Justificación de la consolidación:**\n",
    "- Los datos vienen en miles de archivos JSON individuales, lo que es ineficiente para análisis\n",
    "- La consolidación mejora significativamente la velocidad de carga y procesamiento\n",
    "- Nos permite validar la integridad de los datos y detectar archivos corruptos\n",
    "- Facilita el análisis posterior al tener todos los datos en una estructura unificada\n",
    "- Es un paso fundamental antes de cualquier análisis exploratorio serio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51891834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_battles_data() -> List[dict]:\n",
    "    \"\"\"Carga y consolida todos los datos de batallas.\"\"\"\n",
    "    if ALL_BATTLES_JSON.exists():\n",
    "        with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    # Si no existe el archivo consolidado, lo creamos\n",
    "    json_files = sorted(BATTLES_DIR.glob(\"*.json\"))\n",
    "    battles_data = []\n",
    "    \n",
    "    print(f\"Consolidando {len(json_files)} archivos JSON...\")\n",
    "    \n",
    "    for i, file in enumerate(json_files):\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                battle = json.load(f)\n",
    "                battles_data.append(battle)\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {file.name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Procesados {i + 1} archivos...\")\n",
    "    \n",
    "    # Guardar archivo consolidado\n",
    "    with open(ALL_BATTLES_JSON, \"w\") as f:\n",
    "        json.dump(battles_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Datos consolidados: {len(battles_data)} batallas\")\n",
    "    return battles_data\n",
    "\n",
    "# Cargar datos\n",
    "battles = load_battles_optimized(use_sample=True, sample_size=2000)  # Modo desarrollo por defecto\n",
    "print(f\"📊 Dataset cargado: {len(battles):,} batallas\")\n",
    "\n",
    "# Crear DataFrame de métricas de batalla para análisis posterior\n",
    "battle_metrics = [calculate_battle_metrics(battle) for battle in battles]\n",
    "df_battles = pd.DataFrame(battle_metrics)\n",
    "print(f\"📈 Métricas extraídas: {len(df_battles.columns)} características por batalla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebfad7",
   "metadata": {},
   "source": [
    "### Configuración de modo de trabajo\n",
    "\n",
    "**Para cambiar entre modos:**\n",
    "- **Desarrollo rápido**: `battles = load_battles_optimized(use_sample=True, sample_size=2000)`\n",
    "- **Dataset completo**: `battles = load_battles_optimized(use_sample=False)`\n",
    "- **Desde Parquet**: `df_battles = load_parquet_if_exists()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2241d",
   "metadata": {},
   "source": [
    "## 2. Análisis de calidad de datos\n",
    "\n",
    "**Importancia del análisis de calidad:**\n",
    "- Identificamos problemas de datos antes de invertir tiempo en análisis incorrectos\n",
    "- Validamos que las batallas tengan la estructura esperada (battle_id, metadata, turns)\n",
    "- Detectamos patrones de datos faltantes que podrían sesgar nuestro modelo\n",
    "- Entendemos la distribución de formatos de batalla para enfocar el entrenamiento\n",
    "- La calidad de datos determina directamente la calidad del modelo de IA resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7db7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"ANÁLISIS DE CALIDAD DE DATOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Estadísticas básicas\n",
    "total_battles = len(battles)\n",
    "print(f\"Total de batallas: {total_battles:,}\")\n",
    "\n",
    "# Validación de estructura\n",
    "valid_battles = 0\n",
    "incomplete_battles = 0\n",
    "\n",
    "required_keys = ['battle_id', 'metadata', 'turns']\n",
    "for battle in battles:\n",
    "    if all(key in battle for key in required_keys):\n",
    "        valid_battles += 1\n",
    "    else:\n",
    "        incomplete_battles += 1\n",
    "\n",
    "print(f\"Batallas con estructura completa: {valid_battles:,} ({valid_battles/total_battles*100:.1f}%)\")\n",
    "print(f\"Batallas incompletas: {incomplete_battles:,} ({incomplete_battles/total_battles*100:.1f}%)\")\n",
    "\n",
    "# Análisis de formatos\n",
    "formats = Counter(battle.get('format_id') for battle in battles)\n",
    "print(f\"\\nFormatos de batalla encontrados:\")\n",
    "for format_id, count in formats.most_common():\n",
    "    print(f\"  - {format_id}: {count:,} batallas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1423910",
   "metadata": {},
   "source": [
    "## Capítulo 1.1: Detectando Imperfecciones en Nuestros Datos\n",
    "\n",
    "**¿Qué secretos ocultan los datos faltantes?**\n",
    "\n",
    "Como detectives examinando evidencia, debemos identificar qué información nos falta y por qué. Los datos nulos no son solo números ausentes - son pistas sobre la calidad de nuestro dataset y posibles sesgos que podrían confundir a nuestra IA.\n",
    "\n",
    "**¿Por qué es crucial para nuestra IA?**\n",
    "- **Sesgos ocultos**: Los nulos pueden indicar patrones sistemáticos que sesgarían el aprendizaje\n",
    "- **Estrategias de imputación**: Decidir cómo manejar información faltante afecta directamente la precisión del modelo\n",
    "- **Robustez del modelo**: Una IA entrenada con datos incompletos debe saber manejar incertidumbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e48eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🔍 {'='*50}\")\n",
    "print(\"   CAPÍTULO 1.1: DETECTANDO IMPERFECCIONES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Análisis de nulos en DataFrame de batallas\n",
    "if len(df_battles) > 0:\n",
    "    nulls_battles = df_battles.isnull().sum().sort_values(ascending=False)\n",
    "    print(\"\\nNulos en DataFrame de batallas:\")\n",
    "    for col, null_count in nulls_battles.items():\n",
    "        if null_count > 0:\n",
    "            print(f\"  - {col}: {null_count:,} ({null_count/len(df_battles)*100:.1f}%)\")\n",
    "    \n",
    "    # Duplicados\n",
    "    dupes_battles = df_battles.duplicated().sum()\n",
    "    print(f\"\\nDuplicados exactos en batallas: {dupes_battles:,}\")\n",
    "    \n",
    "    # Duplicados por battle_id\n",
    "    dupes_by_id = df_battles['battle_id'].duplicated().sum()\n",
    "    print(f\"Batallas con battle_id duplicado: {dupes_by_id:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490ffea",
   "metadata": {},
   "source": [
    "## Capítulo 1.2: El ADN de Nuestros Datos\n",
    "\n",
    "**¿Qué tipo de información tenemos realmente?**\n",
    "\n",
    "Cada variable en nuestro dataset tiene una personalidad única. Algunas son categóricas (como especies de Pokemon), otras numéricas (como HP), y algunas tienen miles de valores únicos mientras otras solo unos pocos. Entender esta diversidad es crucial para que nuestra IA aprenda correctamente.\n",
    "\n",
    "**El impacto en el entrenamiento:**\n",
    "- **Variables categóricas**: Requieren encoding especial para que la IA las entienda\n",
    "- **Alta cardinalidad**: Puede causar overfitting si no se maneja correctamente\n",
    "- **Tipos incorrectos**: Pueden hacer que la IA malinterprete patrones importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b23cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🧬 {'='*50}\")\n",
    "print(\"   CAPÍTULO 1.2: EL ADN DE LOS DATOS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(df_battles) > 0:\n",
    "    audit_battles = (df_battles.dtypes.to_frame('dtype')\n",
    "                    .assign(cardinalidad=df_battles.nunique(),\n",
    "                           nulos=df_battles.isnull().sum(),\n",
    "                           pct_nulos=(df_battles.isnull().sum()/len(df_battles)*100).round(2))\n",
    "                    .sort_values('cardinalidad', ascending=False))\n",
    "    \n",
    "    print(\"\\nAuditoría DataFrame batallas:\")\n",
    "    print(audit_battles)\n",
    "    \n",
    "    # Guardar auditoría\n",
    "    audit_path = OUTPUT_DIR / 'data_audit_battles.csv'\n",
    "    audit_battles.to_csv(audit_path)\n",
    "    print(f\"\\nAuditoría guardada: {audit_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a1164",
   "metadata": {},
   "source": [
    "## Capítulo 2: Los Secretos de la Victoria\n",
    "\n",
    "**¿Qué separa a los ganadores de los perdedores?**\n",
    "\n",
    "En el mundo Pokemon, cada batalla cuenta una historia. Algunas terminan rápidamente con estrategias agresivas, otras se extienden en duelos épicos de resistencia. Nuestra IA debe aprender a leer estas historias y entender qué patrones llevan al éxito.\n",
    "\n",
    "**Las lecciones ocultas en cada resultado:**\n",
    "- **Balance del dataset**: ¿Favorece nuestro dataset a algún jugador? Un sesgo aquí crearía una IA injusta\n",
    "- **Razones de victoria**: ¿Ganan por knockout directo o por estrategias más sutiles?\n",
    "- **Duración vs éxito**: ¿Las batallas rápidas o largas tienen más probabilidad de éxito?\n",
    "- **Patrones temporales**: ¿Hay momentos clave donde se decide el resultado?\n",
    "\n",
    "Estos insights guiarán el diseño de la función de recompensa de nuestra IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n⚔️ {'='*50}\")\n",
    "print(\"   CAPÍTULO 2: LOS SECRETOS DE LA VICTORIA\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Análisis de ganadores\n",
    "winner_counts = df_battles['winner'].value_counts()\n",
    "print(f\"Distribución de ganadores:\")\n",
    "for winner, count in winner_counts.items():\n",
    "    print(f\"  - {winner}: {count:,} ({count/len(df_battles)*100:.1f}%)\")\n",
    "\n",
    "# Razones de victoria\n",
    "reason_counts = df_battles['reason'].value_counts()\n",
    "print(f\"\\nRazones de finalización:\")\n",
    "for reason, count in reason_counts.items():\n",
    "    print(f\"  - {reason}: {count:,} ({count/len(df_battles)*100:.1f}%)\")\n",
    "\n",
    "# Estadísticas de duración\n",
    "print(f\"\\nEstadísticas de duración de batalla:\")\n",
    "print(f\"  - Turnos promedio: {df_battles['total_turns'].mean():.1f}\")\n",
    "print(f\"  - Turnos mediana: {df_battles['total_turns'].median():.1f}\")\n",
    "print(f\"  - Turnos min/max: {df_battles['total_turns'].min()}/{df_battles['total_turns'].max()}\")\n",
    "\n",
    "# Análisis de balance de clases\n",
    "print(f\"\\nBalance de clases (winner):\")\n",
    "balance = df_battles['winner'].value_counts(normalize=True).mul(100).round(2)\n",
    "for winner, pct in balance.items():\n",
    "    print(f\"  - {winner}: {pct}%\")\n",
    "\n",
    "# Mostrar primeras filas del DataFrame\n",
    "print(f\"\\nPrimeras 5 batallas procesadas:\")\n",
    "print(df_battles[['battle_id', 'total_turns', 'winner', 'reason', 'move_events', 'switch_events']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143f42cb",
   "metadata": {},
   "source": [
    "## 3. Análisis de patrones de batalla\n",
    "\n",
    "**Valor del análisis de patrones:**\n",
    "- Los eventos por batalla (movimientos, switches, daño) son las acciones que debe aprender la IA\n",
    "- La correlación turnos-eventos nos indica la intensidad estratégica de las batallas\n",
    "- Los patrones por ganador revelan qué comportamientos llevan al éxito\n",
    "- El ratio movimientos/switches indica agresividad vs cautela en las estrategias\n",
    "- Estos insights guiarán el diseño de la función de recompensa del modelo de IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🎯 {'='*50}\")\n",
    "print(\"   CAPÍTULO 3: PATRONES DE COMBATE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Análisis de eventos por batalla\n",
    "print(f\"Eventos por batalla:\")\n",
    "print(f\"  - Eventos totales promedio: {df_battles['total_events'].mean():.1f}\")\n",
    "print(f\"  - Movimientos promedio: {df_battles['move_events'].mean():.1f}\")\n",
    "print(f\"  - Switches promedio: {df_battles['switch_events'].mean():.1f}\")\n",
    "print(f\"  - Eventos de daño promedio: {df_battles['damage_events'].mean():.1f}\")\n",
    "\n",
    "# Relación entre duración y eventos\n",
    "correlation = df_battles['total_turns'].corr(df_battles['total_events'])\n",
    "print(f\"\\nCorrelación turnos-eventos: {correlation:.3f}\")\n",
    "\n",
    "# Análisis por ganador\n",
    "print(f\"\\nPatrones por ganador:\")\n",
    "for winner in ['p1', 'p2']:\n",
    "    winner_data = df_battles[df_battles['winner'] == winner]\n",
    "    if len(winner_data) > 0:\n",
    "        print(f\"  {winner}:\")\n",
    "        print(f\"    - Turnos promedio: {winner_data['total_turns'].mean():.1f}\")\n",
    "        print(f\"    - Eventos promedio: {winner_data['total_events'].mean():.1f}\")\n",
    "        print(f\"    - Ratio movimientos/switches: {winner_data['move_events'].mean() / max(winner_data['switch_events'].mean(), 1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6058e6e",
   "metadata": {},
   "source": [
    "## 3.1 Análisis de distribuciones y outliers\n",
    "\n",
    "**Importancia del análisis de distribuciones:**\n",
    "- Identifica outliers que pueden sesgar el modelo\n",
    "- Revela la forma de las distribuciones para seleccionar algoritmos apropiados\n",
    "- Detecta patrones anómalos en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5581838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n📊 {'='*50}\")\n",
    "print(\"   CAPÍTULO 3.1: DISTRIBUCIONES Y ANOMALÍAS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Análisis de distribuciones para variables numéricas clave\n",
    "num_cols = ['total_turns', 'total_events', 'move_events', 'switch_events', 'events_per_turn']\n",
    "\n",
    "if len(df_battles) > 0:\n",
    "    # Histogramas de distribuciones\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Distribuciones de Variables Numéricas Clave', fontsize=16)\n",
    "    \n",
    "    for i, col in enumerate(num_cols):\n",
    "        row, col_idx = divmod(i, 3)\n",
    "        if col in df_battles.columns:\n",
    "            axes[row, col_idx].hist(df_battles[col].dropna(), bins=30, alpha=0.7, edgecolor='black', color=plot_colors['histogram'])\n",
    "            axes[row, col_idx].set_title(f'Distribución: {col}')\n",
    "            axes[row, col_idx].set_xlabel(col)\n",
    "            axes[row, col_idx].set_ylabel('Frecuencia')\n",
    "            \n",
    "            # Añadir líneas de media y mediana\n",
    "            mean_val = df_battles[col].mean()\n",
    "            median_val = df_battles[col].median()\n",
    "            axes[row, col_idx].axvline(mean_val, color='red', linestyle='--', alpha=0.7, label=f'Media: {mean_val:.1f}')\n",
    "            axes[row, col_idx].axvline(median_val, color='green', linestyle='--', alpha=0.7, label=f'Mediana: {median_val:.1f}')\n",
    "            axes[row, col_idx].legend()\n",
    "    \n",
    "    # Eliminar subplot vacío\n",
    "    if len(num_cols) < 6:\n",
    "        fig.delaxes(axes[1, 2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'distributions_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualizaciones guardadas para análisis posterior\n",
    "    \n",
    "    # Análisis de outliers usando IQR\n",
    "    print(f\"\\nDetección de outliers (método IQR):\")\n",
    "    for col in num_cols:\n",
    "        if col in df_battles.columns:\n",
    "            Q1 = df_battles[col].quantile(0.25)\n",
    "            Q3 = df_battles[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = df_battles[(df_battles[col] < lower_bound) | (df_battles[col] > upper_bound)]\n",
    "            pct_outliers = len(outliers) / len(df_battles) * 100\n",
    "            \n",
    "            print(f\"  - {col}: {len(outliers)} outliers ({pct_outliers:.1f}%)\")\n",
    "    \n",
    "    # Boxplots por ganador\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    key_vars = ['total_turns', 'move_events', 'switch_events']\n",
    "    # Colores específicos para boxplots\n",
    "    boxplot_colors = [pokemon_colors['fire'], pokemon_colors['water']]\n",
    "    \n",
    "    for i, var in enumerate(key_vars):\n",
    "        if var in df_battles.columns:\n",
    "            sns.boxplot(data=df_battles, x='winner', y=var, ax=axes[i], \n",
    "                       hue='winner', palette=boxplot_colors, legend=False)\n",
    "            axes[i].set_title(f'{var} por Ganador')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'boxplots_by_winner.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Análisis comparativo por ganador completado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2097ee",
   "metadata": {},
   "source": [
    "## 4. Análisis de uso de Pokemon\n",
    "\n",
    "**Importancia del análisis de Pokemon:**\n",
    "- Identificamos el 'meta' actual: qué Pokemon son más populares y por qué\n",
    "- Los niveles y HP nos dan información sobre el balance del juego\n",
    "- La frecuencia de uso indica qué Pokemon debe priorizar la IA en sus decisiones\n",
    "- Esta información es crucial para que la IA entienda amenazas y oportunidades\n",
    "- Los Pokemon más utilizados probablemente tienen estrategias más desarrolladas en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🎮 {'='*50}\")\n",
    "print(\"   CAPÍTULO 4: LOS PROTAGONISTAS DEL META\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Extraer información de Pokemon\n",
    "all_pokemon = []\n",
    "for battle in battles:\n",
    "    pokemon_info = extract_pokemon_info(battle)\n",
    "    for pokemon in pokemon_info:\n",
    "        pokemon['winner'] = get_in(battle, ['metadata', 'outcome', 'winner'])\n",
    "        all_pokemon.append(pokemon)\n",
    "\n",
    "df_pokemon = pd.DataFrame(all_pokemon)\n",
    "\n",
    "if len(df_pokemon) > 0:\n",
    "    # Pokemon más utilizados\n",
    "    species_counts = df_pokemon['species'].value_counts()\n",
    "    print(f\"Top 10 Pokemon más utilizados:\")\n",
    "    for i, (species, count) in enumerate(species_counts.head(10).items(), 1):\n",
    "        print(f\"  - {species}: {count:,} usos\")\n",
    "    \n",
    "    # Análisis de niveles\n",
    "    print(f\"\\nDistribución de niveles:\")\n",
    "    print(f\"  - Nivel promedio: {df_pokemon['level'].mean():.1f}\")\n",
    "    print(f\"  - Nivel mediana: {df_pokemon['level'].median():.1f}\")\n",
    "    print(f\"  - Rango de niveles: {df_pokemon['level'].min()}-{df_pokemon['level'].max()}\")\n",
    "    \n",
    "    # Análisis de HP\n",
    "    hp_data = df_pokemon.dropna(subset=['hp'])\n",
    "    if len(hp_data) > 0:\n",
    "        print(f\"\\nEstadísticas de HP:\")\n",
    "        print(f\"  - HP promedio: {hp_data['hp'].mean():.1f}\")\n",
    "        print(f\"  - HP mediana: {hp_data['hp'].median():.1f}\")\n",
    "        print(f\"  - Rango HP: {hp_data['hp'].min()}-{hp_data['hp'].max()}\")\n",
    "\n",
    "print(f\"\\n📋 Resumen del análisis Pokemon:\")\n",
    "print(f\"   • {len(df_pokemon)} registros de Pokemon analizados\")\n",
    "print(f\"   • {df_pokemon['species'].nunique()} especies únicas identificadas\")\n",
    "print(f\"   • Nivel promedio del meta: {df_pokemon['level'].mean():.1f}\")\n",
    "\n",
    "if len(df_pokemon) > 0:\n",
    "    # Análisis de completitud de datos\n",
    "    nulls_pokemon = df_pokemon.isnull().sum().sort_values(ascending=False)\n",
    "    critical_nulls = [(col, count) for col, count in nulls_pokemon.items() if count > 0 and count/len(df_pokemon) > 0.1]\n",
    "    if critical_nulls:\n",
    "        print(f\"\\n⚠️  Datos faltantes significativos:\")\n",
    "        for col, null_count in critical_nulls[:5]:  # Solo top 5\n",
    "            print(f\"   • {col}: {null_count/len(df_pokemon)*100:.1f}% faltante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582145b5",
   "metadata": {},
   "source": [
    "## 5. Visualizaciones clave para entrenamiento de IA\n",
    "\n",
    "**Visualizaciones seleccionadas:**\n",
    "- **Distribución de duración**: Muestra la variabilidad de estrategias (rápidas vs largas)\n",
    "- **Eventos vs turnos**: Revela la intensidad de acción, clave para modelar decisiones\n",
    "- **Patrones por ganador**: Identifica comportamientos exitosos que la IA debe imitar\n",
    "- **Razones de finalización**: Enseña a la IA los diferentes caminos hacia la victoria\n",
    "- Estas gráficas nos ayudan a validar hipótesis y comunicar insights del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871db594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Análisis de Patrones de Batalla Pokemon', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Distribución de duración de batallas\n",
    "axes[0, 0].hist(df_battles['total_turns'], bins=30, alpha=0.7, color=plot_colors['histogram'], edgecolor='black')\n",
    "axes[0, 0].set_title('Distribución de Duración de Batallas')\n",
    "axes[0, 0].set_xlabel('Número de Turnos')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].axvline(df_battles['total_turns'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Media: {df_battles[\"total_turns\"].mean():.1f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Eventos por turno\n",
    "axes[0, 1].scatter(df_battles['total_turns'], df_battles['events_per_turn'], \n",
    "                   alpha=0.6, color=plot_colors['scatter'])\n",
    "axes[0, 1].set_title('Eventos por Turno vs Duración')\n",
    "axes[0, 1].set_xlabel('Número de Turnos')\n",
    "axes[0, 1].set_ylabel('Eventos por Turno')\n",
    "\n",
    "# 3. Comparación de patrones por ganador\n",
    "winner_data = df_battles.groupby('winner').agg({\n",
    "    'total_turns': 'mean',\n",
    "    'move_events': 'mean',\n",
    "    'switch_events': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "x = range(len(winner_data))\n",
    "width = 0.25\n",
    "\n",
    "# Colores diferenciados para cada métrica\n",
    "bar_colors = [pokemon_colors['fire'], pokemon_colors['water'], pokemon_colors['electric']]\n",
    "\n",
    "axes[1, 0].bar([i - width for i in x], winner_data['total_turns'], width, \n",
    "               label='Turnos Promedio', alpha=0.8, color=bar_colors[0], \n",
    "               edgecolor='black', linewidth=1.2)\n",
    "axes[1, 0].bar(x, winner_data['move_events'], width, \n",
    "               label='Movimientos Promedio', alpha=0.8, color=bar_colors[1],\n",
    "               edgecolor='black', linewidth=1.2)\n",
    "axes[1, 0].bar([i + width for i in x], winner_data['switch_events'], width, \n",
    "               label='Switches Promedio', alpha=0.8, color=bar_colors[2],\n",
    "               edgecolor='black', linewidth=1.2)\n",
    "axes[1, 0].set_title('Patrones por Ganador')\n",
    "axes[1, 0].set_xlabel('Ganador')\n",
    "axes[1, 0].set_ylabel('Cantidad')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(winner_data['winner'])\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. Razón de finalización\n",
    "reason_counts = df_battles['reason'].value_counts()\n",
    "axes[1, 1].pie(reason_counts.values, labels=reason_counts.index, autopct='%1.1f%%', colors=primary_palette)\n",
    "axes[1, 1].set_title('Razones de Finalización')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'battle_patterns_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Visualización guardada: {OUTPUT_DIR / 'battle_patterns_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd7d71",
   "metadata": {},
   "source": [
    "## 6. Análisis visual de Pokemon\n",
    "\n",
    "**Enfoque del análisis visual:**\n",
    "- **Top Pokemon**: La IA debe conocer las amenazas más comunes del meta\n",
    "- **Distribución de niveles**: Entiende el rango de poder esperado en batallas\n",
    "- **HP vs Nivel**: Revela la relación entre estadísticas, crucial para cálculos de daño\n",
    "- **Distribución por género**: Algunos movimientos y habilidades dependen del género\n",
    "- Estas visualizaciones informan las decisiones de selección de equipo de la IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044293a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_pokemon) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Análisis de Pokemon en Batallas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Top Pokemon más utilizados\n",
    "    top_pokemon = df_pokemon['species'].value_counts().head(15)\n",
    "    axes[0, 0].barh(range(len(top_pokemon)), top_pokemon.values, color=plot_colors['bar'])\n",
    "    axes[0, 0].set_yticks(range(len(top_pokemon)))\n",
    "    axes[0, 0].set_yticklabels(top_pokemon.index)\n",
    "    axes[0, 0].set_title('Top 15 Pokemon Más Utilizados')\n",
    "    axes[0, 0].set_xlabel('Número de Usos')\n",
    "    \n",
    "    # 2. Distribución de niveles\n",
    "    axes[0, 1].hist(df_pokemon['level'].dropna(), bins=20, alpha=0.7, color=plot_colors['histogram'], edgecolor='black')\n",
    "    axes[0, 1].set_title('Distribución de Niveles de Pokemon')\n",
    "    axes[0, 1].set_xlabel('Nivel')\n",
    "    axes[0, 1].set_ylabel('Frecuencia')\n",
    "    \n",
    "    # 3. HP vs Nivel\n",
    "    hp_level_data = df_pokemon.dropna(subset=['hp', 'level'])\n",
    "    if len(hp_level_data) > 0:\n",
    "        axes[1, 0].scatter(hp_level_data['level'], hp_level_data['hp'], alpha=0.6, color=plot_colors['scatter'])\n",
    "        axes[1, 0].set_title('HP vs Nivel de Pokemon')\n",
    "        axes[1, 0].set_xlabel('Nivel')\n",
    "        axes[1, 0].set_ylabel('HP')\n",
    "    \n",
    "    # 4. Distribución por género\n",
    "    gender_counts = df_pokemon['gender'].value_counts()\n",
    "    axes[1, 1].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', colors=primary_palette)\n",
    "    axes[1, 1].set_title('Distribución por Género')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'pokemon_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Visualización guardada: {OUTPUT_DIR / 'pokemon_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01930c4c",
   "metadata": {},
   "source": [
    "## 7. Extracción de features para entrenamiento de IA\n",
    "\n",
    "**Features seleccionados:**\n",
    "- **Métricas de batalla**: Duración, eventos, ratios - capturan el 'estilo' de juego\n",
    "- **Ratings de jugadores**: Proxy del nivel de habilidad, importante para el aprendizaje\n",
    "- **Información de equipos**: Tamaño, niveles promedio - contexto estratégico\n",
    "- **Patrones temporales**: Eventos por turno - ritmo de juego que debe aprender la IA\n",
    "- Estos features formarán el input del modelo de machine learning para toma de decisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ff8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACCIÓN DE FEATURES PARA IA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Features avanzadas a nivel de batalla para IA\n",
    "battle_features = []\n",
    "\n",
    "print(\"Extrayendo features avanzadas para entrenamiento de IA...\")\n",
    "for i, battle in enumerate(battles):\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f\"Procesadas {i + 1} batallas...\")\n",
    "    \n",
    "    # Métricas básicas mejoradas\n",
    "    metrics = calculate_battle_metrics(battle)\n",
    "    \n",
    "    # Features de composición de equipos\n",
    "    team_features = extract_team_composition_features(battle)\n",
    "    \n",
    "    # Combinar todas las features\n",
    "    features = {\n",
    "        'battle_id': battle.get('battle_id'),\n",
    "        'total_turns': metrics['total_turns'],\n",
    "        'winner': metrics['winner'],\n",
    "        'reason': metrics['reason'],\n",
    "        'move_events': metrics['move_events'],\n",
    "        'switch_events': metrics['switch_events'],\n",
    "        'damage_events': metrics['damage_events'],\n",
    "        'effect_events': metrics['effect_events'],\n",
    "        'heal_events': metrics['heal_events'],\n",
    "        'status_events': metrics['status_events'],\n",
    "        'events_per_turn': metrics['events_per_turn'],\n",
    "        'early_game_intensity': metrics['early_game_intensity'],\n",
    "        'mid_game_intensity': metrics['mid_game_intensity'],\n",
    "        'late_game_intensity': metrics['late_game_intensity'],\n",
    "        'move_switch_ratio': metrics['move_switch_ratio'],\n",
    "        'consecutive_moves': metrics['consecutive_moves'],\n",
    "        'consecutive_switches': metrics['consecutive_switches'],\n",
    "        'action_diversity': metrics['action_diversity']\n",
    "    }\n",
    "    \n",
    "    # Información de jugadores\n",
    "    players = battle.get('players', {})\n",
    "    for player_id in ['p1', 'p2']:\n",
    "        player_info = players.get(player_id, {})\n",
    "        features[f'{player_id}_rating'] = player_info.get('ladder_rating_pre', 0)\n",
    "    \n",
    "    # Agregar features de composición de equipos\n",
    "    features.update(team_features)\n",
    "    \n",
    "    # Features de ventaja competitiva\n",
    "    if features['p1_rating'] and features['p2_rating']:\n",
    "        features['rating_difference'] = abs(features['p1_rating'] - features['p2_rating'])\n",
    "        features['rating_advantage_p1'] = features['p1_rating'] - features['p2_rating']\n",
    "    else:\n",
    "        features['rating_difference'] = 0\n",
    "        features['rating_advantage_p1'] = 0\n",
    "    \n",
    "    # Features de balance de equipos\n",
    "    features['team_size_difference'] = abs(features['p1_team_size'] - features['p2_team_size'])\n",
    "    features['level_advantage_p1'] = features['p1_avg_level'] - features['p2_avg_level']\n",
    "    features['hp_advantage_p1'] = features['p1_total_hp'] - features['p2_total_hp']\n",
    "    features['info_advantage_p1'] = features['p1_info_advantage'] - features['p2_info_advantage']\n",
    "    \n",
    "    battle_features.append(features)\n",
    "\n",
    "df_features = pd.DataFrame(battle_features)\n",
    "\n",
    "# Guardar features\n",
    "features_path = OUTPUT_DIR / 'battle_features.csv'\n",
    "df_features.to_csv(features_path, index=False)\n",
    "\n",
    "print(f\"✅ Extracción completada:\")\n",
    "print(f\"   • {len(df_features.columns)} características por batalla\")\n",
    "print(f\"   • {len(df_features)} batallas procesadas\")\n",
    "print(f\"   • Dataset guardado: {features_path.name}\")\n",
    "\n",
    "# Mostrar correlaciones importantes\n",
    "numeric_cols = df_features.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_cols) > 1:\n",
    "    correlations = df_features[numeric_cols].corr()\n",
    "    print(f\"\\nCorrelaciones más altas con 'total_turns':\")\n",
    "    turn_corr = correlations['total_turns'].abs().sort_values(ascending=False)\n",
    "    for feature, corr in turn_corr.head(5).items():\n",
    "        if feature != 'total_turns':\n",
    "            print(f\"  - {feature}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\nPrimeras 5 filas del dataset de features:\")\n",
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b73f238",
   "metadata": {},
   "source": [
    "## 7.1 Validación rápida con modelo baseline\n",
    "\n",
    "**Propósito del modelo baseline:**\n",
    "- Establece una línea base de rendimiento para comparar modelos futuros\n",
    "- Valida que las features tienen poder predictivo\n",
    "- Identifica las variables más importantes\n",
    "- Detecta posibles problemas de data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4381ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🎯 {'='*50}\")\n",
    "print(\"   VALIDACIÓN: MODELO BASELINE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Preparar datos para modelo baseline\n",
    "try:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import roc_auc_score, classification_report\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "    \n",
    "    # Seleccionar features numéricas para el baseline\n",
    "    numeric_features = df_features.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remover variables que no deben usarse para predicción\n",
    "    exclude_cols = ['battle_id'] if 'battle_id' in numeric_features else []\n",
    "    feature_cols = [col for col in numeric_features if col not in exclude_cols]\n",
    "    \n",
    "    # Preparar target\n",
    "    if 'winner' in df_features.columns:\n",
    "        # Filtrar solo batallas con ganador definido\n",
    "        valid_battles = df_features[df_features['winner'].isin(['p1', 'p2'])].copy()\n",
    "        \n",
    "        if len(valid_battles) > 10 and len(feature_cols) > 0:  # Mínimo para entrenar\n",
    "            X = valid_battles[feature_cols].fillna(0)  # Imputar nulos con 0\n",
    "            y = valid_battles['winner']\n",
    "            \n",
    "            # Codificar target\n",
    "            le = LabelEncoder()\n",
    "            y_encoded = le.fit_transform(y)\n",
    "            \n",
    "            # Split train/test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Escalar features para mejorar convergencia\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Entrenar modelo baseline con features escaladas\n",
    "            clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "            clf.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Evaluar con datos escalados\n",
    "            y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "            auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            print(f\"Modelo baseline entrenado:\")\n",
    "            print(f\"  - Features utilizadas: {len(feature_cols)}\")\n",
    "            print(f\"  - Tamaño entrenamiento: {len(X_train):,}\")\n",
    "            print(f\"  - Tamaño test: {len(X_test):,}\")\n",
    "            print(f\"  - ROC-AUC: {auc_score:.3f}\")\n",
    "            \n",
    "            # Importancia de features\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': feature_cols,\n",
    "                'importance': np.abs(clf.coef_[0])\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(f\"\\nTop 10 features más importantes:\")\n",
    "            for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):\n",
    "                print(f\"  {i:2d}. {row['feature']}: {row['importance']:.3f}\")\n",
    "            \n",
    "            # Guardar importancia de features\n",
    "            importance_path = OUTPUT_DIR / 'feature_importance_baseline.csv'\n",
    "            feature_importance.to_csv(importance_path, index=False)\n",
    "            print(f\"\\nImportancia guardada: {importance_path}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Datos insuficientes para entrenar modelo baseline\")\n",
    "    else:\n",
    "        print(\"Variable 'winner' no encontrada para modelo baseline\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Scikit-learn no disponible. Instalar con: pip install scikit-learn\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en modelo baseline: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7691e5df",
   "metadata": {},
   "source": [
    "## 8. Matriz de correlación de features numéricas\n",
    "\n",
    "**Propósito del análisis de correlaciones:**\n",
    "- Identificamos features redundantes que pueden confundir al modelo\n",
    "- Detectamos relaciones no obvias entre variables que pueden ser útiles\n",
    "- Ayuda a seleccionar las features más informativas para el entrenamiento\n",
    "- Previene problemas de multicolinealidad en modelos lineales\n",
    "- Guía la ingeniería de features y la selección de variables para el modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de correlación para features numéricas\n",
    "numeric_features = df_features.select_dtypes(include=[np.number])\n",
    "\n",
    "if len(numeric_features.columns) > 1:\n",
    "    correlation_matrix = numeric_features.corr()\n",
    "    \n",
    "    # Matriz completa (sin anotaciones para mejor legibilidad)\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(correlation_matrix, annot=False, cmap=plot_colors['heatmap'], center=0, \n",
    "                square=True, cbar_kws={'shrink': 0.8})\n",
    "    plt.title('Matriz de Correlación Completa - Features Numéricas', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "    plt.yticks(rotation=0, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'correlation_matrix_full.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Matriz de correlaciones más altas (filtrada)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    # Seleccionar solo correlaciones > 0.3 o < -0.3 con target variables\n",
    "    target_vars = ['total_turns', 'total_events', 'move_events', 'switch_events', 'events_per_turn']\n",
    "    important_vars = []\n",
    "    \n",
    "    for var in target_vars:\n",
    "        if var in correlation_matrix.columns:\n",
    "            corrs = correlation_matrix[var].abs().sort_values(ascending=False)\n",
    "            # Tomar top 8 correlaciones para cada variable target\n",
    "            important_vars.extend(corrs.head(8).index.tolist())\n",
    "    \n",
    "    # Eliminar duplicados y mantener orden\n",
    "    important_vars = list(dict.fromkeys(important_vars))[:20]  # Máximo 20 variables\n",
    "    \n",
    "    if len(important_vars) > 1:\n",
    "        filtered_corr = correlation_matrix.loc[important_vars, important_vars]\n",
    "        sns.heatmap(filtered_corr, annot=True, cmap=plot_colors['heatmap'], center=0, \n",
    "                    square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "        plt.title('Matriz de Correlación - Variables Más Importantes', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / 'correlation_matrix_filtered.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"📊 Matrices de correlación generadas:\")\n",
    "        print(f\"   • Matriz completa: visión general de todas las variables\")\n",
    "        print(f\"   • Matriz filtrada: enfoque en variables más relevantes\")\n",
    "    else:\n",
    "        print(\"No hay suficientes variables para matriz filtrada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbef7ea",
   "metadata": {},
   "source": [
    "---\n",
    "# Epílogo: El camino hacia la maestría\n",
    "\n",
    "**Nuestra investigación llega a su fin, pero el verdadero viaje apenas comienza.**\n",
    "\n",
    "Hemos desentrañado los secretos de miles de batallas Pokemon, identificado a los campeones del meta, descubierto patrones temporales, y destilado todo este conocimiento en características que una IA puede aprender. \n",
    "\n",
    "## 9. Resumen ejecutivo para entrenamiento de IA\n",
    "\n",
    "**Los hallazgos de nuestra expedición:**\n",
    "\n",
    "Como exploradores que regresan de una tierra desconocida, traemos mapas, tesoros y sabiduría. Estos son los insights que guiarán la creación de nuestra IA Pokemon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca829d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN EJECUTIVO PARA ENTRENAMIENTO DE IA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"## La Sabiduría Extraída de Nuestro Viaje:\n",
    "\n",
    "### 1. La Confiabilidad de Nuestros Datos:\n",
    "   - Hemos analizado {len(battles):,} batallas reales y verificadas\n",
    "   - Formato gen9randombattle: el estándar competitivo actual\n",
    "   - Cada batalla cuenta una historia completa con {len(df_features.columns)} características extraídas\n",
    "\n",
    "### 2. Los Secretos de las Batallas Exitosas:\n",
    "   - Las batallas competitivas duran en promedio {df_battles['total_turns'].mean():.1f} turnos\n",
    "   - El momentum cambia según la fase: early-game vs late-game tienen dinámicas diferentes\n",
    "   - Los patrones de switching y timing son más predictivos que las estadísticas brutas\n",
    "\n",
    "### 3. El Arsenal Avanzado de Conocimiento para Nuestra IA:\n",
    "   - **Features Temporales**: Intensidad por fase de batalla (early/mid/late game)\n",
    "   - **Patrones de Decisión**: Ratios move/switch, acciones consecutivas, diversidad de acciones\n",
    "   - **Composición de Equipos**: Diversidad de especies, distribución de niveles, ventajas de HP\n",
    "   - **Información Estratégica**: Habilidades conocidas, items revelados, movimientos descubiertos\n",
    "   - **Ventajas Competitivas**: Diferencias de rating, balance de equipos, ventajas de información\n",
    "\n",
    "### 4. La Estrategia de Entrenamiento Revolucionaria:\n",
    "   - **Aprendizaje por Fases**: La IA debe adaptar estrategias según early/mid/late game\n",
    "   - **Momentum Awareness**: Detectar cambios en intensidad y patrones de acción\n",
    "   - **Information Advantage**: Usar conocimiento parcial del oponente estratégicamente\n",
    "   - **Team Synergy**: Entender composiciones de equipo y sus fortalezas/debilidades\n",
    "   - **Adaptive Decision Making**: Cambiar entre agresión y conservación según el contexto\n",
    "\n",
    "### 5. El Mapa Definitivo hacia la Maestría:\n",
    "   - **Arquitectura Híbrida**: CNN para patrones + LSTM para secuencias temporales + Attention para decisiones críticas\n",
    "   - **Multi-Task Learning**: Predecir próximo movimiento + resultado de batalla + timing óptimo\n",
    "   - **Curriculum Learning**: Entrenar primero en batallas simples, luego en escenarios complejos\n",
    "   - **Adversarial Training**: IA vs IA para desarrollar estrategias anti-meta\n",
    "   - **Continual Learning**: Adaptación automática a cambios en el meta competitivo\n",
    "   - **Explainable AI**: Sistema de explicación de decisiones para análisis estratégico\n",
    "\n",
    "### 6. Features Críticas Implementadas (NUEVO):\n",
    "   - **{len([c for c in df_features.columns if 'intensity' in c])} métricas de intensidad** por fase de batalla\n",
    "   - **{len([c for c in df_features.columns if 'advantage' in c])} indicadores de ventaja** estratégica\n",
    "   - **{len([c for c in df_features.columns if 'diversity' in c or 'ratio' in c])} métricas de diversidad** y patrones\n",
    "   - **Información de revelación progresiva** para decisiones bajo incertidumbre\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cc41e",
   "metadata": {},
   "source": [
    "## 10. Estadísticas finales y archivos generados\n",
    "\n",
    "**Importancia de la documentación:**\n",
    "- Proporciona un inventario completo de los artefactos generados\n",
    "- Facilita la reproducibilidad del análisis\n",
    "- Permite validar que todos los pasos se ejecutaron correctamente\n",
    "- Sirve como checklist para asegurar que no falta ningún componente\n",
    "- Documenta el punto de partida para la siguiente fase del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15418188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"NUESTRA EXPEDICIÓN HA CONCLUIDO\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(\"\\n** El conocimiento ha sido extraído, los patrones revelados. **\")\n",
    "print(\"** Nuestra IA ahora tiene el mapa para convertirse en maestra Pokemon. **\")\n",
    "\n",
    "print(f\"\\nArchivos generados en: {OUTPUT_DIR.resolve()}\")\n",
    "output_files = list(OUTPUT_DIR.glob(\"*\"))\n",
    "for file in output_files:\n",
    "    print(f\"  - {file.name}\")\n",
    "\n",
    "print(f\"\\nTesoros de conocimiento recolectados:\")\n",
    "print(f\"  - Historias de batalla analizadas: {len(df_battles)} registros\")\n",
    "print(f\"  - Protagonistas Pokemon catalogados: {len(df_pokemon)} registros\")\n",
    "print(f\"  - Características estratégicas extraídas: {len(df_features)} registros\")\n",
    "print(f\"  - Features avanzadas implementadas: {len(df_features.columns)} dimensiones\")\n",
    "print(f\"  - Métricas de momentum y timing: Implementadas\")\n",
    "print(f\"  - Análisis de composición de equipos: Completo\")\n",
    "print(f\"  - Sistema de ventajas competitivas: Operativo\")\n",
    "print(f\"\\n** La IA ahora tiene acceso a patrones temporales, momentum de batalla,\")\n",
    "print(f\"   composición de equipos y ventajas estratégicas - todo lo necesario\")\n",
    "print(f\"   para decisiones de nivel maestro Pokemon. **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8590502",
   "metadata": {},
   "source": [
    "---\n",
    "# Capítulo 5: ¿Cuándo ocurren las batallas?\n",
    "\n",
    "**El tiempo revela secretos que las estadísticas básicas no pueden mostrar.**\n",
    "\n",
    "¿Hay momentos del día donde los entrenadores más hábiles están activos? ¿Cambian las estrategias con el tiempo? ¿Evoluciona el meta de formas que nuestra IA debe anticipar?\n",
    "\n",
    "## 11. Análisis temporal de batallas\n",
    "\n",
    "**Explorando los ritmos del combate:**\n",
    "- ¿Cuándo luchan los entrenadores más dedicados?\n",
    "- ¿Hay patrones estacionales en las estrategias Pokemon?\n",
    "- ¿Cómo evoluciona el meta a través del tiempo?\n",
    "- ¿Debe nuestra IA adaptarse a diferentes \"épocas\" del juego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd064be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n⏰ {'='*50}\")\n",
    "print(\"   CAPÍTULO 6: PATRONES TEMPORALES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(df_battles) > 0 and 'timestamp' in df_battles.columns:\n",
    "    # Convertir timestamp a datetime\n",
    "    df_battles['datetime'] = pd.to_datetime(df_battles['timestamp'], unit='s', errors='coerce')\n",
    "    \n",
    "    if df_battles['datetime'].notna().sum() > 0:\n",
    "        # Análisis por día de la semana\n",
    "        df_battles['day_of_week'] = df_battles['datetime'].dt.day_name()\n",
    "        battles_by_day = df_battles['day_of_week'].value_counts()\n",
    "        \n",
    "        print(\"Distribución de batallas por día de la semana:\")\n",
    "        for day, count in battles_by_day.items():\n",
    "            print(f\"  - {day}: {count:,} batallas\")\n",
    "        \n",
    "        # Análisis por hora del día\n",
    "        df_battles['hour'] = df_battles['datetime'].dt.hour\n",
    "        battles_by_hour = df_battles['hour'].value_counts().sort_index()\n",
    "        \n",
    "        print(f\"\\nHoras pico de actividad:\")\n",
    "        top_hours = battles_by_hour.head(3)\n",
    "        for hour, count in top_hours.items():\n",
    "            print(f\"  - {hour:02d}:00: {count:,} batallas\")\n",
    "        \n",
    "        # Evolución temporal de duración promedio\n",
    "        df_battles['date'] = df_battles['datetime'].dt.date\n",
    "        daily_avg_turns = df_battles.groupby('date')['total_turns'].mean()\n",
    "        \n",
    "        if len(daily_avg_turns) > 1:\n",
    "            trend = \"creciente\" if daily_avg_turns.iloc[-1] > daily_avg_turns.iloc[0] else \"decreciente\"\n",
    "            print(f\"\\nTendencia en duración de batallas: {trend}\")\n",
    "            print(f\"  - Primer día: {daily_avg_turns.iloc[0]:.1f} turnos promedio\")\n",
    "            print(f\"  - Último día: {daily_avg_turns.iloc[-1]:.1f} turnos promedio\")\n",
    "        \n",
    "        # Visualización temporal\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Batallas por día de la semana\n",
    "        battles_by_day.plot(kind='bar', ax=axes[0], color=plot_colors['bar'])\n",
    "        axes[0].set_title('Batallas por Día de la Semana')\n",
    "        axes[0].set_xlabel('Día')\n",
    "        axes[0].set_ylabel('Número de Batallas')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Batallas por hora\n",
    "        battles_by_hour.plot(kind='line', ax=axes[1], color=plot_colors['line'], marker='o')\n",
    "        axes[1].set_title('Actividad por Hora del Día')\n",
    "        axes[1].set_xlabel('Hora')\n",
    "        axes[1].set_ylabel('Número de Batallas')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / 'temporal_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Análisis temporal guardado: {OUTPUT_DIR / 'temporal_analysis.png'}\")\n",
    "    else:\n",
    "        print(\"No se encontraron timestamps válidos para análisis temporal\")\n",
    "else:\n",
    "    print(\"Columna 'timestamp' no disponible para análisis temporal\")\n",
    "\n",
    "# Crear diccionario de datos para documentación\n",
    "if len(df_features) > 0:\n",
    "    data_dict = (df_features.dtypes.to_frame('dtype')\n",
    "                .assign(\n",
    "                    nunique=df_features.nunique(),\n",
    "                    n_null=df_features.isnull().sum(),\n",
    "                    pct_null=(df_features.isnull().sum()/len(df_features)*100).round(2),\n",
    "                    sample_values=df_features.astype(str).apply(\n",
    "                        lambda s: ', '.join(s.dropna().unique()[:3])\n",
    "                    )\n",
    "                )\n",
    "                .sort_values('nunique', ascending=False))\n",
    "    \n",
    "    # Guardar diccionario de datos\n",
    "    dict_path = OUTPUT_DIR / 'data_dictionary.csv'\n",
    "    data_dict.to_csv(dict_path)\n",
    "    \n",
    "    # Guardar dataset limpio\n",
    "    clean_dataset_path = OUTPUT_DIR / 'dataset_limpio_features.parquet'\n",
    "    df_features.to_parquet(clean_dataset_path, index=False)\n",
    "\n",
    "print(f\"\\n🎯 Análisis EDA completado exitosamente\")\n",
    "\n",
    "# Guardar dataset de batallas\n",
    "battles_clean_path = OUTPUT_DIR / 'dataset_batallas_limpio.parquet'\n",
    "df_battles.to_parquet(battles_clean_path, index=False)\n",
    "\n",
    "# Si hay datos de Pokemon, guardarlos también\n",
    "if len(df_pokemon) > 0:\n",
    "    pokemon_clean_path = OUTPUT_DIR / 'dataset_pokemon_limpio.parquet'\n",
    "    df_pokemon.to_parquet(pokemon_clean_path, index=False)\n",
    "\n",
    "print(f\"\\n✅ Análisis EDA completado - datasets guardados para entrenamiento de IA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4621e1",
   "metadata": {},
   "source": [
    "## 13. Análisis de tipos de Pokemon\n",
    "\n",
    "**Relevancia para la IA:**\n",
    "- Los tipos determinan efectividad de movimientos\n",
    "- Crucial para decisiones estratégicas\n",
    "- Identifica combinaciones de tipos dominantes\n",
    "- Informa sobre balance del meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b003606",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"\\n🔥 {'='*50}\")\n",
    "print(\"   CAPÍTULO 7: ANÁLISIS DE TIPOS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(df_pokemon) > 0:\n",
    "    # Simular tipos basados en especies conocidas (esto debería venir de los datos reales)\n",
    "    # En un caso real, extraerías los tipos de la estructura JSON\n",
    "    type_mapping = {\n",
    "        'Charizard': ['Fire', 'Flying'], 'Blastoise': ['Water'], 'Venusaur': ['Grass', 'Poison'],\n",
    "        'Pikachu': ['Electric'], 'Garchomp': ['Dragon', 'Ground'], 'Metagross': ['Steel', 'Psychic'],\n",
    "        'Tyranitar': ['Rock', 'Dark'], 'Dragonite': ['Dragon', 'Flying'], 'Salamence': ['Dragon', 'Flying'],\n",
    "        'Lucario': ['Fighting', 'Steel'], 'Gengar': ['Ghost', 'Poison'], 'Alakazam': ['Psychic']\n",
    "    }\n",
    "    \n",
    "    # Expandir tipos para análisis\n",
    "    type_analysis = []\n",
    "    for _, pokemon in df_pokemon.iterrows():\n",
    "        species = pokemon['species']\n",
    "        if species in type_mapping:\n",
    "            for ptype in type_mapping[species]:\n",
    "                type_analysis.append({\n",
    "                    'species': species,\n",
    "                    'type': ptype,\n",
    "                    'player': pokemon['player'],\n",
    "                    'winner': pokemon['winner']\n",
    "                })\n",
    "    \n",
    "    if type_analysis:\n",
    "        df_types = pd.DataFrame(type_analysis)\n",
    "        \n",
    "        # Tipos más comunes\n",
    "        type_counts = df_types['type'].value_counts()\n",
    "        print(\"Top 10 tipos más utilizados:\")\n",
    "        for i, (ptype, count) in enumerate(type_counts.head(10).items(), 1):\n",
    "            print(f\"  {i:2d}. {ptype}: {count:,} usos\")\n",
    "        \n",
    "        # Análisis de efectividad por tipo\n",
    "        if 'winner' in df_types.columns:\n",
    "            # Calcular winrates por tipo (evitando FutureWarning)\n",
    "            type_stats = []\n",
    "            for ptype in df_types['type'].unique():\n",
    "                type_data = df_types[df_types['type'] == ptype]\n",
    "                if len(type_data) > 10:\n",
    "                    winrate = (type_data['winner'] == type_data['player']).mean()\n",
    "                    type_stats.append({'type': ptype, 'winrate': winrate})\n",
    "            \n",
    "            if type_stats:\n",
    "                type_winrates = pd.DataFrame(type_stats).set_index('type')['winrate'].sort_values(ascending=False)\n",
    "            \n",
    "            if len(type_winrates) > 0:\n",
    "                print(f\"\\nTipos con mejor winrate (mín. 10 usos):\")\n",
    "                for ptype, winrate in type_winrates.head(5).items():\n",
    "                    print(f\"  - {ptype}: {winrate:.1%}\")\n",
    "        \n",
    "        # Visualización de tipos\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Distribución de tipos\n",
    "        type_counts.head(12).plot(kind='barh', ax=axes[0], color=plot_colors['bar'])\n",
    "        axes[0].set_yticks(range(len(type_counts)))\n",
    "        axes[0].set_yticklabels(type_counts.index)\n",
    "        axes[0].set_title('Distribución de Tipos de Pokemon')\n",
    "        axes[0].set_xlabel('Número de Usos')\n",
    "        \n",
    "        # Winrates por tipo (si disponible)\n",
    "        if len(type_winrates) > 0:\n",
    "            type_winrates.head(10).plot(kind='bar', ax=axes[1], color=plot_colors['bar'])\n",
    "            axes[1].set_title('Winrate por Tipo de Pokemon')\n",
    "            axes[1].set_ylabel('Winrate')\n",
    "            axes[1].tick_params(axis='x', rotation=45)\n",
    "            axes[1].axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='50%')\n",
    "            axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / 'type_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Análisis de tipos guardado: {OUTPUT_DIR / 'type_analysis.png'}\")\n",
    "    else:\n",
    "        print(\"No se pudieron mapear tipos para las especies encontradas\")\n",
    "else:\n",
    "    print(\"No hay datos de Pokemon disponibles para análisis de tipos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df8aff",
   "metadata": {},
   "source": [
    "---\n",
    "# Estrategia Final: El Blueprint para la IA Maestra\n",
    "\n",
    "**Después de nuestro exhaustivo viaje por los datos, es momento de trazar el mapa definitivo hacia la creación de una IA Pokemon de nivel maestro.**\n",
    "\n",
    "Hemos extraído cada secreto de las batallas, analizado cada patrón, y destilado todo el conocimiento en características que una IA puede dominar. Ahora, presentamos la estrategia revolucionaria que transformará estos insights en inteligencia artificial superior.\n",
    "\n",
    "## Estrategia de Entrenamiento Revolucionaria\n",
    "\n",
    "### Arquitectura Recomendada\n",
    "\n",
    "**Modelo Híbrido Multi-Componente:**\n",
    "- **CNN (Convolutional Neural Network)**: Para patrones espaciales de equipos y composiciones\n",
    "- **LSTM (Long Short-Term Memory)**: Para secuencias temporales de batalla y momentum\n",
    "- **Attention Mechanism**: Para decisiones críticas por turno y timing óptimo\n",
    "- **Transformer Blocks**: Para relaciones complejas entre Pokemon y movimientos\n",
    "\n",
    "### Enfoques de Aprendizaje Avanzados\n",
    "\n",
    "**Multi-Task Learning:**\n",
    "- Predecir próximo movimiento óptimo\n",
    "- Estimar probabilidad de victoria\n",
    "- Calcular timing perfecto para switches\n",
    "- Evaluar riesgo/recompensa de cada acción\n",
    "\n",
    "**Curriculum Learning:**\n",
    "- Fase 1: Batallas simples y directas\n",
    "- Fase 2: Escenarios con switches complejos\n",
    "- Fase 3: Batallas de alta intensidad y momentum\n",
    "- Fase 4: Meta-game y estrategias anti-competitivas\n",
    "\n",
    "**Adversarial Training:**\n",
    "- IA vs IA para desarrollar estrategias anti-meta\n",
    "- Generación de escenarios adversos\n",
    "- Robustez contra estrategias impredecibles\n",
    "\n",
    "**Continual Learning:**\n",
    "- Adaptación automática a cambios en el meta competitivo\n",
    "- Aprendizaje incremental de nuevas estrategias\n",
    "- Preservación de conocimiento previo\n",
    "\n",
    "## Impacto Revolucionario en el Rendimiento\n",
    "\n",
    "**Con nuestras mejoras implementadas, la IA ahora puede:**\n",
    "\n",
    "**1. Detectar Momentum y Cambiar Estrategias Según la Fase**\n",
    "- Reconocer patrones de early-game vs late-game\n",
    "- Adaptar agresividad según intensidad de batalla\n",
    "- Optimizar decisiones por fase temporal\n",
    "\n",
    "**2. Evaluar Ventajas de Información y Composición de Equipos**\n",
    "- Calcular ventajas de HP, nivel y diversidad\n",
    "- Aprovechar información parcial del oponente\n",
    "- Optimizar team synergy y balance\n",
    "\n",
    "**3. Predecir Patrones de Decisión del Oponente**\n",
    "- Analizar ratios move/switch históricos\n",
    "- Detectar tendencias en acciones consecutivas\n",
    "- Anticipar cambios de estrategia\n",
    "\n",
    "**4. Optimizar Timing de Switches y Movimientos Críticos**\n",
    "- Calcular momentos óptimos para cambios\n",
    "- Maximizar impacto de movimientos especiales\n",
    "- Minimizar riesgos en decisiones críticas\n",
    "\n",
    "**5. Adaptarse Dinámicamente a Diferentes Estilos de Juego**\n",
    "- Reconocer estilos agresivos vs defensivos\n",
    "- Ajustar estrategia según rating del oponente\n",
    "- Evolucionar táctica durante la batalla\n",
    "\n",
    "## El Legado de Nuestro Análisis\n",
    "\n",
    "**Hemos transformado datos crudos en sabiduría estratégica.**\n",
    "\n",
    "Cada feature extraída, cada patrón descubierto, cada insight revelado contribuye a crear una IA que no solo juega Pokemon, sino que comprende la esencia misma del combate estratégico. \n",
    "\n",
    "**La IA resultante será capaz de:**\n",
    "- Tomar decisiones con la intuición de un maestro\n",
    "- Adaptarse con la flexibilidad de un experto\n",
    "- Aprender con la velocidad de una máquina\n",
    "- Competir con la precisión de un campeón\n",
    "\n",
    "**El futuro del combate Pokemon ha comenzado.**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
