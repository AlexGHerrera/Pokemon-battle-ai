{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd7fa302",
   "metadata": {},
   "source": [
    "# Pokemon Battle Dataset - An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "## La Historia que Vamos a Contar\n",
    "\n",
    "**Imagina que eres un entrenador Pokemon novato** que quiere convertirse en maestro. ¬øC√≥mo aprender√≠as? Observando a los mejores, analizando sus estrategias, entendiendo qu√© Pokemon usan y cu√°ndo.\n",
    "\n",
    "**Eso es exactamente lo que haremos con nuestra IA.** A trav√©s de aproximadamente 14,000 batallas reales de Pokemon Showdown, descubriremos:\n",
    "\n",
    "- **¬øQu√© hace que una batalla sea exitosa?**\n",
    "- **¬øCu√°les son las estrategias ganadoras?**\n",
    "- **¬øQu√© Pokemon dominan el meta competitivo?**\n",
    "- **¬øC√≥mo puede nuestra IA aprender estos patrones?**\n",
    "\n",
    "## Nuestro Viaje de Descubrimiento\n",
    "\n",
    "**Cap√≠tulo 1**: *¬øSon nuestros datos confiables?* - Validaci√≥n de calidad y integridad\n",
    "**Cap√≠tulo 2**: *¬øQu√© nos dicen las batallas?* - Patrones y m√©tricas de combate\n",
    "**Cap√≠tulo 3**: *¬øQui√©nes son los protagonistas?* - An√°lisis profundo de Pokemon\n",
    "**Cap√≠tulo 4**: *¬øCu√°ndo ocurren las batallas?* - Patrones temporales del meta\n",
    "**Cap√≠tulo 5**: *¬øQu√© debe aprender nuestra IA?* - Ingenier√≠a de caracter√≠sticas\n",
    "**Ep√≠logo**: *El camino hacia la maestr√≠a* - Pr√≥ximos pasos para el entrenamiento\n",
    "\n",
    "## Alcance del Proyecto\n",
    "\n",
    "Este proyecto tiene como objetivo desarrollar un **modelo de inteligencia artificial capaz de jugar Pokemon de forma aut√≥noma** contra usuarios humanos. Para lograr esto, necesitamos comprender profundamente los patrones de batalla, estrategias ganadoras y comportamientos de los jugadores expertos.\n",
    "\n",
    "### Contexto del Dataset\n",
    "\n",
    "- **Fuente**: Batallas reales de Pokemon Showdown (formato gen9randombattle)\n",
    "- **Volumen**: ~14,000 batallas individuales en formato JSON\n",
    "- **Contenido**: Turnos secuenciales, eventos de batalla, estados del juego, resultados\n",
    "- **Aplicaci√≥n**: Entrenamiento de modelo de IA para toma de decisiones en tiempo real\n",
    "\n",
    "---\n",
    "\n",
    "# %% [markdown]\n",
    "## Importaci√≥n de librer√≠as y configuraci√≥n inicial\n",
    "\n",
    "**Objetivo de esta secci√≥n:**\n",
    "- Importamos las librer√≠as necesarias para el an√°lisis de datos y visualizaci√≥n\n",
    "- Configuramos matplotlib y seaborn para generar gr√°ficas consistentes y profesionales\n",
    "- Configuramos el entorno de trabajo para an√°lisis √≥ptimo\n",
    "- Estas configuraciones son fundamentales para un EDA reproducible y visualmente atractivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "# Nota: No suprimimos warnings para mantener visibilidad de posibles problemas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Configuraci√≥n de visualizaciones con paleta Pokemon tem√°tica\n",
    "plt.style.use('seaborn-v0_8-whitegrid')  # Estilo m√°s moderno\n",
    "\n",
    "# Paleta Pokemon tem√°tica - colores vibrantes pero profesionales\n",
    "pokemon_colors = {\n",
    "    'fire': '#FF6B35',      # Naranja fuego vibrante\n",
    "    'water': '#4A90E2',     # Azul agua profundo  \n",
    "    'grass': '#7ED321',     # Verde hierba brillante\n",
    "    'electric': '#F5A623',  # Amarillo el√©ctrico\n",
    "    'psychic': '#BD10E0',   # P√∫rpura ps√≠quico\n",
    "    'dragon': '#9013FE',    # P√∫rpura drag√≥n\n",
    "    'dark': '#2C3E50',      # Gris oscuro elegante\n",
    "    'steel': '#95A5A6',     # Gris met√°lico\n",
    "    'fairy': '#FF69B4',     # Rosa hada\n",
    "    'fighting': '#D0021B',  # Rojo lucha\n",
    "    'poison': '#7B68EE',    # P√∫rpura veneno\n",
    "    'ground': '#8B4513',    # Marr√≥n tierra\n",
    "    'flying': '#87CEEB',    # Azul cielo\n",
    "    'bug': '#9ACD32',       # Verde insecto\n",
    "    'rock': '#A0522D',      # Marr√≥n roca\n",
    "    'ghost': '#483D8B',     # P√∫rpura fantasma\n",
    "    'ice': '#B0E0E6',       # Azul hielo\n",
    "    'normal': '#A8A878'     # Beige normal\n",
    "}\n",
    "\n",
    "# Paletas para diferentes tipos de gr√°ficos\n",
    "primary_palette = [pokemon_colors['fire'], pokemon_colors['water'], pokemon_colors['grass'], \n",
    "                  pokemon_colors['electric'], pokemon_colors['psychic'], pokemon_colors['dragon']]\n",
    "\n",
    "secondary_palette = [pokemon_colors['dark'], pokemon_colors['steel'], pokemon_colors['fairy'],\n",
    "                    pokemon_colors['fighting'], pokemon_colors['poison'], pokemon_colors['ground']]\n",
    "\n",
    "# Configurar seaborn con la nueva paleta\n",
    "sns.set_palette(primary_palette)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 10\n",
    "plt.rcParams['figure.titlesize'] = 16\n",
    "\n",
    "# Configuraci√≥n de colores para gr√°ficos espec√≠ficos\n",
    "plot_colors = {\n",
    "    'histogram': pokemon_colors['water'],\n",
    "    'scatter': pokemon_colors['fire'], \n",
    "    'line': pokemon_colors['electric'],\n",
    "    'bar': pokemon_colors['grass'],\n",
    "    'boxplot': primary_palette,\n",
    "    'heatmap': 'RdYlBu_r'  # Colormap para matrices de correlaci√≥n\n",
    "}\n",
    "\n",
    "# Configuraci√≥n de reproducibilidad\n",
    "import platform\n",
    "import sys\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configuraci√≥n completada - entorno listo para an√°lisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1a03e",
   "metadata": {},
   "source": [
    "## Configuraci√≥n de rutas y constantes\n",
    "\n",
    "**Prop√≥sito de la configuraci√≥n:**\n",
    "- Centralizamos la gesti√≥n de archivos para facilitar el mantenimiento del c√≥digo\n",
    "- `BATTLES_DIR`: Contiene los archivos JSON individuales de cada batalla\n",
    "- `ALL_BATTLES_JSON`: Archivo consolidado que mejora la velocidad de carga\n",
    "- `OUTPUT_DIR`: Directorio donde guardaremos visualizaciones y resultados\n",
    "- Esta organizaci√≥n es crucial para un flujo de trabajo ordenado y escalable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5561b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectar si estamos ejecutando desde notebooks/ o desde ra√≠z\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\":\n",
    "    DATA_DIR = Path(\"../data\")\n",
    "    OUTPUT_DIR = Path(\"../output\")\n",
    "else:\n",
    "    DATA_DIR = Path(\"data\")\n",
    "    OUTPUT_DIR = Path(\"output\")\n",
    "\n",
    "BATTLES_DIR = DATA_DIR / \"battles\"\n",
    "ALL_BATTLES_JSON = DATA_DIR / \"all_battles.json\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Rutas configuradas correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79392cf",
   "metadata": {},
   "source": [
    "## Funciones auxiliares para procesamiento de datos\n",
    "\n",
    "**Funciones implementadas:**\n",
    "- `get_in()`: Navega estructuras JSON anidadas de forma segura, evitando errores por claves faltantes\n",
    "- `extract_pokemon_info()`: Extrae informaci√≥n espec√≠fica de Pokemon que ser√° clave para el modelo de IA\n",
    "- `calculate_battle_metrics()`: Calcula m√©tricas estrat√©gicas como eventos por turno, tipos de acciones, etc.\n",
    "- Estas funciones nos permiten transformar datos complejos en features estructuradas para machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d0f33",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_in(d: Any, path: List[str], default: Any = None) -> Any:\n",
    "    \"\"\"Extrae valores anidados de diccionarios de forma segura.\"\"\"\n",
    "    cur = d\n",
    "    for k in path:\n",
    "        if isinstance(cur, dict) and k in cur:\n",
    "            cur = cur[k]\n",
    "        else:\n",
    "            return default\n",
    "    return cur\n",
    "\n",
    "def extract_pokemon_info(battle: dict) -> List[dict]:\n",
    "    \"\"\"Extrae informaci√≥n detallada de Pokemon de una batalla.\"\"\"\n",
    "    pokemon_info = []\n",
    "    teams = get_in(battle, [\"team_revelation\", \"teams\"], {})\n",
    "    \n",
    "    for player_id, team in teams.items():\n",
    "        if isinstance(team, list):\n",
    "            for pokemon in team:\n",
    "                # Extraer todas las estad√≠sticas base disponibles\n",
    "                base_stats = pokemon.get('base_stats', {})\n",
    "                info = {\n",
    "                    'battle_id': battle.get('battle_id'),\n",
    "                    'player': player_id,\n",
    "                    'species': pokemon.get('species'),\n",
    "                    'level': pokemon.get('level'),\n",
    "                    'gender': pokemon.get('gender'),\n",
    "                    'hp': base_stats.get('hp'),\n",
    "                    'attack': base_stats.get('attack'),\n",
    "                    'defense': base_stats.get('defense'),\n",
    "                    'sp_attack': base_stats.get('sp_attack'),\n",
    "                    'sp_defense': base_stats.get('sp_defense'),\n",
    "                    'speed': base_stats.get('speed'),\n",
    "                    'first_seen_turn': pokemon.get('first_seen_turn'),\n",
    "                    'revelation_status': pokemon.get('revelation_status'),\n",
    "                    'known_ability': pokemon.get('known_ability'),\n",
    "                    'known_item': pokemon.get('known_item'),\n",
    "                    'known_tera_type': pokemon.get('known_tera_type'),\n",
    "                    'known_moves_count': len(pokemon.get('known_moves', [])),\n",
    "                    'unknown_move_slots': pokemon.get('unknown_move_slots', 0)\n",
    "                }\n",
    "                pokemon_info.append(info)\n",
    "    return pokemon_info\n",
    "\n",
    "def calculate_battle_metrics(battle: dict) -> dict:\n",
    "    \"\"\"Calcula m√©tricas clave de una batalla para an√°lisis avanzado de IA.\"\"\"\n",
    "    metadata = battle.get('metadata', {})\n",
    "    turns = battle.get('turns', [])\n",
    "    \n",
    "    # M√©tricas b√°sicas\n",
    "    total_turns = len(turns)\n",
    "    winner = get_in(metadata, ['outcome', 'winner'])\n",
    "    reason = get_in(metadata, ['outcome', 'reason'])\n",
    "    \n",
    "    # An√°lisis detallado de eventos\n",
    "    total_events = 0\n",
    "    move_events = 0\n",
    "    switch_events = 0\n",
    "    damage_events = 0\n",
    "    effect_events = 0\n",
    "    heal_events = 0\n",
    "    status_events = 0\n",
    "    \n",
    "    # M√©tricas de momentum y timing\n",
    "    early_game_events = 0  # Primeros 3 turnos\n",
    "    mid_game_events = 0    # Turnos 4-8\n",
    "    late_game_events = 0   # Turnos 9+\n",
    "    \n",
    "    # Patrones de decisi√≥n\n",
    "    consecutive_moves = 0\n",
    "    consecutive_switches = 0\n",
    "    last_action = None\n",
    "    \n",
    "    for turn_idx, turn in enumerate(turns, 1):\n",
    "        events = turn.get('events', [])\n",
    "        turn_event_count = len(events)\n",
    "        total_events += turn_event_count\n",
    "        \n",
    "        # Clasificar por fase de batalla\n",
    "        if turn_idx <= 3:\n",
    "            early_game_events += turn_event_count\n",
    "        elif turn_idx <= 8:\n",
    "            mid_game_events += turn_event_count\n",
    "        else:\n",
    "            late_game_events += turn_event_count\n",
    "        \n",
    "        for event in events:\n",
    "            event_type = event.get('type')\n",
    "            \n",
    "            # Conteo de tipos de eventos\n",
    "            if event_type == 'move':\n",
    "                move_events += 1\n",
    "                if last_action == 'move':\n",
    "                    consecutive_moves += 1\n",
    "                last_action = 'move'\n",
    "            elif event_type == 'switch':\n",
    "                switch_events += 1\n",
    "                if last_action == 'switch':\n",
    "                    consecutive_switches += 1\n",
    "                last_action = 'switch'\n",
    "            elif event_type == 'damage':\n",
    "                damage_events += 1\n",
    "            elif event_type == 'effect':\n",
    "                effect_events += 1\n",
    "            elif event_type == 'heal':\n",
    "                heal_events += 1\n",
    "            elif event_type in ['status', 'boost', 'unboost']:\n",
    "                status_events += 1\n",
    "    \n",
    "    return {\n",
    "        'battle_id': battle.get('battle_id'),\n",
    "        'total_turns': total_turns,\n",
    "        'total_events': total_events,\n",
    "        'move_events': move_events,\n",
    "        'switch_events': switch_events,\n",
    "        'damage_events': damage_events,\n",
    "        'effect_events': effect_events,\n",
    "        'heal_events': heal_events,\n",
    "        'status_events': status_events,\n",
    "        'winner': winner,\n",
    "        'reason': reason,\n",
    "        'events_per_turn': total_events / max(total_turns, 1),\n",
    "        'timestamp': metadata.get('timestamp_unix'),\n",
    "        # M√©tricas de momentum\n",
    "        'early_game_intensity': early_game_events / max(min(total_turns, 3), 1),\n",
    "        'mid_game_intensity': mid_game_events / max(min(total_turns - 3, 5), 1) if total_turns > 3 else 0,\n",
    "        'late_game_intensity': late_game_events / max(total_turns - 8, 1) if total_turns > 8 else 0,\n",
    "        # Patrones de decisi√≥n\n",
    "        'move_switch_ratio': move_events / max(switch_events, 1),\n",
    "        'consecutive_moves': consecutive_moves,\n",
    "        'consecutive_switches': consecutive_switches,\n",
    "        'action_diversity': len(set([e.get('type') for turn in turns for e in turn.get('events', [])]))  \n",
    "    }\n",
    "\n",
    "def extract_team_composition_features(battle: dict) -> dict:\n",
    "    \"\"\"Extrae features avanzadas de composici√≥n de equipos para IA.\"\"\"\n",
    "    teams = get_in(battle, [\"team_revelation\", \"teams\"], {})\n",
    "    features = {'battle_id': battle.get('battle_id')}\n",
    "    \n",
    "    for player_id in ['p1', 'p2']:\n",
    "        team = teams.get(player_id, [])\n",
    "        if isinstance(team, list) and team:\n",
    "            # M√©tricas b√°sicas del equipo\n",
    "            levels = [p.get('level', 0) for p in team if p.get('level')]\n",
    "            hps = [get_in(p, ['base_stats', 'hp']) for p in team if get_in(p, ['base_stats', 'hp'])]\n",
    "            \n",
    "            features.update({\n",
    "                f'{player_id}_team_size': len(team),\n",
    "                f'{player_id}_avg_level': np.mean(levels) if levels else 0,\n",
    "                f'{player_id}_level_std': np.std(levels) if len(levels) > 1 else 0,\n",
    "                f'{player_id}_min_level': min(levels) if levels else 0,\n",
    "                f'{player_id}_max_level': max(levels) if levels else 0,\n",
    "                f'{player_id}_avg_hp': np.mean(hps) if hps else 0,\n",
    "                f'{player_id}_hp_std': np.std(hps) if len(hps) > 1 else 0,\n",
    "                f'{player_id}_total_hp': sum(hps) if hps else 0,\n",
    "            })\n",
    "            \n",
    "            # Diversidad de especies\n",
    "            species = [p.get('species') for p in team if p.get('species')]\n",
    "            features[f'{player_id}_species_diversity'] = len(set(species))\n",
    "            \n",
    "            # Informaci√≥n de revelaci√≥n\n",
    "            revelation_statuses = [p.get('revelation_status') for p in team]\n",
    "            features[f'{player_id}_fully_revealed'] = revelation_statuses.count('fully_revealed')\n",
    "            features[f'{player_id}_partially_revealed'] = revelation_statuses.count('partially_revealed')\n",
    "            \n",
    "            # Informaci√≥n conocida vs desconocida\n",
    "            known_abilities = sum(1 for p in team if p.get('known_ability'))\n",
    "            known_items = sum(1 for p in team if p.get('known_item'))\n",
    "            total_known_moves = sum(len(p.get('known_moves', [])) for p in team)\n",
    "            \n",
    "            features.update({\n",
    "                f'{player_id}_known_abilities': known_abilities,\n",
    "                f'{player_id}_known_items': known_items,\n",
    "                f'{player_id}_total_known_moves': total_known_moves,\n",
    "                f'{player_id}_info_advantage': (known_abilities + known_items + total_known_moves) / max(len(team), 1)\n",
    "            })\n",
    "        else:\n",
    "            # Valores por defecto si no hay datos del equipo\n",
    "            for metric in ['team_size', 'avg_level', 'level_std', 'min_level', 'max_level', \n",
    "                          'avg_hp', 'hp_std', 'total_hp', 'species_diversity', \n",
    "                          'fully_revealed', 'partially_revealed', 'known_abilities', \n",
    "                          'known_items', 'total_known_moves', 'info_advantage']:\n",
    "                features[f'{player_id}_{metric}'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Funciones auxiliares listas para procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8530d8e4",
   "metadata": {},
   "source": [
    "## Funciones de optimizaci√≥n para datasets grandes\n",
    "\n",
    "**Estrategias implementadas:**\n",
    "- Muestreo aleatorio para desarrollo r√°pido\n",
    "- Conversi√≥n a formato Parquet (m√°s eficiente)\n",
    "- Carga por chunks para evitar problemas de memoria\n",
    "- Procesamiento incremental de batallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dedbc3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_sample_dataset(sample_size: int = 1000, force_recreate: bool = False) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Crea un dataset de muestra para desarrollo r√°pido.\n",
    "    \n",
    "    Args:\n",
    "        sample_size: N√∫mero de batallas a incluir en la muestra\n",
    "        force_recreate: Si True, recrea la muestra aunque ya exista\n",
    "    \"\"\"\n",
    "    sample_path = DATA_DIR / f\"battles_sample_{sample_size}.json\"\n",
    "    \n",
    "    if sample_path.exists() and not force_recreate:\n",
    "        print(f\"Cargando muestra existente: {sample_path}\")\n",
    "        with open(sample_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    print(f\"Creando nueva muestra de {sample_size} batallas...\")\n",
    "    \n",
    "    # Cargar dataset completo y tomar muestra aleatoria\n",
    "    with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "        all_battles = json.load(f)\n",
    "    \n",
    "    import random\n",
    "    random.seed(42)  # Para reproducibilidad\n",
    "    sample_battles = random.sample(all_battles, min(sample_size, len(all_battles)))\n",
    "    \n",
    "    # Guardar muestra\n",
    "    with open(sample_path, \"w\") as f:\n",
    "        json.dump(sample_battles, f, indent=2)\n",
    "    \n",
    "    print(f\"Muestra guardada: {sample_path}\")\n",
    "    print(f\"Tama√±o de muestra: {len(sample_battles)} batallas\")\n",
    "    \n",
    "    return sample_battles\n",
    "\n",
    "def convert_to_parquet() -> None:\n",
    "    \"\"\"\n",
    "    Convierte el dataset a formato Parquet para acceso m√°s r√°pido.\n",
    "    \"\"\"\n",
    "    parquet_path = DATA_DIR / \"battles_optimized.parquet\"\n",
    "    \n",
    "    if parquet_path.exists():\n",
    "        print(f\"Archivo Parquet ya existe: {parquet_path}\")\n",
    "        return\n",
    "    \n",
    "    print(\"Convirtiendo a formato Parquet...\")\n",
    "    \n",
    "    # Cargar y procesar por chunks\n",
    "    chunk_size = 1000\n",
    "    all_metrics = []\n",
    "    \n",
    "    with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "        battles = json.load(f)\n",
    "    \n",
    "    print(f\" Procesando {len(battles)} batallas para extracci√≥n de caracter√≠sticas...\")\n",
    "    for i in range(0, len(battles), 500):\n",
    "        chunk = battles[i:i+500]\n",
    "        chunk_features = [extract_team_composition_features(battle) for battle in chunk]\n",
    "        all_metrics.extend(chunk_features)\n",
    "        if (i + 500) % 1000 == 0:  # Reducir prints\n",
    "            print(f\"   ‚Ä¢ {min(i+500, len(battles))} batallas procesadas\")\n",
    "    \n",
    "    # Convertir a DataFrame y guardar\n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "    \n",
    "    print(f\"Dataset convertido a Parquet: {parquet_path}\")\n",
    "    print(f\"Tama√±o original JSON: {ALL_BATTLES_JSON.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "    print(f\"Tama√±o Parquet: {parquet_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "def load_battles_optimized(use_sample: bool = True, sample_size: int = 1000) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Carga optimizada de datos con opciones de muestreo.\n",
    "    \n",
    "    Args:\n",
    "        use_sample: Si True, usa una muestra para desarrollo r√°pido\n",
    "        sample_size: Tama√±o de la muestra si use_sample=True\n",
    "    \"\"\"\n",
    "    if use_sample:\n",
    "        print(f\"Modo desarrollo: usando muestra de {sample_size} batallas\")\n",
    "        return create_sample_dataset(sample_size)\n",
    "    else:\n",
    "        print(\"Modo producci√≥n: cargando dataset completo\")\n",
    "        if ALL_BATTLES_JSON.exists():\n",
    "            with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "                return json.load(f)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No existe {ALL_BATTLES_JSON}\")\n",
    "\n",
    "def load_parquet_if_exists() -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Carga el archivo Parquet si existe, para an√°lisis r√°pido.\n",
    "    \"\"\"\n",
    "    parquet_path = DATA_DIR / \"battles_optimized.parquet\"\n",
    "    \n",
    "    if parquet_path.exists():\n",
    "        print(f\"Cargando datos desde Parquet: {parquet_path}\")\n",
    "        return pd.read_parquet(parquet_path)\n",
    "    else:\n",
    "        print(\"Archivo Parquet no encontrado. Usa convert_to_parquet() primero.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42acc5",
   "metadata": {},
   "source": [
    "## 1. Carga y consolidaci√≥n de datos\n",
    "\n",
    "**Justificaci√≥n de la consolidaci√≥n:**\n",
    "- Los datos vienen en miles de archivos JSON individuales, lo que es ineficiente para an√°lisis\n",
    "- La consolidaci√≥n mejora significativamente la velocidad de carga y procesamiento\n",
    "- Nos permite validar la integridad de los datos y detectar archivos corruptos\n",
    "- Facilita el an√°lisis posterior al tener todos los datos en una estructura unificada\n",
    "- Es un paso fundamental antes de cualquier an√°lisis exploratorio serio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51891834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_battles_data() -> List[dict]:\n",
    "    \"\"\"Carga y consolida todos los datos de batallas.\"\"\"\n",
    "    if ALL_BATTLES_JSON.exists():\n",
    "        with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    # Si no existe el archivo consolidado, lo creamos\n",
    "    json_files = sorted(BATTLES_DIR.glob(\"*.json\"))\n",
    "    battles_data = []\n",
    "    \n",
    "    print(f\"Consolidando {len(json_files)} archivos JSON...\")\n",
    "    \n",
    "    for i, file in enumerate(json_files):\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                battle = json.load(f)\n",
    "                battles_data.append(battle)\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {file.name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Procesados {i + 1} archivos...\")\n",
    "    \n",
    "    # Guardar archivo consolidado\n",
    "    with open(ALL_BATTLES_JSON, \"w\") as f:\n",
    "        json.dump(battles_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Datos consolidados: {len(battles_data)} batallas\")\n",
    "    return battles_data\n",
    "\n",
    "# Cargar datos\n",
    "battles = load_battles_optimized(use_sample=True, sample_size=2000)  # Modo desarrollo por defecto\n",
    "print(f\"üìä Dataset cargado: {len(battles):,} batallas\")\n",
    "\n",
    "# Crear DataFrame de m√©tricas de batalla para an√°lisis posterior\n",
    "battle_metrics = [calculate_battle_metrics(battle) for battle in battles]\n",
    "df_battles = pd.DataFrame(battle_metrics)\n",
    "print(f\"üìà M√©tricas extra√≠das: {len(df_battles.columns)} caracter√≠sticas por batalla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebfad7",
   "metadata": {},
   "source": [
    "### Configuraci√≥n de modo de trabajo\n",
    "\n",
    "**Para cambiar entre modos:**\n",
    "- **Desarrollo r√°pido**: `battles = load_battles_optimized(use_sample=True, sample_size=2000)`\n",
    "- **Dataset completo**: `battles = load_battles_optimized(use_sample=False)`\n",
    "- **Desde Parquet**: `df_battles = load_parquet_if_exists()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2241d",
   "metadata": {},
   "source": [
    "## 2. An√°lisis de calidad de datos\n",
    "\n",
    "**Importancia del an√°lisis de calidad:**\n",
    "- Identificamos problemas de datos antes de invertir tiempo en an√°lisis incorrectos\n",
    "- Validamos que las batallas tengan la estructura esperada (battle_id, metadata, turns)\n",
    "- Detectamos patrones de datos faltantes que podr√≠an sesgar nuestro modelo\n",
    "- Entendemos la distribuci√≥n de formatos de batalla para enfocar el entrenamiento\n",
    "- La calidad de datos determina directamente la calidad del modelo de IA resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7db7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"AN√ÅLISIS DE CALIDAD DE DATOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Estad√≠sticas b√°sicas\n",
    "total_battles = len(battles)\n",
    "print(f\"Total de batallas: {total_battles:,}\")\n",
    "\n",
    "# Validaci√≥n de estructura\n",
    "valid_battles = 0\n",
    "incomplete_battles = 0\n",
    "\n",
    "required_keys = ['battle_id', 'metadata', 'turns']\n",
    "for battle in battles:\n",
    "    if all(key in battle for key in required_keys):\n",
    "        valid_battles += 1\n",
    "    else:\n",
    "        incomplete_battles += 1\n",
    "\n",
    "print(f\"Batallas con estructura completa: {valid_battles:,} ({valid_battles/total_battles*100:.1f}%)\")\n",
    "print(f\"Batallas incompletas: {incomplete_battles:,} ({incomplete_battles/total_battles*100:.1f}%)\")\n",
    "\n",
    "# An√°lisis de formatos\n",
    "formats = Counter(battle.get('format_id') for battle in battles)\n",
    "print(f\"\\nFormatos de batalla encontrados:\")\n",
    "for format_id, count in formats.most_common():\n",
    "    print(f\"  - {format_id}: {count:,} batallas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1423910",
   "metadata": {},
   "source": [
    "## Cap√≠tulo 1.1: Detectando Imperfecciones en Nuestros Datos\n",
    "\n",
    "**¬øQu√© secretos ocultan los datos faltantes?**\n",
    "\n",
    "Como detectives examinando evidencia, debemos identificar qu√© informaci√≥n nos falta y por qu√©. Los datos nulos no son solo n√∫meros ausentes - son pistas sobre la calidad de nuestro dataset y posibles sesgos que podr√≠an confundir a nuestra IA.\n",
    "\n",
    "**¬øPor qu√© es crucial para nuestra IA?**\n",
    "- **Sesgos ocultos**: Los nulos pueden indicar patrones sistem√°ticos que sesgar√≠an el aprendizaje\n",
    "- **Estrategias de imputaci√≥n**: Decidir c√≥mo manejar informaci√≥n faltante afecta directamente la precisi√≥n del modelo\n",
    "- **Robustez del modelo**: Una IA entrenada con datos incompletos debe saber manejar incertidumbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e48eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüîç {'='*50}\")\n",
    "print(\"   CAP√çTULO 1.1: DETECTANDO IMPERFECCIONES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# An√°lisis de nulos en DataFrame de batallas\n",
    "if len(df_battles) > 0:\n",
    "    nulls_battles = df_battles.isnull().sum().sort_values(ascending=False)\n",
    "    print(\"\\nNulos en DataFrame de batallas:\")\n",
    "    for col, null_count in nulls_battles.items():\n",
    "        if null_count > 0:\n",
    "            print(f\"  - {col}: {null_count:,} ({null_count/len(df_battles)*100:.1f}%)\")\n",
    "    \n",
    "    # Duplicados\n",
    "    dupes_battles = df_battles.duplicated().sum()\n",
    "    print(f\"\\nDuplicados exactos en batallas: {dupes_battles:,}\")\n",
    "    \n",
    "    # Duplicados por battle_id\n",
    "    dupes_by_id = df_battles['battle_id'].duplicated().sum()\n",
    "    print(f\"Batallas con battle_id duplicado: {dupes_by_id:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490ffea",
   "metadata": {},
   "source": [
    "## Cap√≠tulo 1.2: El ADN de Nuestros Datos\n",
    "\n",
    "**¬øQu√© tipo de informaci√≥n tenemos realmente?**\n",
    "\n",
    "Cada variable en nuestro dataset tiene una personalidad √∫nica. Algunas son categ√≥ricas (como especies de Pokemon), otras num√©ricas (como HP), y algunas tienen miles de valores √∫nicos mientras otras solo unos pocos. Entender esta diversidad es crucial para que nuestra IA aprenda correctamente.\n",
    "\n",
    "**El impacto en el entrenamiento:**\n",
    "- **Variables categ√≥ricas**: Requieren encoding especial para que la IA las entienda\n",
    "- **Alta cardinalidad**: Puede causar overfitting si no se maneja correctamente\n",
    "- **Tipos incorrectos**: Pueden hacer que la IA malinterprete patrones importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b23cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüß¨ {'='*50}\")\n",
    "print(\"   CAP√çTULO 1.2: EL ADN DE LOS DATOS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(df_battles) > 0:\n",
    "    audit_battles = (df_battles.dtypes.to_frame('dtype')\n",
    "                    .assign(cardinalidad=df_battles.nunique(),\n",
    "                           nulos=df_battles.isnull().sum(),\n",
    "                           pct_nulos=(df_battles.isnull().sum()/len(df_battles)*100).round(2))\n",
    "                    .sort_values('cardinalidad', ascending=False))\n",
    "    \n",
    "    print(\"\\nAuditor√≠a DataFrame batallas:\")\n",
    "    print(audit_battles)\n",
    "    \n",
    "    # Guardar auditor√≠a\n",
    "    audit_path = OUTPUT_DIR / 'data_audit_battles.csv'\n",
    "    audit_battles.to_csv(audit_path)\n",
    "    print(f\"\\nAuditor√≠a guardada: {audit_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9a1164",
   "metadata": {},
   "source": [
    "## Cap√≠tulo 2: Los Secretos de la Victoria\n",
    "\n",
    "**¬øQu√© separa a los ganadores de los perdedores?**\n",
    "\n",
    "En el mundo Pokemon, cada batalla cuenta una historia. Algunas terminan r√°pidamente con estrategias agresivas, otras se extienden en duelos √©picos de resistencia. Nuestra IA debe aprender a leer estas historias y entender qu√© patrones llevan al √©xito.\n",
    "\n",
    "**Las lecciones ocultas en cada resultado:**\n",
    "- **Balance del dataset**: ¬øFavorece nuestro dataset a alg√∫n jugador? Un sesgo aqu√≠ crear√≠a una IA injusta\n",
    "- **Razones de victoria**: ¬øGanan por knockout directo o por estrategias m√°s sutiles?\n",
    "- **Duraci√≥n vs √©xito**: ¬øLas batallas r√°pidas o largas tienen m√°s probabilidad de √©xito?\n",
    "- **Patrones temporales**: ¬øHay momentos clave donde se decide el resultado?\n",
    "\n",
    "Estos insights guiar√°n el dise√±o de la funci√≥n de recompensa de nuestra IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c6c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n‚öîÔ∏è {'='*50}\")\n",
    "print(\"   CAP√çTULO 2: LOS SECRETOS DE LA VICTORIA\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# An√°lisis de ganadores\n",
    "winner_counts = df_battles['winner'].value_counts()\n",
    "print(f\"Distribuci√≥n de ganadores:\")\n",
    "for winner, count in winner_counts.items():\n",
    "    print(f\"  - {winner}: {count:,} ({count/len(df_battles)*100:.1f}%)\")\n",
    "\n",
    "# Razones de victoria\n",
    "reason_counts = df_battles['reason'].value_counts()\n",
    "print(f\"\\nRazones de finalizaci√≥n:\")\n",
    "for reason, count in reason_counts.items():\n",
    "    print(f\"  - {reason}: {count:,} ({count/len(df_battles)*100:.1f}%)\")\n",
    "\n",
    "# Estad√≠sticas de duraci√≥n\n",
    "print(f\"\\nEstad√≠sticas de duraci√≥n de batalla:\")\n",
    "print(f\"  - Turnos promedio: {df_battles['total_turns'].mean():.1f}\")\n",
    "print(f\"  - Turnos mediana: {df_battles['total_turns'].median():.1f}\")\n",
    "print(f\"  - Turnos min/max: {df_battles['total_turns'].min()}/{df_battles['total_turns'].max()}\")\n",
    "\n",
    "# An√°lisis de balance de clases\n",
    "print(f\"\\nBalance de clases (winner):\")\n",
    "balance = df_battles['winner'].value_counts(normalize=True).mul(100).round(2)\n",
    "for winner, pct in balance.items():\n",
    "    print(f\"  - {winner}: {pct}%\")\n",
    "\n",
    "# Mostrar primeras filas del DataFrame\n",
    "print(f\"\\nPrimeras 5 batallas procesadas:\")\n",
    "print(df_battles[['battle_id', 'total_turns', 'winner', 'reason', 'move_events', 'switch_events']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143f42cb",
   "metadata": {},
   "source": [
    "## 3. An√°lisis de patrones de batalla\n",
    "\n",
    "**Valor del an√°lisis de patrones:**\n",
    "- Los eventos por batalla (movimientos, switches, da√±o) son las acciones que debe aprender la IA\n",
    "- La correlaci√≥n turnos-eventos nos indica la intensidad estrat√©gica de las batallas\n",
    "- Los patrones por ganador revelan qu√© comportamientos llevan al √©xito\n",
    "- El ratio movimientos/switches indica agresividad vs cautela en las estrategias\n",
    "- Estos insights guiar√°n el dise√±o de la funci√≥n de recompensa del modelo de IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüéØ {'='*50}\")\n",
    "print(\"   CAP√çTULO 3: PATRONES DE COMBATE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# An√°lisis de eventos por batalla\n",
    "print(f\"Eventos por batalla:\")\n",
    "print(f\"  - Eventos totales promedio: {df_battles['total_events'].mean():.1f}\")\n",
    "print(f\"  - Movimientos promedio: {df_battles['move_events'].mean():.1f}\")\n",
    "print(f\"  - Switches promedio: {df_battles['switch_events'].mean():.1f}\")\n",
    "print(f\"  - Eventos de da√±o promedio: {df_battles['damage_events'].mean():.1f}\")\n",
    "\n",
    "# Relaci√≥n entre duraci√≥n y eventos\n",
    "correlation = df_battles['total_turns'].corr(df_battles['total_events'])\n",
    "print(f\"\\nCorrelaci√≥n turnos-eventos: {correlation:.3f}\")\n",
    "\n",
    "# An√°lisis por ganador\n",
    "print(f\"\\nPatrones por ganador:\")\n",
    "for winner in ['p1', 'p2']:\n",
    "    winner_data = df_battles[df_battles['winner'] == winner]\n",
    "    if len(winner_data) > 0:\n",
    "        print(f\"  {winner}:\")\n",
    "        print(f\"    - Turnos promedio: {winner_data['total_turns'].mean():.1f}\")\n",
    "        print(f\"    - Eventos promedio: {winner_data['total_events'].mean():.1f}\")\n",
    "        print(f\"    - Ratio movimientos/switches: {winner_data['move_events'].mean() / max(winner_data['switch_events'].mean(), 1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6058e6e",
   "metadata": {},
   "source": [
    "## 3.1 An√°lisis de distribuciones y outliers\n",
    "\n",
    "**Importancia del an√°lisis de distribuciones:**\n",
    "- Identifica outliers que pueden sesgar el modelo\n",
    "- Revela la forma de las distribuciones para seleccionar algoritmos apropiados\n",
    "- Detecta patrones an√≥malos en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5581838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüìä {'='*50}\")\n",
    "print(\"   CAP√çTULO 3.1: DISTRIBUCIONES Y ANOMAL√çAS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# An√°lisis de distribuciones para variables num√©ricas clave\n",
    "num_cols = ['total_turns', 'total_events', 'move_events', 'switch_events', 'events_per_turn']\n",
    "\n",
    "if len(df_battles) > 0:\n",
    "    # Histogramas de distribuciones\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Distribuciones de Variables Num√©ricas Clave', fontsize=16)\n",
    "    \n",
    "    for i, col in enumerate(num_cols):\n",
    "        row, col_idx = divmod(i, 3)\n",
    "        if col in df_battles.columns:\n",
    "            axes[row, col_idx].hist(df_battles[col].dropna(), bins=30, alpha=0.7, edgecolor='black', color=plot_colors['histogram'])\n",
    "            axes[row, col_idx].set_title(f'Distribuci√≥n: {col}')\n",
    "            axes[row, col_idx].set_xlabel(col)\n",
    "            axes[row, col_idx].set_ylabel('Frecuencia')\n",
    "            \n",
    "            # A√±adir l√≠neas de media y mediana\n",
    "            mean_val = df_battles[col].mean()\n",
    "            median_val = df_battles[col].median()\n",
    "            axes[row, col_idx].axvline(mean_val, color='red', linestyle='--', alpha=0.7, label=f'Media: {mean_val:.1f}')\n",
    "            axes[row, col_idx].axvline(median_val, color='green', linestyle='--', alpha=0.7, label=f'Mediana: {median_val:.1f}')\n",
    "            axes[row, col_idx].legend()\n",
    "    \n",
    "    # Eliminar subplot vac√≠o\n",
    "    if len(num_cols) < 6:\n",
    "        fig.delaxes(axes[1, 2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'distributions_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualizaciones guardadas para an√°lisis posterior\n",
    "    \n",
    "    # An√°lisis de outliers usando IQR\n",
    "    print(f\"\\nDetecci√≥n de outliers (m√©todo IQR):\")\n",
    "    for col in num_cols:\n",
    "        if col in df_battles.columns:\n",
    "            Q1 = df_battles[col].quantile(0.25)\n",
    "            Q3 = df_battles[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = df_battles[(df_battles[col] < lower_bound) | (df_battles[col] > upper_bound)]\n",
    "            pct_outliers = len(outliers) / len(df_battles) * 100\n",
    "            \n",
    "            print(f\"  - {col}: {len(outliers)} outliers ({pct_outliers:.1f}%)\")\n",
    "    \n",
    "    # Boxplots por ganador\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    key_vars = ['total_turns', 'move_events', 'switch_events']\n",
    "    # Colores espec√≠ficos para boxplots\n",
    "    boxplot_colors = [pokemon_colors['fire'], pokemon_colors['water']]\n",
    "    \n",
    "    for i, var in enumerate(key_vars):\n",
    "        if var in df_battles.columns:\n",
    "            sns.boxplot(data=df_battles, x='winner', y=var, ax=axes[i], \n",
    "                       hue='winner', palette=boxplot_colors, legend=False)\n",
    "            axes[i].set_title(f'{var} por Ganador')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'boxplots_by_winner.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # An√°lisis comparativo por ganador completado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2097ee",
   "metadata": {},
   "source": [
    "## 4. An√°lisis de uso de Pokemon\n",
    "\n",
    "**Importancia del an√°lisis de Pokemon:**\n",
    "- Identificamos el 'meta' actual: qu√© Pokemon son m√°s populares y por qu√©\n",
    "- Los niveles y HP nos dan informaci√≥n sobre el balance del juego\n",
    "- La frecuencia de uso indica qu√© Pokemon debe priorizar la IA en sus decisiones\n",
    "- Esta informaci√≥n es crucial para que la IA entienda amenazas y oportunidades\n",
    "- Los Pokemon m√°s utilizados probablemente tienen estrategias m√°s desarrolladas en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d2ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüéÆ {'='*50}\")\n",
    "print(\"   CAP√çTULO 4: LOS PROTAGONISTAS DEL META\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Extraer informaci√≥n de Pokemon\n",
    "all_pokemon = []\n",
    "for battle in battles:\n",
    "    pokemon_info = extract_pokemon_info(battle)\n",
    "    for pokemon in pokemon_info:\n",
    "        pokemon['winner'] = get_in(battle, ['metadata', 'outcome', 'winner'])\n",
    "        all_pokemon.append(pokemon)\n",
    "\n",
    "df_pokemon = pd.DataFrame(all_pokemon)\n",
    "\n",
    "if len(df_pokemon) > 0:\n",
    "    # Pokemon m√°s utilizados\n",
    "    species_counts = df_pokemon['species'].value_counts()\n",
    "    print(f\"Top 10 Pokemon m√°s utilizados:\")\n",
    "    for i, (species, count) in enumerate(species_counts.head(10).items(), 1):\n",
    "        print(f\"  - {species}: {count:,} usos\")\n",
    "    \n",
    "    # An√°lisis de niveles\n",
    "    print(f\"\\nDistribuci√≥n de niveles:\")\n",
    "    print(f\"  - Nivel promedio: {df_pokemon['level'].mean():.1f}\")\n",
    "    print(f\"  - Nivel mediana: {df_pokemon['level'].median():.1f}\")\n",
    "    print(f\"  - Rango de niveles: {df_pokemon['level'].min()}-{df_pokemon['level'].max()}\")\n",
    "    \n",
    "    # An√°lisis de HP\n",
    "    hp_data = df_pokemon.dropna(subset=['hp'])\n",
    "    if len(hp_data) > 0:\n",
    "        print(f\"\\nEstad√≠sticas de HP:\")\n",
    "        print(f\"  - HP promedio: {hp_data['hp'].mean():.1f}\")\n",
    "        print(f\"  - HP mediana: {hp_data['hp'].median():.1f}\")\n",
    "        print(f\"  - Rango HP: {hp_data['hp'].min()}-{hp_data['hp'].max()}\")\n",
    "\n",
    "print(f\"\\nüìã Resumen del an√°lisis Pokemon:\")\n",
    "print(f\"   ‚Ä¢ {len(df_pokemon)} registros de Pokemon analizados\")\n",
    "print(f\"   ‚Ä¢ {df_pokemon['species'].nunique()} especies √∫nicas identificadas\")\n",
    "print(f\"   ‚Ä¢ Nivel promedio del meta: {df_pokemon['level'].mean():.1f}\")\n",
    "\n",
    "if len(df_pokemon) > 0:\n",
    "    # An√°lisis de completitud de datos\n",
    "    nulls_pokemon = df_pokemon.isnull().sum().sort_values(ascending=False)\n",
    "    critical_nulls = [(col, count) for col, count in nulls_pokemon.items() if count > 0 and count/len(df_pokemon) > 0.1]\n",
    "    if critical_nulls:\n",
    "        print(f\"\\n‚ö†Ô∏è  Datos faltantes significativos:\")\n",
    "        for col, null_count in critical_nulls[:5]:  # Solo top 5\n",
    "            print(f\"   ‚Ä¢ {col}: {null_count/len(df_pokemon)*100:.1f}% faltante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582145b5",
   "metadata": {},
   "source": [
    "## 5. Visualizaciones clave para entrenamiento de IA\n",
    "\n",
    "**Visualizaciones seleccionadas:**\n",
    "- **Distribuci√≥n de duraci√≥n**: Muestra la variabilidad de estrategias (r√°pidas vs largas)\n",
    "- **Eventos vs turnos**: Revela la intensidad de acci√≥n, clave para modelar decisiones\n",
    "- **Patrones por ganador**: Identifica comportamientos exitosos que la IA debe imitar\n",
    "- **Razones de finalizaci√≥n**: Ense√±a a la IA los diferentes caminos hacia la victoria\n",
    "- Estas gr√°ficas nos ayudan a validar hip√≥tesis y comunicar insights del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871db594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('An√°lisis de Patrones de Batalla Pokemon', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Distribuci√≥n de duraci√≥n de batallas\n",
    "axes[0, 0].hist(df_battles['total_turns'], bins=30, alpha=0.7, color=plot_colors['histogram'], edgecolor='black')\n",
    "axes[0, 0].set_title('Distribuci√≥n de Duraci√≥n de Batallas')\n",
    "axes[0, 0].set_xlabel('N√∫mero de Turnos')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].axvline(df_battles['total_turns'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Media: {df_battles[\"total_turns\"].mean():.1f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Eventos por turno\n",
    "axes[0, 1].scatter(df_battles['total_turns'], df_battles['events_per_turn'], \n",
    "                   alpha=0.6, color=plot_colors['scatter'])\n",
    "axes[0, 1].set_title('Eventos por Turno vs Duraci√≥n')\n",
    "axes[0, 1].set_xlabel('N√∫mero de Turnos')\n",
    "axes[0, 1].set_ylabel('Eventos por Turno')\n",
    "\n",
    "# 3. Comparaci√≥n de patrones por ganador\n",
    "winner_data = df_battles.groupby('winner').agg({\n",
    "    'total_turns': 'mean',\n",
    "    'move_events': 'mean',\n",
    "    'switch_events': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "x = range(len(winner_data))\n",
    "width = 0.25\n",
    "\n",
    "# Colores diferenciados para cada m√©trica\n",
    "bar_colors = [pokemon_colors['fire'], pokemon_colors['water'], pokemon_colors['electric']]\n",
    "\n",
    "axes[1, 0].bar([i - width for i in x], winner_data['total_turns'], width, \n",
    "               label='Turnos Promedio', alpha=0.8, color=bar_colors[0], \n",
    "               edgecolor='black', linewidth=1.2)\n",
    "axes[1, 0].bar(x, winner_data['move_events'], width, \n",
    "               label='Movimientos Promedio', alpha=0.8, color=bar_colors[1],\n",
    "               edgecolor='black', linewidth=1.2)\n",
    "axes[1, 0].bar([i + width for i in x], winner_data['switch_events'], width, \n",
    "               label='Switches Promedio', alpha=0.8, color=bar_colors[2],\n",
    "               edgecolor='black', linewidth=1.2)\n",
    "axes[1, 0].set_title('Patrones por Ganador')\n",
    "axes[1, 0].set_xlabel('Ganador')\n",
    "axes[1, 0].set_ylabel('Cantidad')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(winner_data['winner'])\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. Raz√≥n de finalizaci√≥n\n",
    "reason_counts = df_battles['reason'].value_counts()\n",
    "axes[1, 1].pie(reason_counts.values, labels=reason_counts.index, autopct='%1.1f%%', colors=primary_palette)\n",
    "axes[1, 1].set_title('Razones de Finalizaci√≥n')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'battle_patterns_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Visualizaci√≥n guardada: {OUTPUT_DIR / 'battle_patterns_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd7d71",
   "metadata": {},
   "source": [
    "## 6. An√°lisis visual de Pokemon\n",
    "\n",
    "**Enfoque del an√°lisis visual:**\n",
    "- **Top Pokemon**: La IA debe conocer las amenazas m√°s comunes del meta\n",
    "- **Distribuci√≥n de niveles**: Entiende el rango de poder esperado en batallas\n",
    "- **HP vs Nivel**: Revela la relaci√≥n entre estad√≠sticas, crucial para c√°lculos de da√±o\n",
    "- **Distribuci√≥n por g√©nero**: Algunos movimientos y habilidades dependen del g√©nero\n",
    "- Estas visualizaciones informan las decisiones de selecci√≥n de equipo de la IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044293a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_pokemon) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('An√°lisis de Pokemon en Batallas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Top Pokemon m√°s utilizados\n",
    "    top_pokemon = df_pokemon['species'].value_counts().head(15)\n",
    "    axes[0, 0].barh(range(len(top_pokemon)), top_pokemon.values, color=plot_colors['bar'])\n",
    "    axes[0, 0].set_yticks(range(len(top_pokemon)))\n",
    "    axes[0, 0].set_yticklabels(top_pokemon.index)\n",
    "    axes[0, 0].set_title('Top 15 Pokemon M√°s Utilizados')\n",
    "    axes[0, 0].set_xlabel('N√∫mero de Usos')\n",
    "    \n",
    "    # 2. Distribuci√≥n de niveles\n",
    "    axes[0, 1].hist(df_pokemon['level'].dropna(), bins=20, alpha=0.7, color=plot_colors['histogram'], edgecolor='black')\n",
    "    axes[0, 1].set_title('Distribuci√≥n de Niveles de Pokemon')\n",
    "    axes[0, 1].set_xlabel('Nivel')\n",
    "    axes[0, 1].set_ylabel('Frecuencia')\n",
    "    \n",
    "    # 3. HP vs Nivel\n",
    "    hp_level_data = df_pokemon.dropna(subset=['hp', 'level'])\n",
    "    if len(hp_level_data) > 0:\n",
    "        axes[1, 0].scatter(hp_level_data['level'], hp_level_data['hp'], alpha=0.6, color=plot_colors['scatter'])\n",
    "        axes[1, 0].set_title('HP vs Nivel de Pokemon')\n",
    "        axes[1, 0].set_xlabel('Nivel')\n",
    "        axes[1, 0].set_ylabel('HP')\n",
    "    \n",
    "    # 4. Distribuci√≥n por g√©nero\n",
    "    gender_counts = df_pokemon['gender'].value_counts()\n",
    "    axes[1, 1].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', colors=primary_palette)\n",
    "    axes[1, 1].set_title('Distribuci√≥n por G√©nero')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'pokemon_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Visualizaci√≥n guardada: {OUTPUT_DIR / 'pokemon_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01930c4c",
   "metadata": {},
   "source": [
    "## 7. Extracci√≥n de features para entrenamiento de IA\n",
    "\n",
    "**Features seleccionados:**\n",
    "- **M√©tricas de batalla**: Duraci√≥n, eventos, ratios - capturan el 'estilo' de juego\n",
    "- **Ratings de jugadores**: Proxy del nivel de habilidad, importante para el aprendizaje\n",
    "- **Informaci√≥n de equipos**: Tama√±o, niveles promedio - contexto estrat√©gico\n",
    "- **Patrones temporales**: Eventos por turno - ritmo de juego que debe aprender la IA\n",
    "- Estos features formar√°n el input del modelo de machine learning para toma de decisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ff8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACCI√ìN DE FEATURES PARA IA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Features avanzadas a nivel de batalla para IA\n",
    "battle_features = []\n",
    "\n",
    "print(\"Extrayendo features avanzadas para entrenamiento de IA...\")\n",
    "for i, battle in enumerate(battles):\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f\"Procesadas {i + 1} batallas...\")\n",
    "    \n",
    "    # M√©tricas b√°sicas mejoradas\n",
    "    metrics = calculate_battle_metrics(battle)\n",
    "    \n",
    "    # Features de composici√≥n de equipos\n",
    "    team_features = extract_team_composition_features(battle)\n",
    "    \n",
    "    # Combinar todas las features\n",
    "    features = {\n",
    "        'battle_id': battle.get('battle_id'),\n",
    "        'total_turns': metrics['total_turns'],\n",
    "        'winner': metrics['winner'],\n",
    "        'reason': metrics['reason'],\n",
    "        'move_events': metrics['move_events'],\n",
    "        'switch_events': metrics['switch_events'],\n",
    "        'damage_events': metrics['damage_events'],\n",
    "        'effect_events': metrics['effect_events'],\n",
    "        'heal_events': metrics['heal_events'],\n",
    "        'status_events': metrics['status_events'],\n",
    "        'events_per_turn': metrics['events_per_turn'],\n",
    "        'early_game_intensity': metrics['early_game_intensity'],\n",
    "        'mid_game_intensity': metrics['mid_game_intensity'],\n",
    "        'late_game_intensity': metrics['late_game_intensity'],\n",
    "        'move_switch_ratio': metrics['move_switch_ratio'],\n",
    "        'consecutive_moves': metrics['consecutive_moves'],\n",
    "        'consecutive_switches': metrics['consecutive_switches'],\n",
    "        'action_diversity': metrics['action_diversity']\n",
    "    }\n",
    "    \n",
    "    # Informaci√≥n de jugadores\n",
    "    players = battle.get('players', {})\n",
    "    for player_id in ['p1', 'p2']:\n",
    "        player_info = players.get(player_id, {})\n",
    "        features[f'{player_id}_rating'] = player_info.get('ladder_rating_pre', 0)\n",
    "    \n",
    "    # Agregar features de composici√≥n de equipos\n",
    "    features.update(team_features)\n",
    "    \n",
    "    # Features de ventaja competitiva\n",
    "    if features['p1_rating'] and features['p2_rating']:\n",
    "        features['rating_difference'] = abs(features['p1_rating'] - features['p2_rating'])\n",
    "        features['rating_advantage_p1'] = features['p1_rating'] - features['p2_rating']\n",
    "    else:\n",
    "        features['rating_difference'] = 0\n",
    "        features['rating_advantage_p1'] = 0\n",
    "    \n",
    "    # Features de balance de equipos\n",
    "    features['team_size_difference'] = abs(features['p1_team_size'] - features['p2_team_size'])\n",
    "    features['level_advantage_p1'] = features['p1_avg_level'] - features['p2_avg_level']\n",
    "    features['hp_advantage_p1'] = features['p1_total_hp'] - features['p2_total_hp']\n",
    "    features['info_advantage_p1'] = features['p1_info_advantage'] - features['p2_info_advantage']\n",
    "    \n",
    "    battle_features.append(features)\n",
    "\n",
    "df_features = pd.DataFrame(battle_features)\n",
    "\n",
    "# Guardar features\n",
    "features_path = OUTPUT_DIR / 'battle_features.csv'\n",
    "df_features.to_csv(features_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ Extracci√≥n completada:\")\n",
    "print(f\"   ‚Ä¢ {len(df_features.columns)} caracter√≠sticas por batalla\")\n",
    "print(f\"   ‚Ä¢ {len(df_features)} batallas procesadas\")\n",
    "print(f\"   ‚Ä¢ Dataset guardado: {features_path.name}\")\n",
    "\n",
    "# Mostrar correlaciones importantes\n",
    "numeric_cols = df_features.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_cols) > 1:\n",
    "    correlations = df_features[numeric_cols].corr()\n",
    "    print(f\"\\nCorrelaciones m√°s altas con 'total_turns':\")\n",
    "    turn_corr = correlations['total_turns'].abs().sort_values(ascending=False)\n",
    "    for feature, corr in turn_corr.head(5).items():\n",
    "        if feature != 'total_turns':\n",
    "            print(f\"  - {feature}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\nPrimeras 5 filas del dataset de features:\")\n",
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b73f238",
   "metadata": {},
   "source": [
    "## 7.1 Validaci√≥n r√°pida con modelo baseline\n",
    "\n",
    "**Prop√≥sito del modelo baseline:**\n",
    "- Establece una l√≠nea base de rendimiento para comparar modelos futuros\n",
    "- Valida que las features tienen poder predictivo\n",
    "- Identifica las variables m√°s importantes\n",
    "- Detecta posibles problemas de data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4381ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüéØ {'='*50}\")\n",
    "print(\"   VALIDACI√ìN: MODELO BASELINE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Preparar datos para modelo baseline\n",
    "try:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import roc_auc_score, classification_report\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "    \n",
    "    # Seleccionar features num√©ricas para el baseline\n",
    "    numeric_features = df_features.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remover variables que no deben usarse para predicci√≥n\n",
    "    exclude_cols = ['battle_id'] if 'battle_id' in numeric_features else []\n",
    "    feature_cols = [col for col in numeric_features if col not in exclude_cols]\n",
    "    \n",
    "    # Preparar target\n",
    "    if 'winner' in df_features.columns:\n",
    "        # Filtrar solo batallas con ganador definido\n",
    "        valid_battles = df_features[df_features['winner'].isin(['p1', 'p2'])].copy()\n",
    "        \n",
    "        if len(valid_battles) > 10 and len(feature_cols) > 0:  # M√≠nimo para entrenar\n",
    "            X = valid_battles[feature_cols].fillna(0)  # Imputar nulos con 0\n",
    "            y = valid_battles['winner']\n",
    "            \n",
    "            # Codificar target\n",
    "            le = LabelEncoder()\n",
    "            y_encoded = le.fit_transform(y)\n",
    "            \n",
    "            # Split train/test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Escalar features para mejorar convergencia\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            # Entrenar modelo baseline con features escaladas\n",
    "            clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "            clf.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Evaluar con datos escalados\n",
    "            y_pred_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "            auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            print(f\"Modelo baseline entrenado:\")\n",
    "            print(f\"  - Features utilizadas: {len(feature_cols)}\")\n",
    "            print(f\"  - Tama√±o entrenamiento: {len(X_train):,}\")\n",
    "            print(f\"  - Tama√±o test: {len(X_test):,}\")\n",
    "            print(f\"  - ROC-AUC: {auc_score:.3f}\")\n",
    "            \n",
    "            # Importancia de features\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': feature_cols,\n",
    "                'importance': np.abs(clf.coef_[0])\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(f\"\\nTop 10 features m√°s importantes:\")\n",
    "            for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):\n",
    "                print(f\"  {i:2d}. {row['feature']}: {row['importance']:.3f}\")\n",
    "            \n",
    "            # Guardar importancia de features\n",
    "            importance_path = OUTPUT_DIR / 'feature_importance_baseline.csv'\n",
    "            feature_importance.to_csv(importance_path, index=False)\n",
    "            print(f\"\\nImportancia guardada: {importance_path}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Datos insuficientes para entrenar modelo baseline\")\n",
    "    else:\n",
    "        print(\"Variable 'winner' no encontrada para modelo baseline\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Scikit-learn no disponible. Instalar con: pip install scikit-learn\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en modelo baseline: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7691e5df",
   "metadata": {},
   "source": [
    "## 8. Matriz de correlaci√≥n de features num√©ricas\n",
    "\n",
    "**Prop√≥sito del an√°lisis de correlaciones:**\n",
    "- Identificamos features redundantes que pueden confundir al modelo\n",
    "- Detectamos relaciones no obvias entre variables que pueden ser √∫tiles\n",
    "- Ayuda a seleccionar las features m√°s informativas para el entrenamiento\n",
    "- Previene problemas de multicolinealidad en modelos lineales\n",
    "- Gu√≠a la ingenier√≠a de features y la selecci√≥n de variables para el modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de correlaci√≥n para features num√©ricas\n",
    "numeric_features = df_features.select_dtypes(include=[np.number])\n",
    "\n",
    "if len(numeric_features.columns) > 1:\n",
    "    correlation_matrix = numeric_features.corr()\n",
    "    \n",
    "    # Matriz completa (sin anotaciones para mejor legibilidad)\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(correlation_matrix, annot=False, cmap=plot_colors['heatmap'], center=0, \n",
    "                square=True, cbar_kws={'shrink': 0.8})\n",
    "    plt.title('Matriz de Correlaci√≥n Completa - Features Num√©ricas', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=8)\n",
    "    plt.yticks(rotation=0, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'correlation_matrix_full.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Matriz de correlaciones m√°s altas (filtrada)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    # Seleccionar solo correlaciones > 0.3 o < -0.3 con target variables\n",
    "    target_vars = ['total_turns', 'total_events', 'move_events', 'switch_events', 'events_per_turn']\n",
    "    important_vars = []\n",
    "    \n",
    "    for var in target_vars:\n",
    "        if var in correlation_matrix.columns:\n",
    "            corrs = correlation_matrix[var].abs().sort_values(ascending=False)\n",
    "            # Tomar top 8 correlaciones para cada variable target\n",
    "            important_vars.extend(corrs.head(8).index.tolist())\n",
    "    \n",
    "    # Eliminar duplicados y mantener orden\n",
    "    important_vars = list(dict.fromkeys(important_vars))[:20]  # M√°ximo 20 variables\n",
    "    \n",
    "    if len(important_vars) > 1:\n",
    "        filtered_corr = correlation_matrix.loc[important_vars, important_vars]\n",
    "        sns.heatmap(filtered_corr, annot=True, cmap=plot_colors['heatmap'], center=0, \n",
    "                    square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "        plt.title('Matriz de Correlaci√≥n - Variables M√°s Importantes', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / 'correlation_matrix_filtered.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"üìä Matrices de correlaci√≥n generadas:\")\n",
    "        print(f\"   ‚Ä¢ Matriz completa: visi√≥n general de todas las variables\")\n",
    "        print(f\"   ‚Ä¢ Matriz filtrada: enfoque en variables m√°s relevantes\")\n",
    "    else:\n",
    "        print(\"No hay suficientes variables para matriz filtrada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbef7ea",
   "metadata": {},
   "source": [
    "---\n",
    "# Ep√≠logo: El camino hacia la maestr√≠a\n",
    "\n",
    "**Nuestra investigaci√≥n llega a su fin, pero el verdadero viaje apenas comienza.**\n",
    "\n",
    "Hemos desentra√±ado los secretos de miles de batallas Pokemon, identificado a los campeones del meta, descubierto patrones temporales, y destilado todo este conocimiento en caracter√≠sticas que una IA puede aprender. \n",
    "\n",
    "## 9. Resumen ejecutivo para entrenamiento de IA\n",
    "\n",
    "**Los hallazgos de nuestra expedici√≥n:**\n",
    "\n",
    "Como exploradores que regresan de una tierra desconocida, traemos mapas, tesoros y sabidur√≠a. Estos son los insights que guiar√°n la creaci√≥n de nuestra IA Pokemon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca829d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN EJECUTIVO PARA ENTRENAMIENTO DE IA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"## La Sabidur√≠a Extra√≠da de Nuestro Viaje:\n",
    "\n",
    "### 1. La Confiabilidad de Nuestros Datos:\n",
    "   - Hemos analizado {len(battles):,} batallas reales y verificadas\n",
    "   - Formato gen9randombattle: el est√°ndar competitivo actual\n",
    "   - Cada batalla cuenta una historia completa con {len(df_features.columns)} caracter√≠sticas extra√≠das\n",
    "\n",
    "### 2. Los Secretos de las Batallas Exitosas:\n",
    "   - Las batallas competitivas duran en promedio {df_battles['total_turns'].mean():.1f} turnos\n",
    "   - El momentum cambia seg√∫n la fase: early-game vs late-game tienen din√°micas diferentes\n",
    "   - Los patrones de switching y timing son m√°s predictivos que las estad√≠sticas brutas\n",
    "\n",
    "### 3. El Arsenal Avanzado de Conocimiento para Nuestra IA:\n",
    "   - **Features Temporales**: Intensidad por fase de batalla (early/mid/late game)\n",
    "   - **Patrones de Decisi√≥n**: Ratios move/switch, acciones consecutivas, diversidad de acciones\n",
    "   - **Composici√≥n de Equipos**: Diversidad de especies, distribuci√≥n de niveles, ventajas de HP\n",
    "   - **Informaci√≥n Estrat√©gica**: Habilidades conocidas, items revelados, movimientos descubiertos\n",
    "   - **Ventajas Competitivas**: Diferencias de rating, balance de equipos, ventajas de informaci√≥n\n",
    "\n",
    "### 4. La Estrategia de Entrenamiento Revolucionaria:\n",
    "   - **Aprendizaje por Fases**: La IA debe adaptar estrategias seg√∫n early/mid/late game\n",
    "   - **Momentum Awareness**: Detectar cambios en intensidad y patrones de acci√≥n\n",
    "   - **Information Advantage**: Usar conocimiento parcial del oponente estrat√©gicamente\n",
    "   - **Team Synergy**: Entender composiciones de equipo y sus fortalezas/debilidades\n",
    "   - **Adaptive Decision Making**: Cambiar entre agresi√≥n y conservaci√≥n seg√∫n el contexto\n",
    "\n",
    "### 5. El Mapa Definitivo hacia la Maestr√≠a:\n",
    "   - **Arquitectura H√≠brida**: CNN para patrones + LSTM para secuencias temporales + Attention para decisiones cr√≠ticas\n",
    "   - **Multi-Task Learning**: Predecir pr√≥ximo movimiento + resultado de batalla + timing √≥ptimo\n",
    "   - **Curriculum Learning**: Entrenar primero en batallas simples, luego en escenarios complejos\n",
    "   - **Adversarial Training**: IA vs IA para desarrollar estrategias anti-meta\n",
    "   - **Continual Learning**: Adaptaci√≥n autom√°tica a cambios en el meta competitivo\n",
    "   - **Explainable AI**: Sistema de explicaci√≥n de decisiones para an√°lisis estrat√©gico\n",
    "\n",
    "### 6. Features Cr√≠ticas Implementadas (NUEVO):\n",
    "   - **{len([c for c in df_features.columns if 'intensity' in c])} m√©tricas de intensidad** por fase de batalla\n",
    "   - **{len([c for c in df_features.columns if 'advantage' in c])} indicadores de ventaja** estrat√©gica\n",
    "   - **{len([c for c in df_features.columns if 'diversity' in c or 'ratio' in c])} m√©tricas de diversidad** y patrones\n",
    "   - **Informaci√≥n de revelaci√≥n progresiva** para decisiones bajo incertidumbre\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cc41e",
   "metadata": {},
   "source": [
    "## 10. Estad√≠sticas finales y archivos generados\n",
    "\n",
    "**Importancia de la documentaci√≥n:**\n",
    "- Proporciona un inventario completo de los artefactos generados\n",
    "- Facilita la reproducibilidad del an√°lisis\n",
    "- Permite validar que todos los pasos se ejecutaron correctamente\n",
    "- Sirve como checklist para asegurar que no falta ning√∫n componente\n",
    "- Documenta el punto de partida para la siguiente fase del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15418188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"NUESTRA EXPEDICI√ìN HA CONCLUIDO\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(\"\\n** El conocimiento ha sido extra√≠do, los patrones revelados. **\")\n",
    "print(\"** Nuestra IA ahora tiene el mapa para convertirse en maestra Pokemon. **\")\n",
    "\n",
    "print(f\"\\nArchivos generados en: {OUTPUT_DIR.resolve()}\")\n",
    "output_files = list(OUTPUT_DIR.glob(\"*\"))\n",
    "for file in output_files:\n",
    "    print(f\"  - {file.name}\")\n",
    "\n",
    "print(f\"\\nTesoros de conocimiento recolectados:\")\n",
    "print(f\"  - Historias de batalla analizadas: {len(df_battles)} registros\")\n",
    "print(f\"  - Protagonistas Pokemon catalogados: {len(df_pokemon)} registros\")\n",
    "print(f\"  - Caracter√≠sticas estrat√©gicas extra√≠das: {len(df_features)} registros\")\n",
    "print(f\"  - Features avanzadas implementadas: {len(df_features.columns)} dimensiones\")\n",
    "print(f\"  - M√©tricas de momentum y timing: Implementadas\")\n",
    "print(f\"  - An√°lisis de composici√≥n de equipos: Completo\")\n",
    "print(f\"  - Sistema de ventajas competitivas: Operativo\")\n",
    "print(f\"\\n** La IA ahora tiene acceso a patrones temporales, momentum de batalla,\")\n",
    "print(f\"   composici√≥n de equipos y ventajas estrat√©gicas - todo lo necesario\")\n",
    "print(f\"   para decisiones de nivel maestro Pokemon. **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8590502",
   "metadata": {},
   "source": [
    "---\n",
    "# Cap√≠tulo 5: ¬øCu√°ndo ocurren las batallas?\n",
    "\n",
    "**El tiempo revela secretos que las estad√≠sticas b√°sicas no pueden mostrar.**\n",
    "\n",
    "¬øHay momentos del d√≠a donde los entrenadores m√°s h√°biles est√°n activos? ¬øCambian las estrategias con el tiempo? ¬øEvoluciona el meta de formas que nuestra IA debe anticipar?\n",
    "\n",
    "## 11. An√°lisis temporal de batallas\n",
    "\n",
    "**Explorando los ritmos del combate:**\n",
    "- ¬øCu√°ndo luchan los entrenadores m√°s dedicados?\n",
    "- ¬øHay patrones estacionales en las estrategias Pokemon?\n",
    "- ¬øC√≥mo evoluciona el meta a trav√©s del tiempo?\n",
    "- ¬øDebe nuestra IA adaptarse a diferentes \"√©pocas\" del juego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd064be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n‚è∞ {'='*50}\")\n",
    "print(\"   CAP√çTULO 6: PATRONES TEMPORALES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(df_battles) > 0 and 'timestamp' in df_battles.columns:\n",
    "    # Convertir timestamp a datetime\n",
    "    df_battles['datetime'] = pd.to_datetime(df_battles['timestamp'], unit='s', errors='coerce')\n",
    "    \n",
    "    if df_battles['datetime'].notna().sum() > 0:\n",
    "        # An√°lisis por d√≠a de la semana\n",
    "        df_battles['day_of_week'] = df_battles['datetime'].dt.day_name()\n",
    "        battles_by_day = df_battles['day_of_week'].value_counts()\n",
    "        \n",
    "        print(\"Distribuci√≥n de batallas por d√≠a de la semana:\")\n",
    "        for day, count in battles_by_day.items():\n",
    "            print(f\"  - {day}: {count:,} batallas\")\n",
    "        \n",
    "        # An√°lisis por hora del d√≠a\n",
    "        df_battles['hour'] = df_battles['datetime'].dt.hour\n",
    "        battles_by_hour = df_battles['hour'].value_counts().sort_index()\n",
    "        \n",
    "        print(f\"\\nHoras pico de actividad:\")\n",
    "        top_hours = battles_by_hour.head(3)\n",
    "        for hour, count in top_hours.items():\n",
    "            print(f\"  - {hour:02d}:00: {count:,} batallas\")\n",
    "        \n",
    "        # Evoluci√≥n temporal de duraci√≥n promedio\n",
    "        df_battles['date'] = df_battles['datetime'].dt.date\n",
    "        daily_avg_turns = df_battles.groupby('date')['total_turns'].mean()\n",
    "        \n",
    "        if len(daily_avg_turns) > 1:\n",
    "            trend = \"creciente\" if daily_avg_turns.iloc[-1] > daily_avg_turns.iloc[0] else \"decreciente\"\n",
    "            print(f\"\\nTendencia en duraci√≥n de batallas: {trend}\")\n",
    "            print(f\"  - Primer d√≠a: {daily_avg_turns.iloc[0]:.1f} turnos promedio\")\n",
    "            print(f\"  - √öltimo d√≠a: {daily_avg_turns.iloc[-1]:.1f} turnos promedio\")\n",
    "        \n",
    "        # Visualizaci√≥n temporal\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Batallas por d√≠a de la semana\n",
    "        battles_by_day.plot(kind='bar', ax=axes[0], color=plot_colors['bar'])\n",
    "        axes[0].set_title('Batallas por D√≠a de la Semana')\n",
    "        axes[0].set_xlabel('D√≠a')\n",
    "        axes[0].set_ylabel('N√∫mero de Batallas')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Batallas por hora\n",
    "        battles_by_hour.plot(kind='line', ax=axes[1], color=plot_colors['line'], marker='o')\n",
    "        axes[1].set_title('Actividad por Hora del D√≠a')\n",
    "        axes[1].set_xlabel('Hora')\n",
    "        axes[1].set_ylabel('N√∫mero de Batallas')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / 'temporal_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"An√°lisis temporal guardado: {OUTPUT_DIR / 'temporal_analysis.png'}\")\n",
    "    else:\n",
    "        print(\"No se encontraron timestamps v√°lidos para an√°lisis temporal\")\n",
    "else:\n",
    "    print(\"Columna 'timestamp' no disponible para an√°lisis temporal\")\n",
    "\n",
    "# Crear diccionario de datos para documentaci√≥n\n",
    "if len(df_features) > 0:\n",
    "    data_dict = (df_features.dtypes.to_frame('dtype')\n",
    "                .assign(\n",
    "                    nunique=df_features.nunique(),\n",
    "                    n_null=df_features.isnull().sum(),\n",
    "                    pct_null=(df_features.isnull().sum()/len(df_features)*100).round(2),\n",
    "                    sample_values=df_features.astype(str).apply(\n",
    "                        lambda s: ', '.join(s.dropna().unique()[:3])\n",
    "                    )\n",
    "                )\n",
    "                .sort_values('nunique', ascending=False))\n",
    "    \n",
    "    # Guardar diccionario de datos\n",
    "    dict_path = OUTPUT_DIR / 'data_dictionary.csv'\n",
    "    data_dict.to_csv(dict_path)\n",
    "    \n",
    "    # Guardar dataset limpio\n",
    "    clean_dataset_path = OUTPUT_DIR / 'dataset_limpio_features.parquet'\n",
    "    df_features.to_parquet(clean_dataset_path, index=False)\n",
    "\n",
    "print(f\"\\nüéØ An√°lisis EDA completado exitosamente\")\n",
    "\n",
    "# Guardar dataset de batallas\n",
    "battles_clean_path = OUTPUT_DIR / 'dataset_batallas_limpio.parquet'\n",
    "df_battles.to_parquet(battles_clean_path, index=False)\n",
    "\n",
    "# Si hay datos de Pokemon, guardarlos tambi√©n\n",
    "if len(df_pokemon) > 0:\n",
    "    pokemon_clean_path = OUTPUT_DIR / 'dataset_pokemon_limpio.parquet'\n",
    "    df_pokemon.to_parquet(pokemon_clean_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ An√°lisis EDA completado - datasets guardados para entrenamiento de IA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4621e1",
   "metadata": {},
   "source": [
    "## 13. An√°lisis de tipos de Pokemon\n",
    "\n",
    "**Relevancia para la IA:**\n",
    "- Los tipos determinan efectividad de movimientos\n",
    "- Crucial para decisiones estrat√©gicas\n",
    "- Identifica combinaciones de tipos dominantes\n",
    "- Informa sobre balance del meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b003606",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"\\nüî• {'='*50}\")\n",
    "print(\"   CAP√çTULO 7: AN√ÅLISIS DE TIPOS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(df_pokemon) > 0:\n",
    "    # Simular tipos basados en especies conocidas (esto deber√≠a venir de los datos reales)\n",
    "    # En un caso real, extraer√≠as los tipos de la estructura JSON\n",
    "    type_mapping = {\n",
    "        'Charizard': ['Fire', 'Flying'], 'Blastoise': ['Water'], 'Venusaur': ['Grass', 'Poison'],\n",
    "        'Pikachu': ['Electric'], 'Garchomp': ['Dragon', 'Ground'], 'Metagross': ['Steel', 'Psychic'],\n",
    "        'Tyranitar': ['Rock', 'Dark'], 'Dragonite': ['Dragon', 'Flying'], 'Salamence': ['Dragon', 'Flying'],\n",
    "        'Lucario': ['Fighting', 'Steel'], 'Gengar': ['Ghost', 'Poison'], 'Alakazam': ['Psychic']\n",
    "    }\n",
    "    \n",
    "    # Expandir tipos para an√°lisis\n",
    "    type_analysis = []\n",
    "    for _, pokemon in df_pokemon.iterrows():\n",
    "        species = pokemon['species']\n",
    "        if species in type_mapping:\n",
    "            for ptype in type_mapping[species]:\n",
    "                type_analysis.append({\n",
    "                    'species': species,\n",
    "                    'type': ptype,\n",
    "                    'player': pokemon['player'],\n",
    "                    'winner': pokemon['winner']\n",
    "                })\n",
    "    \n",
    "    if type_analysis:\n",
    "        df_types = pd.DataFrame(type_analysis)\n",
    "        \n",
    "        # Tipos m√°s comunes\n",
    "        type_counts = df_types['type'].value_counts()\n",
    "        print(\"Top 10 tipos m√°s utilizados:\")\n",
    "        for i, (ptype, count) in enumerate(type_counts.head(10).items(), 1):\n",
    "            print(f\"  {i:2d}. {ptype}: {count:,} usos\")\n",
    "        \n",
    "        # An√°lisis de efectividad por tipo\n",
    "        if 'winner' in df_types.columns:\n",
    "            # Calcular winrates por tipo (evitando FutureWarning)\n",
    "            type_stats = []\n",
    "            for ptype in df_types['type'].unique():\n",
    "                type_data = df_types[df_types['type'] == ptype]\n",
    "                if len(type_data) > 10:\n",
    "                    winrate = (type_data['winner'] == type_data['player']).mean()\n",
    "                    type_stats.append({'type': ptype, 'winrate': winrate})\n",
    "            \n",
    "            if type_stats:\n",
    "                type_winrates = pd.DataFrame(type_stats).set_index('type')['winrate'].sort_values(ascending=False)\n",
    "            \n",
    "            if len(type_winrates) > 0:\n",
    "                print(f\"\\nTipos con mejor winrate (m√≠n. 10 usos):\")\n",
    "                for ptype, winrate in type_winrates.head(5).items():\n",
    "                    print(f\"  - {ptype}: {winrate:.1%}\")\n",
    "        \n",
    "        # Visualizaci√≥n de tipos\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Distribuci√≥n de tipos\n",
    "        type_counts.head(12).plot(kind='barh', ax=axes[0], color=plot_colors['bar'])\n",
    "        axes[0].set_yticks(range(len(type_counts)))\n",
    "        axes[0].set_yticklabels(type_counts.index)\n",
    "        axes[0].set_title('Distribuci√≥n de Tipos de Pokemon')\n",
    "        axes[0].set_xlabel('N√∫mero de Usos')\n",
    "        \n",
    "        # Winrates por tipo (si disponible)\n",
    "        if len(type_winrates) > 0:\n",
    "            type_winrates.head(10).plot(kind='bar', ax=axes[1], color=plot_colors['bar'])\n",
    "            axes[1].set_title('Winrate por Tipo de Pokemon')\n",
    "            axes[1].set_ylabel('Winrate')\n",
    "            axes[1].tick_params(axis='x', rotation=45)\n",
    "            axes[1].axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='50%')\n",
    "            axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / 'type_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"An√°lisis de tipos guardado: {OUTPUT_DIR / 'type_analysis.png'}\")\n",
    "    else:\n",
    "        print(\"No se pudieron mapear tipos para las especies encontradas\")\n",
    "else:\n",
    "    print(\"No hay datos de Pokemon disponibles para an√°lisis de tipos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0df8aff",
   "metadata": {},
   "source": [
    "---\n",
    "# Estrategia Final: El Blueprint para la IA Maestra\n",
    "\n",
    "**Despu√©s de nuestro exhaustivo viaje por los datos, es momento de trazar el mapa definitivo hacia la creaci√≥n de una IA Pokemon de nivel maestro.**\n",
    "\n",
    "Hemos extra√≠do cada secreto de las batallas, analizado cada patr√≥n, y destilado todo el conocimiento en caracter√≠sticas que una IA puede dominar. Ahora, presentamos la estrategia revolucionaria que transformar√° estos insights en inteligencia artificial superior.\n",
    "\n",
    "## Estrategia de Entrenamiento Revolucionaria\n",
    "\n",
    "### Arquitectura Recomendada\n",
    "\n",
    "**Modelo H√≠brido Multi-Componente:**\n",
    "- **CNN (Convolutional Neural Network)**: Para patrones espaciales de equipos y composiciones\n",
    "- **LSTM (Long Short-Term Memory)**: Para secuencias temporales de batalla y momentum\n",
    "- **Attention Mechanism**: Para decisiones cr√≠ticas por turno y timing √≥ptimo\n",
    "- **Transformer Blocks**: Para relaciones complejas entre Pokemon y movimientos\n",
    "\n",
    "### Enfoques de Aprendizaje Avanzados\n",
    "\n",
    "**Multi-Task Learning:**\n",
    "- Predecir pr√≥ximo movimiento √≥ptimo\n",
    "- Estimar probabilidad de victoria\n",
    "- Calcular timing perfecto para switches\n",
    "- Evaluar riesgo/recompensa de cada acci√≥n\n",
    "\n",
    "**Curriculum Learning:**\n",
    "- Fase 1: Batallas simples y directas\n",
    "- Fase 2: Escenarios con switches complejos\n",
    "- Fase 3: Batallas de alta intensidad y momentum\n",
    "- Fase 4: Meta-game y estrategias anti-competitivas\n",
    "\n",
    "**Adversarial Training:**\n",
    "- IA vs IA para desarrollar estrategias anti-meta\n",
    "- Generaci√≥n de escenarios adversos\n",
    "- Robustez contra estrategias impredecibles\n",
    "\n",
    "**Continual Learning:**\n",
    "- Adaptaci√≥n autom√°tica a cambios en el meta competitivo\n",
    "- Aprendizaje incremental de nuevas estrategias\n",
    "- Preservaci√≥n de conocimiento previo\n",
    "\n",
    "## Impacto Revolucionario en el Rendimiento\n",
    "\n",
    "**Con nuestras mejoras implementadas, la IA ahora puede:**\n",
    "\n",
    "**1. Detectar Momentum y Cambiar Estrategias Seg√∫n la Fase**\n",
    "- Reconocer patrones de early-game vs late-game\n",
    "- Adaptar agresividad seg√∫n intensidad de batalla\n",
    "- Optimizar decisiones por fase temporal\n",
    "\n",
    "**2. Evaluar Ventajas de Informaci√≥n y Composici√≥n de Equipos**\n",
    "- Calcular ventajas de HP, nivel y diversidad\n",
    "- Aprovechar informaci√≥n parcial del oponente\n",
    "- Optimizar team synergy y balance\n",
    "\n",
    "**3. Predecir Patrones de Decisi√≥n del Oponente**\n",
    "- Analizar ratios move/switch hist√≥ricos\n",
    "- Detectar tendencias en acciones consecutivas\n",
    "- Anticipar cambios de estrategia\n",
    "\n",
    "**4. Optimizar Timing de Switches y Movimientos Cr√≠ticos**\n",
    "- Calcular momentos √≥ptimos para cambios\n",
    "- Maximizar impacto de movimientos especiales\n",
    "- Minimizar riesgos en decisiones cr√≠ticas\n",
    "\n",
    "**5. Adaptarse Din√°micamente a Diferentes Estilos de Juego**\n",
    "- Reconocer estilos agresivos vs defensivos\n",
    "- Ajustar estrategia seg√∫n rating del oponente\n",
    "- Evolucionar t√°ctica durante la batalla\n",
    "\n",
    "## El Legado de Nuestro An√°lisis\n",
    "\n",
    "**Hemos transformado datos crudos en sabidur√≠a estrat√©gica.**\n",
    "\n",
    "Cada feature extra√≠da, cada patr√≥n descubierto, cada insight revelado contribuye a crear una IA que no solo juega Pokemon, sino que comprende la esencia misma del combate estrat√©gico. \n",
    "\n",
    "**La IA resultante ser√° capaz de:**\n",
    "- Tomar decisiones con la intuici√≥n de un maestro\n",
    "- Adaptarse con la flexibilidad de un experto\n",
    "- Aprender con la velocidad de una m√°quina\n",
    "- Competir con la precisi√≥n de un campe√≥n\n",
    "\n",
    "**El futuro del combate Pokemon ha comenzado.**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
