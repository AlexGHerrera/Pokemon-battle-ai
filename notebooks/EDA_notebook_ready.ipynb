{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4ab383",
   "metadata": {},
   "source": [
    "# Pokemon Battle Dataset - An√°lisis Exploratorio de Datos (EDA)\n",
    "\n",
    "## La Historia que Vamos a Contar\n",
    "\n",
    "**Imagina que eres un entrenador Pokemon novato** que quiere convertirse en maestro. ¬øC√≥mo aprender√≠as? Observando a los mejores, analizando sus estrategias, entendiendo qu√© Pokemon usan y cu√°ndo.\n",
    "\n",
    "**Eso es exactamente lo que haremos con nuestra IA.** A trav√©s de aproximadamente 14,000 batallas reales de Pokemon Showdown, descubriremos:\n",
    "\n",
    "- **¬øQu√© hace que una batalla sea exitosa?**\n",
    "- **¬øCu√°les son las estrategias ganadoras?**\n",
    "- **¬øQu√© Pokemon dominan el meta competitivo?**\n",
    "- **¬øC√≥mo puede nuestra IA aprender estos patrones?**\n",
    "\n",
    "## Nuestro Viaje de Descubrimiento\n",
    "\n",
    "**Cap√≠tulo 1**: *¬øSon nuestros datos confiables?* - Validaci√≥n de calidad y integridad\n",
    "**Cap√≠tulo 2**: *¬øQu√© nos dicen las batallas?* - Patrones y m√©tricas de combate\n",
    "**Cap√≠tulo 3**: *¬øQui√©nes son los protagonistas?* - An√°lisis profundo de Pokemon\n",
    "**Cap√≠tulo 4**: *¬øCu√°ndo ocurren las batallas?* - Patrones temporales del meta\n",
    "**Cap√≠tulo 5**: *¬øQu√© debe aprender nuestra IA?* - Ingenier√≠a de caracter√≠sticas\n",
    "**Ep√≠logo**: *El camino hacia la maestr√≠a* - Pr√≥ximos pasos para el entrenamiento\n",
    "\n",
    "## Alcance del Proyecto\n",
    "\n",
    "Este proyecto tiene como objetivo desarrollar un **modelo de inteligencia artificial capaz de jugar Pokemon de forma aut√≥noma** contra usuarios humanos. Para lograr esto, necesitamos comprender profundamente los patrones de batalla, estrategias ganadoras y comportamientos de los jugadores expertos.\n",
    "\n",
    "### Contexto del Dataset\n",
    "\n",
    "- **Fuente**: Batallas reales de Pokemon Showdown (formato gen9randombattle)\n",
    "- **Volumen**: ~14,000 batallas individuales en formato JSON\n",
    "- **Contenido**: Turnos secuenciales, eventos de batalla, estados del juego, resultados\n",
    "- **Aplicaci√≥n**: Entrenamiento de modelo de IA para toma de decisiones en tiempo real\n",
    "\n",
    "---\n",
    "\n",
    "# %% [markdown]\n",
    "## Importaci√≥n de librer√≠as y configuraci√≥n inicial\n",
    "\n",
    "**Objetivo de esta secci√≥n:**\n",
    "- Importamos las librer√≠as necesarias para el an√°lisis de datos y visualizaci√≥n\n",
    "- Configuramos matplotlib y seaborn para generar gr√°ficas consistentes y profesionales\n",
    "- Configuramos el entorno de trabajo para an√°lisis √≥ptimo\n",
    "- Estas configuraciones son fundamentales para un EDA reproducible y visualmente atractivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62fbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "# Nota: No suprimimos warnings para mantener visibilidad de posibles problemas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Configuraci√≥n de visualizaciones\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configuraci√≥n de reproducibilidad\n",
    "import platform\n",
    "import sys\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(\"‚úÖ Configuraci√≥n de visualizaci√≥n establecida\")\n",
    "print(f\"üîß Entorno: {platform.platform()}\")\n",
    "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "print(\"üé≤ Seeds configuradas para reproducibilidad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fae6ff",
   "metadata": {},
   "source": [
    "## Configuraci√≥n de rutas y constantes\n",
    "\n",
    "**Prop√≥sito de la configuraci√≥n:**\n",
    "- Centralizamos la gesti√≥n de archivos para facilitar el mantenimiento del c√≥digo\n",
    "- `BATTLES_DIR`: Contiene los archivos JSON individuales de cada batalla\n",
    "- `ALL_BATTLES_JSON`: Archivo consolidado que mejora la velocidad de carga\n",
    "- `OUTPUT_DIR`: Directorio donde guardaremos visualizaciones y resultados\n",
    "- Esta organizaci√≥n es crucial para un flujo de trabajo ordenado y escalable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68bf00e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"../data\")  # Subir un nivel desde notebooks/\n",
    "BATTLES_DIR = DATA_DIR / \"battles\"\n",
    "ALL_BATTLES_JSON = DATA_DIR / \"all_battles.json\"\n",
    "OUTPUT_DIR = Path(\"../output\")  # Crear output en la ra√≠z del proyecto\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\" Directorio de datos: {DATA_DIR}\")\n",
    "print(f\" Directorio de batallas: {BATTLES_DIR}\")\n",
    "print(f\" Archivo consolidado: {ALL_BATTLES_JSON}\")\n",
    "print(f\" Directorio de salida: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9eb00",
   "metadata": {},
   "source": [
    "## Funciones auxiliares para procesamiento de datos\n",
    "\n",
    "**Funciones implementadas:**\n",
    "- `get_in()`: Navega estructuras JSON anidadas de forma segura, evitando errores por claves faltantes\n",
    "- `extract_pokemon_info()`: Extrae informaci√≥n espec√≠fica de Pokemon que ser√° clave para el modelo de IA\n",
    "- `calculate_battle_metrics()`: Calcula m√©tricas estrat√©gicas como eventos por turno, tipos de acciones, etc.\n",
    "- Estas funciones nos permiten transformar datos complejos en features estructuradas para machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d31d31",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_in(d: Any, path: List[str], default: Any = None) -> Any:\n",
    "    \"\"\"Extrae valores anidados de diccionarios de forma segura.\"\"\"\n",
    "    cur = d\n",
    "    for k in path:\n",
    "        if isinstance(cur, dict) and k in cur:\n",
    "            cur = cur[k]\n",
    "        else:\n",
    "            return default\n",
    "    return cur\n",
    "\n",
    "def extract_pokemon_info(battle: dict) -> List[dict]:\n",
    "    \"\"\"Extrae informaci√≥n detallada de Pokemon de una batalla.\"\"\"\n",
    "    pokemon_info = []\n",
    "    teams = get_in(battle, [\"team_revelation\", \"teams\"], {})\n",
    "    \n",
    "    for player_id, team in teams.items():\n",
    "        if isinstance(team, list):\n",
    "            for pokemon in team:\n",
    "                # Extraer todas las estad√≠sticas base disponibles\n",
    "                base_stats = pokemon.get('base_stats', {})\n",
    "                info = {\n",
    "                    'battle_id': battle.get('battle_id'),\n",
    "                    'player': player_id,\n",
    "                    'species': pokemon.get('species'),\n",
    "                    'level': pokemon.get('level'),\n",
    "                    'gender': pokemon.get('gender'),\n",
    "                    'hp': base_stats.get('hp'),\n",
    "                    'attack': base_stats.get('attack'),\n",
    "                    'defense': base_stats.get('defense'),\n",
    "                    'sp_attack': base_stats.get('sp_attack'),\n",
    "                    'sp_defense': base_stats.get('sp_defense'),\n",
    "                    'speed': base_stats.get('speed'),\n",
    "                    'first_seen_turn': pokemon.get('first_seen_turn'),\n",
    "                    'revelation_status': pokemon.get('revelation_status'),\n",
    "                    'known_ability': pokemon.get('known_ability'),\n",
    "                    'known_item': pokemon.get('known_item'),\n",
    "                    'known_tera_type': pokemon.get('known_tera_type'),\n",
    "                    'known_moves_count': len(pokemon.get('known_moves', [])),\n",
    "                    'unknown_move_slots': pokemon.get('unknown_move_slots', 0)\n",
    "                }\n",
    "                pokemon_info.append(info)\n",
    "    return pokemon_info\n",
    "\n",
    "def calculate_battle_metrics(battle: dict) -> dict:\n",
    "    \"\"\"Calcula m√©tricas clave de una batalla para an√°lisis avanzado de IA.\"\"\"\n",
    "    metadata = battle.get('metadata', {})\n",
    "    turns = battle.get('turns', [])\n",
    "    \n",
    "    # M√©tricas b√°sicas\n",
    "    total_turns = len(turns)\n",
    "    winner = get_in(metadata, ['outcome', 'winner'])\n",
    "    reason = get_in(metadata, ['outcome', 'reason'])\n",
    "    \n",
    "    # An√°lisis detallado de eventos\n",
    "    total_events = 0\n",
    "    move_events = 0\n",
    "    switch_events = 0\n",
    "    damage_events = 0\n",
    "    effect_events = 0\n",
    "    heal_events = 0\n",
    "    status_events = 0\n",
    "    \n",
    "    # M√©tricas de momentum y timing\n",
    "    early_game_events = 0  # Primeros 3 turnos\n",
    "    mid_game_events = 0    # Turnos 4-8\n",
    "    late_game_events = 0   # Turnos 9+\n",
    "    \n",
    "    # Patrones de decisi√≥n\n",
    "    consecutive_moves = 0\n",
    "    consecutive_switches = 0\n",
    "    last_action = None\n",
    "    \n",
    "    for turn_idx, turn in enumerate(turns, 1):\n",
    "        events = turn.get('events', [])\n",
    "        turn_event_count = len(events)\n",
    "        total_events += turn_event_count\n",
    "        \n",
    "        # Clasificar por fase de batalla\n",
    "        if turn_idx <= 3:\n",
    "            early_game_events += turn_event_count\n",
    "        elif turn_idx <= 8:\n",
    "            mid_game_events += turn_event_count\n",
    "        else:\n",
    "            late_game_events += turn_event_count\n",
    "        \n",
    "        for event in events:\n",
    "            event_type = event.get('type')\n",
    "            \n",
    "            # Conteo de tipos de eventos\n",
    "            if event_type == 'move':\n",
    "                move_events += 1\n",
    "                if last_action == 'move':\n",
    "                    consecutive_moves += 1\n",
    "                last_action = 'move'\n",
    "            elif event_type == 'switch':\n",
    "                switch_events += 1\n",
    "                if last_action == 'switch':\n",
    "                    consecutive_switches += 1\n",
    "                last_action = 'switch'\n",
    "            elif event_type == 'damage':\n",
    "                damage_events += 1\n",
    "            elif event_type == 'effect':\n",
    "                effect_events += 1\n",
    "            elif event_type == 'heal':\n",
    "                heal_events += 1\n",
    "            elif event_type in ['status', 'boost', 'unboost']:\n",
    "                status_events += 1\n",
    "    \n",
    "    return {\n",
    "        'battle_id': battle.get('battle_id'),\n",
    "        'total_turns': total_turns,\n",
    "        'total_events': total_events,\n",
    "        'move_events': move_events,\n",
    "        'switch_events': switch_events,\n",
    "        'damage_events': damage_events,\n",
    "        'effect_events': effect_events,\n",
    "        'heal_events': heal_events,\n",
    "        'status_events': status_events,\n",
    "        'winner': winner,\n",
    "        'reason': reason,\n",
    "        'events_per_turn': total_events / max(total_turns, 1),\n",
    "        'timestamp': metadata.get('timestamp_unix'),\n",
    "        # M√©tricas de momentum\n",
    "        'early_game_intensity': early_game_events / max(min(total_turns, 3), 1),\n",
    "        'mid_game_intensity': mid_game_events / max(min(total_turns - 3, 5), 1) if total_turns > 3 else 0,\n",
    "        'late_game_intensity': late_game_events / max(total_turns - 8, 1) if total_turns > 8 else 0,\n",
    "        # Patrones de decisi√≥n\n",
    "        'move_switch_ratio': move_events / max(switch_events, 1),\n",
    "        'consecutive_moves': consecutive_moves,\n",
    "        'consecutive_switches': consecutive_switches,\n",
    "        'action_diversity': len(set([e.get('type') for turn in turns for e in turn.get('events', [])]))  \n",
    "    }\n",
    "\n",
    "def extract_team_composition_features(battle: dict) -> dict:\n",
    "    \"\"\"Extrae features avanzadas de composici√≥n de equipos para IA.\"\"\"\n",
    "    teams = get_in(battle, [\"team_revelation\", \"teams\"], {})\n",
    "    features = {'battle_id': battle.get('battle_id')}\n",
    "    \n",
    "    for player_id in ['p1', 'p2']:\n",
    "        team = teams.get(player_id, [])\n",
    "        if isinstance(team, list) and team:\n",
    "            # M√©tricas b√°sicas del equipo\n",
    "            levels = [p.get('level', 0) for p in team if p.get('level')]\n",
    "            hps = [get_in(p, ['base_stats', 'hp']) for p in team if get_in(p, ['base_stats', 'hp'])]\n",
    "            \n",
    "            features.update({\n",
    "                f'{player_id}_team_size': len(team),\n",
    "                f'{player_id}_avg_level': np.mean(levels) if levels else 0,\n",
    "                f'{player_id}_level_std': np.std(levels) if len(levels) > 1 else 0,\n",
    "                f'{player_id}_min_level': min(levels) if levels else 0,\n",
    "                f'{player_id}_max_level': max(levels) if levels else 0,\n",
    "                f'{player_id}_avg_hp': np.mean(hps) if hps else 0,\n",
    "                f'{player_id}_hp_std': np.std(hps) if len(hps) > 1 else 0,\n",
    "                f'{player_id}_total_hp': sum(hps) if hps else 0,\n",
    "            })\n",
    "            \n",
    "            # Diversidad de especies\n",
    "            species = [p.get('species') for p in team if p.get('species')]\n",
    "            features[f'{player_id}_species_diversity'] = len(set(species))\n",
    "            \n",
    "            # Informaci√≥n de revelaci√≥n\n",
    "            revelation_statuses = [p.get('revelation_status') for p in team]\n",
    "            features[f'{player_id}_fully_revealed'] = revelation_statuses.count('fully_revealed')\n",
    "            features[f'{player_id}_partially_revealed'] = revelation_statuses.count('partially_revealed')\n",
    "            \n",
    "            # Informaci√≥n conocida vs desconocida\n",
    "            known_abilities = sum(1 for p in team if p.get('known_ability'))\n",
    "            known_items = sum(1 for p in team if p.get('known_item'))\n",
    "            total_known_moves = sum(len(p.get('known_moves', [])) for p in team)\n",
    "            \n",
    "            features.update({\n",
    "                f'{player_id}_known_abilities': known_abilities,\n",
    "                f'{player_id}_known_items': known_items,\n",
    "                f'{player_id}_total_known_moves': total_known_moves,\n",
    "                f'{player_id}_info_advantage': (known_abilities + known_items + total_known_moves) / max(len(team), 1)\n",
    "            })\n",
    "        else:\n",
    "            # Valores por defecto si no hay datos del equipo\n",
    "            for metric in ['team_size', 'avg_level', 'level_std', 'min_level', 'max_level', \n",
    "                          'avg_hp', 'hp_std', 'total_hp', 'species_diversity', \n",
    "                          'fully_revealed', 'partially_revealed', 'known_abilities', \n",
    "                          'known_items', 'total_known_moves', 'info_advantage']:\n",
    "                features[f'{player_id}_{metric}'] = 0\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\" Funciones auxiliares avanzadas definidas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b92516",
   "metadata": {},
   "source": [
    "## Funciones de optimizaci√≥n para datasets grandes\n",
    "\n",
    "**Estrategias implementadas:**\n",
    "- Muestreo aleatorio para desarrollo r√°pido\n",
    "- Conversi√≥n a formato Parquet (m√°s eficiente)\n",
    "- Carga por chunks para evitar problemas de memoria\n",
    "- Procesamiento incremental de batallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b72f9b2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_sample_dataset(sample_size: int = 1000, force_recreate: bool = False) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Crea un dataset de muestra para desarrollo r√°pido.\n",
    "    \n",
    "    Args:\n",
    "        sample_size: N√∫mero de batallas a incluir en la muestra\n",
    "        force_recreate: Si True, recrea la muestra aunque ya exista\n",
    "    \"\"\"\n",
    "    sample_path = DATA_DIR / f\"battles_sample_{sample_size}.json\"\n",
    "    \n",
    "    if sample_path.exists() and not force_recreate:\n",
    "        print(f\"Cargando muestra existente: {sample_path}\")\n",
    "        with open(sample_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    print(f\"Creando nueva muestra de {sample_size} batallas...\")\n",
    "    \n",
    "    # Cargar dataset completo y tomar muestra aleatoria\n",
    "    with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "        all_battles = json.load(f)\n",
    "    \n",
    "    import random\n",
    "    random.seed(42)  # Para reproducibilidad\n",
    "    sample_battles = random.sample(all_battles, min(sample_size, len(all_battles)))\n",
    "    \n",
    "    # Guardar muestra\n",
    "    with open(sample_path, \"w\") as f:\n",
    "        json.dump(sample_battles, f, indent=2)\n",
    "    \n",
    "    print(f\"Muestra guardada: {sample_path}\")\n",
    "    print(f\"Tama√±o de muestra: {len(sample_battles)} batallas\")\n",
    "    \n",
    "    return sample_battles\n",
    "\n",
    "def convert_to_parquet() -> None:\n",
    "    \"\"\"\n",
    "    Convierte el dataset a formato Parquet para acceso m√°s r√°pido.\n",
    "    \"\"\"\n",
    "    parquet_path = DATA_DIR / \"battles_optimized.parquet\"\n",
    "    \n",
    "    if parquet_path.exists():\n",
    "        print(f\"Archivo Parquet ya existe: {parquet_path}\")\n",
    "        return\n",
    "    \n",
    "    print(\"Convirtiendo a formato Parquet...\")\n",
    "    \n",
    "    # Cargar y procesar por chunks\n",
    "    chunk_size = 1000\n",
    "    all_metrics = []\n",
    "    \n",
    "    with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "        battles = json.load(f)\n",
    "    \n",
    "    for i in range(0, len(battles), chunk_size):\n",
    "        chunk = battles[i:i+chunk_size]\n",
    "        chunk_metrics = [calculate_battle_metrics(battle) for battle in chunk]\n",
    "        all_metrics.extend(chunk_metrics)\n",
    "        \n",
    "        if (i + chunk_size) % 5000 == 0:\n",
    "            print(f\"Procesadas {i + chunk_size} batallas...\")\n",
    "    \n",
    "    # Convertir a DataFrame y guardar\n",
    "    df = pd.DataFrame(all_metrics)\n",
    "    df.to_parquet(parquet_path, index=False)\n",
    "    \n",
    "    print(f\"Dataset convertido a Parquet: {parquet_path}\")\n",
    "    print(f\"Tama√±o original JSON: {ALL_BATTLES_JSON.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "    print(f\"Tama√±o Parquet: {parquet_path.stat().st_size / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "def load_battles_optimized(use_sample: bool = True, sample_size: int = 1000) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Carga optimizada de datos con opciones de muestreo.\n",
    "    \n",
    "    Args:\n",
    "        use_sample: Si True, usa una muestra para desarrollo r√°pido\n",
    "        sample_size: Tama√±o de la muestra si use_sample=True\n",
    "    \"\"\"\n",
    "    if use_sample:\n",
    "        print(f\"Modo desarrollo: usando muestra de {sample_size} batallas\")\n",
    "        return create_sample_dataset(sample_size)\n",
    "    else:\n",
    "        print(\"Modo producci√≥n: cargando dataset completo\")\n",
    "        if ALL_BATTLES_JSON.exists():\n",
    "            with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "                return json.load(f)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No existe {ALL_BATTLES_JSON}\")\n",
    "\n",
    "def load_parquet_if_exists() -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Carga el archivo Parquet si existe, para an√°lisis r√°pido.\n",
    "    \"\"\"\n",
    "    parquet_path = DATA_DIR / \"battles_optimized.parquet\"\n",
    "    \n",
    "    if parquet_path.exists():\n",
    "        print(f\"Cargando datos desde Parquet: {parquet_path}\")\n",
    "        return pd.read_parquet(parquet_path)\n",
    "    else:\n",
    "        print(\"Archivo Parquet no encontrado. Usa convert_to_parquet() primero.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582cf9e",
   "metadata": {},
   "source": [
    "## 1. Carga y consolidaci√≥n de datos\n",
    "\n",
    "**Justificaci√≥n de la consolidaci√≥n:**\n",
    "- Los datos vienen en miles de archivos JSON individuales, lo que es ineficiente para an√°lisis\n",
    "- La consolidaci√≥n mejora significativamente la velocidad de carga y procesamiento\n",
    "- Nos permite validar la integridad de los datos y detectar archivos corruptos\n",
    "- Facilita el an√°lisis posterior al tener todos los datos en una estructura unificada\n",
    "- Es un paso fundamental antes de cualquier an√°lisis exploratorio serio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede03e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_battles_data() -> List[dict]:\n",
    "    \"\"\"Carga y consolida todos los datos de batallas.\"\"\"\n",
    "    if ALL_BATTLES_JSON.exists():\n",
    "        with open(ALL_BATTLES_JSON, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    # Si no existe el archivo consolidado, lo creamos\n",
    "    json_files = sorted(BATTLES_DIR.glob(\"*.json\"))\n",
    "    battles_data = []\n",
    "    \n",
    "    print(f\"Consolidando {len(json_files)} archivos JSON...\")\n",
    "    \n",
    "    for i, file in enumerate(json_files):\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                battle = json.load(f)\n",
    "                battles_data.append(battle)\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {file.name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Procesados {i + 1} archivos...\")\n",
    "    \n",
    "    # Guardar archivo consolidado\n",
    "    with open(ALL_BATTLES_JSON, \"w\") as f:\n",
    "        json.dump(battles_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Datos consolidados: {len(battles_data)} batallas\")\n",
    "    return battles_data\n",
    "\n",
    "# Cargar datos\n",
    "battles = load_battles_optimized(use_sample=True, sample_size=2000)  # Modo desarrollo por defecto\n",
    "print(f\"Total de batallas cargadas: {len(battles):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750086b3",
   "metadata": {},
   "source": [
    "### Configuraci√≥n de modo de trabajo\n",
    "\n",
    "**Para cambiar entre modos:**\n",
    "- **Desarrollo r√°pido**: `battles = load_battles_optimized(use_sample=True, sample_size=2000)`\n",
    "- **Dataset completo**: `battles = load_battles_optimized(use_sample=False)`\n",
    "- **Desde Parquet**: `df_battles = load_parquet_if_exists()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0e100",
   "metadata": {},
   "source": [
    "## 2. An√°lisis de calidad de datos\n",
    "\n",
    "**Importancia del an√°lisis de calidad:**\n",
    "- Identificamos problemas de datos antes de invertir tiempo en an√°lisis incorrectos\n",
    "- Validamos que las batallas tengan la estructura esperada (battle_id, metadata, turns)\n",
    "- Detectamos patrones de datos faltantes que podr√≠an sesgar nuestro modelo\n",
    "- Entendemos la distribuci√≥n de formatos de batalla para enfocar el entrenamiento\n",
    "- La calidad de datos determina directamente la calidad del modelo de IA resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed540fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"AN√ÅLISIS DE CALIDAD DE DATOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Estad√≠sticas b√°sicas\n",
    "total_battles = len(battles)\n",
    "print(f\"Total de batallas: {total_battles:,}\")\n",
    "\n",
    "# Validaci√≥n de estructura\n",
    "valid_battles = 0\n",
    "incomplete_battles = 0\n",
    "\n",
    "required_keys = ['battle_id', 'metadata', 'turns']\n",
    "for battle in battles:\n",
    "    if all(key in battle for key in required_keys):\n",
    "        valid_battles += 1\n",
    "    else:\n",
    "        incomplete_battles += 1\n",
    "\n",
    "print(f\"Batallas con estructura completa: {valid_battles:,} ({valid_battles/total_battles*100:.1f}%)\")\n",
    "print(f\"Batallas incompletas: {incomplete_battles:,} ({incomplete_battles/total_battles*100:.1f}%)\")\n",
    "\n",
    "# An√°lisis de formatos\n",
    "formats = Counter(battle.get('format_id') for battle in battles)\n",
    "print(f\"\\nFormatos de batalla encontrados:\")\n",
    "for format_id, count in formats.most_common():\n",
    "    print(f\"  - {format_id}: {count:,} batallas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f059a7",
   "metadata": {},
   "source": [
    "## 1.1 An√°lisis de nulos y duplicados\n",
    "\n",
    "**Importancia del an√°lisis de nulos:**\n",
    "- Detecta problemas de calidad que pueden afectar el entrenamiento\n",
    "- Identifica patrones de datos faltantes\n",
    "- Permite tomar decisiones informadas sobre imputaci√≥n o eliminaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46315bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"AN√ÅLISIS DE NULOS Y DUPLICADOS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# An√°lisis de nulos en DataFrame de batallas\n",
    "if len(df_battles) > 0:\n",
    "    nulls_battles = df_battles.isnull().sum().sort_values(ascending=False)\n",
    "    print(\"\\nNulos en DataFrame de batallas:\")\n",
    "    for col, null_count in nulls_battles.items():\n",
    "        if null_count > 0:\n",
    "            print(f\"  - {col}: {null_count:,} ({null_count/len(df_battles)*100:.1f}%)\")\n",
    "    \n",
    "    # Duplicados\n",
    "    dupes_battles = df_battles.duplicated().sum()\n",
    "    print(f\"\\nDuplicados exactos en batallas: {dupes_battles:,}\")\n",
    "    \n",
    "    # Duplicados por battle_id\n",
    "    dupes_by_id = df_battles['battle_id'].duplicated().sum()\n",
    "    print(f\"Batallas con battle_id duplicado: {dupes_by_id:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe51d81",
   "metadata": {},
   "source": [
    "## 1.2 Auditor√≠a de tipos y cardinalidad\n",
    "\n",
    "**Prop√≥sito de la auditor√≠a:**\n",
    "- Identifica columnas con alta/baja cardinalidad\n",
    "- Detecta posibles errores de tipo de datos\n",
    "- Ayuda a identificar variables categ√≥ricas vs num√©ricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20045de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"AUDITOR√çA DE TIPOS Y CARDINALIDAD\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(df_battles) > 0:\n",
    "    audit_battles = (df_battles.dtypes.to_frame('dtype')\n",
    "                    .assign(cardinalidad=df_battles.nunique(),\n",
    "                           nulos=df_battles.isnull().sum(),\n",
    "                           pct_nulos=(df_battles.isnull().sum()/len(df_battles)*100).round(2))\n",
    "                    .sort_values('cardinalidad', ascending=False))\n",
    "    \n",
    "    print(\"\\nAuditor√≠a DataFrame batallas:\")\n",
    "    print(audit_battles)\n",
    "    \n",
    "    # Guardar auditor√≠a\n",
    "    audit_path = OUTPUT_DIR / 'data_audit_battles.csv'\n",
    "    audit_battles.to_csv(audit_path)\n",
    "    print(f\"\\nAuditor√≠a guardada: {audit_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282aae0c",
   "metadata": {},
   "source": [
    "## 2. An√°lisis de resultados de batalla\n",
    "\n",
    "**Relevancia del an√°lisis de resultados:**\n",
    "- Verificamos si hay balance entre jugadores (p1 vs p2) para evitar sesgos en el entrenamiento\n",
    "- Las razones de finalizaci√≥n nos indican qu√© estrategias son m√°s efectivas\n",
    "- La duraci√≥n de batallas revela patrones de juego defensivo vs agresivo\n",
    "- Estos patrones son fundamentales para que la IA aprenda estrategias ganadoras\n",
    "- Un dataset balanceado asegura que el modelo no favorezca injustamente a un jugador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c5b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AN√ÅLISIS DE RESULTADOS DE BATALLA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extraer m√©tricas de batalla\n",
    "battle_metrics = [calculate_battle_metrics(battle) for battle in battles]\n",
    "df_battles = pd.DataFrame(battle_metrics)\n",
    "\n",
    "# An√°lisis de ganadores\n",
    "winner_counts = df_battles['winner'].value_counts()\n",
    "print(f\"Distribuci√≥n de ganadores:\")\n",
    "for winner, count in winner_counts.items():\n",
    "    print(f\"  - {winner}: {count:,} ({count/len(df_battles)*100:.1f}%)\")\n",
    "\n",
    "# Razones de victoria\n",
    "reason_counts = df_battles['reason'].value_counts()\n",
    "print(f\"\\nRazones de finalizaci√≥n:\")\n",
    "for reason, count in reason_counts.items():\n",
    "    print(f\"  - {reason}: {count:,} ({count/len(df_battles)*100:.1f}%)\")\n",
    "\n",
    "# Estad√≠sticas de duraci√≥n\n",
    "print(f\"\\nEstad√≠sticas de duraci√≥n de batalla:\")\n",
    "print(f\"  - Turnos promedio: {df_battles['total_turns'].mean():.1f}\")\n",
    "print(f\"  - Turnos mediana: {df_battles['total_turns'].median():.1f}\")\n",
    "print(f\"  - Turnos min/max: {df_battles['total_turns'].min()}/{df_battles['total_turns'].max()}\")\n",
    "\n",
    "# An√°lisis de balance de clases\n",
    "print(f\"\\nBalance de clases (winner):\")\n",
    "balance = df_battles['winner'].value_counts(normalize=True).mul(100).round(2)\n",
    "for winner, pct in balance.items():\n",
    "    print(f\"  - {winner}: {pct}%\")\n",
    "\n",
    "# Mostrar primeras filas del DataFrame\n",
    "print(f\"\\nPrimeras 5 batallas procesadas:\")\n",
    "print(df_battles[['battle_id', 'total_turns', 'winner', 'reason', 'move_events', 'switch_events']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c389b",
   "metadata": {},
   "source": [
    "## 3. An√°lisis de patrones de batalla\n",
    "\n",
    "**Valor del an√°lisis de patrones:**\n",
    "- Los eventos por batalla (movimientos, switches, da√±o) son las acciones que debe aprender la IA\n",
    "- La correlaci√≥n turnos-eventos nos indica la intensidad estrat√©gica de las batallas\n",
    "- Los patrones por ganador revelan qu√© comportamientos llevan al √©xito\n",
    "- El ratio movimientos/switches indica agresividad vs cautela en las estrategias\n",
    "- Estos insights guiar√°n el dise√±o de la funci√≥n de recompensa del modelo de IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AN√ÅLISIS DE PATRONES DE BATALLA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# An√°lisis de eventos por batalla\n",
    "print(f\"Eventos por batalla:\")\n",
    "print(f\"  - Eventos totales promedio: {df_battles['total_events'].mean():.1f}\")\n",
    "print(f\"  - Movimientos promedio: {df_battles['move_events'].mean():.1f}\")\n",
    "print(f\"  - Switches promedio: {df_battles['switch_events'].mean():.1f}\")\n",
    "print(f\"  - Eventos de da√±o promedio: {df_battles['damage_events'].mean():.1f}\")\n",
    "\n",
    "# Relaci√≥n entre duraci√≥n y eventos\n",
    "correlation = df_battles['total_turns'].corr(df_battles['total_events'])\n",
    "print(f\"\\nCorrelaci√≥n turnos-eventos: {correlation:.3f}\")\n",
    "\n",
    "# An√°lisis por ganador\n",
    "print(f\"\\nPatrones por ganador:\")\n",
    "for winner in ['p1', 'p2']:\n",
    "    winner_data = df_battles[df_battles['winner'] == winner]\n",
    "    if len(winner_data) > 0:\n",
    "        print(f\"  {winner}:\")\n",
    "        print(f\"    - Turnos promedio: {winner_data['total_turns'].mean():.1f}\")\n",
    "        print(f\"    - Eventos promedio: {winner_data['total_events'].mean():.1f}\")\n",
    "        print(f\"    - Ratio movimientos/switches: {winner_data['move_events'].mean() / max(winner_data['switch_events'].mean(), 1):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c41d287",
   "metadata": {},
   "source": [
    "## 3.1 An√°lisis de distribuciones y outliers\n",
    "\n",
    "**Importancia del an√°lisis de distribuciones:**\n",
    "- Identifica outliers que pueden sesgar el modelo\n",
    "- Revela la forma de las distribuciones para seleccionar algoritmos apropiados\n",
    "- Detecta patrones an√≥malos en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"AN√ÅLISIS DE DISTRIBUCIONES Y OUTLIERS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# An√°lisis de distribuciones para variables num√©ricas clave\n",
    "num_cols = ['total_turns', 'total_events', 'move_events', 'switch_events', 'events_per_turn']\n",
    "\n",
    "if len(df_battles) > 0:\n",
    "    # Histogramas de distribuciones\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Distribuciones de Variables Num√©ricas Clave', fontsize=16)\n",
    "    \n",
    "    for i, col in enumerate(num_cols):\n",
    "        row, col_idx = divmod(i, 3)\n",
    "        if col in df_battles.columns:\n",
    "            axes[row, col_idx].hist(df_battles[col].dropna(), bins=30, alpha=0.7, edgecolor='black')\n",
    "            axes[row, col_idx].set_title(f'Distribuci√≥n: {col}')\n",
    "            axes[row, col_idx].set_xlabel(col)\n",
    "            axes[row, col_idx].set_ylabel('Frecuencia')\n",
    "            \n",
    "            # A√±adir l√≠neas de media y mediana\n",
    "            mean_val = df_battles[col].mean()\n",
    "            median_val = df_battles[col].median()\n",
    "            axes[row, col_idx].axvline(mean_val, color='red', linestyle='--', alpha=0.7, label=f'Media: {mean_val:.1f}')\n",
    "            axes[row, col_idx].axvline(median_val, color='green', linestyle='--', alpha=0.7, label=f'Mediana: {median_val:.1f}')\n",
    "            axes[row, col_idx].legend()\n",
    "    \n",
    "    # Eliminar subplot vac√≠o\n",
    "    if len(num_cols) < 6:\n",
    "        fig.delaxes(axes[1, 2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'distributions_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Distribuciones guardadas: {OUTPUT_DIR / 'distributions_analysis.png'}\")\n",
    "    \n",
    "    # An√°lisis de outliers usando IQR\n",
    "    print(f\"\\nDetecci√≥n de outliers (m√©todo IQR):\")\n",
    "    for col in num_cols:\n",
    "        if col in df_battles.columns:\n",
    "            Q1 = df_battles[col].quantile(0.25)\n",
    "            Q3 = df_battles[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = df_battles[(df_battles[col] < lower_bound) | (df_battles[col] > upper_bound)]\n",
    "            pct_outliers = len(outliers) / len(df_battles) * 100\n",
    "            \n",
    "            print(f\"  - {col}: {len(outliers)} outliers ({pct_outliers:.1f}%)\")\n",
    "    \n",
    "    # Boxplots por ganador\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    fig.suptitle('Boxplots por Ganador', fontsize=16)\n",
    "    \n",
    "    key_vars = ['total_turns', 'move_events', 'switch_events']\n",
    "    for i, var in enumerate(key_vars):\n",
    "        if var in df_battles.columns:\n",
    "            sns.boxplot(data=df_battles, x='winner', y=var, ax=axes[i])\n",
    "            axes[i].set_title(f'{var} por Ganador')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'boxplots_by_winner.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Boxplots guardados: {OUTPUT_DIR / 'boxplots_by_winner.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa670e4",
   "metadata": {},
   "source": [
    "## 4. An√°lisis de uso de Pokemon\n",
    "\n",
    "**Importancia del an√°lisis de Pokemon:**\n",
    "- Identificamos el 'meta' actual: qu√© Pokemon son m√°s populares y por qu√©\n",
    "- Los niveles y HP nos dan informaci√≥n sobre el balance del juego\n",
    "- La frecuencia de uso indica qu√© Pokemon debe priorizar la IA en sus decisiones\n",
    "- Esta informaci√≥n es crucial para que la IA entienda amenazas y oportunidades\n",
    "- Los Pokemon m√°s utilizados probablemente tienen estrategias m√°s desarrolladas en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2effff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"AN√ÅLISIS DE USO DE POKEMON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Extraer informaci√≥n de Pokemon\n",
    "all_pokemon = []\n",
    "for battle in battles:\n",
    "    pokemon_info = extract_pokemon_info(battle)\n",
    "    for pokemon in pokemon_info:\n",
    "        pokemon['winner'] = get_in(battle, ['metadata', 'outcome', 'winner'])\n",
    "        all_pokemon.append(pokemon)\n",
    "\n",
    "df_pokemon = pd.DataFrame(all_pokemon)\n",
    "\n",
    "if len(df_pokemon) > 0:\n",
    "    # Pokemon m√°s utilizados\n",
    "    species_counts = df_pokemon['species'].value_counts()\n",
    "    print(f\"Top 10 Pokemon m√°s utilizados:\")\n",
    "    for i, (species, count) in enumerate(species_counts.head(10).items(), 1):\n",
    "        print(f\"  {i:2d}. {species}: {count:,} usos\")\n",
    "    \n",
    "    # An√°lisis de niveles\n",
    "    print(f\"\\nDistribuci√≥n de niveles:\")\n",
    "    print(f\"  - Nivel promedio: {df_pokemon['level'].mean():.1f}\")\n",
    "    print(f\"  - Nivel mediana: {df_pokemon['level'].median():.1f}\")\n",
    "    print(f\"  - Rango de niveles: {df_pokemon['level'].min()}-{df_pokemon['level'].max()}\")\n",
    "    \n",
    "    # An√°lisis de HP\n",
    "    hp_data = df_pokemon.dropna(subset=['hp'])\n",
    "    if len(hp_data) > 0:\n",
    "        print(f\"\\nEstad√≠sticas de HP:\")\n",
    "        print(f\"  - HP promedio: {hp_data['hp'].mean():.1f}\")\n",
    "        print(f\"  - HP mediana: {hp_data['hp'].median():.1f}\")\n",
    "        print(f\"  - Rango HP: {hp_data['hp'].min()}-{hp_data['hp'].max()}\")\n",
    "\n",
    "print(f\"\\nDataFrame de Pokemon - Shape: {df_pokemon.shape}\")\n",
    "if len(df_pokemon) > 0:\n",
    "    print(df_pokemon.head())\n",
    "    \n",
    "    # An√°lisis de nulos en Pokemon\n",
    "    nulls_pokemon = df_pokemon.isnull().sum().sort_values(ascending=False)\n",
    "    print(f\"\\nNulos en DataFrame de Pokemon:\")\n",
    "    for col, null_count in nulls_pokemon.items():\n",
    "        if null_count > 0:\n",
    "            print(f\"  - {col}: {null_count:,} ({null_count/len(df_pokemon)*100:.1f}%)\")\n",
    "else:\n",
    "    print(\"No se encontraron datos de Pokemon para analizar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0b0c7",
   "metadata": {},
   "source": [
    "## 5. Visualizaciones clave para entrenamiento de IA\n",
    "\n",
    "**Visualizaciones seleccionadas:**\n",
    "- **Distribuci√≥n de duraci√≥n**: Muestra la variabilidad de estrategias (r√°pidas vs largas)\n",
    "- **Eventos vs turnos**: Revela la intensidad de acci√≥n, clave para modelar decisiones\n",
    "- **Patrones por ganador**: Identifica comportamientos exitosos que la IA debe imitar\n",
    "- **Razones de finalizaci√≥n**: Ense√±a a la IA los diferentes caminos hacia la victoria\n",
    "- Estas gr√°ficas nos ayudan a validar hip√≥tesis y comunicar insights del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8579a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('An√°lisis de Patrones de Batalla Pokemon', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Distribuci√≥n de duraci√≥n de batallas\n",
    "axes[0, 0].hist(df_battles['total_turns'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribuci√≥n de Duraci√≥n de Batallas')\n",
    "axes[0, 0].set_xlabel('N√∫mero de Turnos')\n",
    "axes[0, 0].set_ylabel('Frecuencia')\n",
    "axes[0, 0].axvline(df_battles['total_turns'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Media: {df_battles[\"total_turns\"].mean():.1f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Eventos por turno\n",
    "axes[0, 1].scatter(df_battles['total_turns'], df_battles['events_per_turn'], \n",
    "                   alpha=0.6, color='green')\n",
    "axes[0, 1].set_title('Eventos por Turno vs Duraci√≥n')\n",
    "axes[0, 1].set_xlabel('N√∫mero de Turnos')\n",
    "axes[0, 1].set_ylabel('Eventos por Turno')\n",
    "\n",
    "# 3. Comparaci√≥n de patrones por ganador\n",
    "winner_data = df_battles.groupby('winner').agg({\n",
    "    'total_turns': 'mean',\n",
    "    'move_events': 'mean',\n",
    "    'switch_events': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "x = range(len(winner_data))\n",
    "width = 0.25\n",
    "axes[1, 0].bar([i - width for i in x], winner_data['total_turns'], width, \n",
    "               label='Turnos Promedio', alpha=0.8)\n",
    "axes[1, 0].bar(x, winner_data['move_events'], width, \n",
    "               label='Movimientos Promedio', alpha=0.8)\n",
    "axes[1, 0].bar([i + width for i in x], winner_data['switch_events'], width, \n",
    "               label='Switches Promedio', alpha=0.8)\n",
    "axes[1, 0].set_title('Patrones por Ganador')\n",
    "axes[1, 0].set_xlabel('Ganador')\n",
    "axes[1, 0].set_ylabel('Cantidad')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels(winner_data['winner'])\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. Raz√≥n de finalizaci√≥n\n",
    "reason_counts = df_battles['reason'].value_counts()\n",
    "axes[1, 1].pie(reason_counts.values, labels=reason_counts.index, autopct='%1.1f%%')\n",
    "axes[1, 1].set_title('Razones de Finalizaci√≥n')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'battle_patterns_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Visualizaci√≥n guardada: {OUTPUT_DIR / 'battle_patterns_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a800ef",
   "metadata": {},
   "source": [
    "## 6. An√°lisis visual de Pokemon\n",
    "\n",
    "**Enfoque del an√°lisis visual:**\n",
    "- **Top Pokemon**: La IA debe conocer las amenazas m√°s comunes del meta\n",
    "- **Distribuci√≥n de niveles**: Entiende el rango de poder esperado en batallas\n",
    "- **HP vs Nivel**: Revela la relaci√≥n entre estad√≠sticas, crucial para c√°lculos de da√±o\n",
    "- **Distribuci√≥n por g√©nero**: Algunos movimientos y habilidades dependen del g√©nero\n",
    "- Estas visualizaciones informan las decisiones de selecci√≥n de equipo de la IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8939aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_pokemon) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('An√°lisis de Pokemon en Batallas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Top Pokemon m√°s utilizados\n",
    "    top_pokemon = df_pokemon['species'].value_counts().head(15)\n",
    "    axes[0, 0].barh(range(len(top_pokemon)), top_pokemon.values)\n",
    "    axes[0, 0].set_yticks(range(len(top_pokemon)))\n",
    "    axes[0, 0].set_yticklabels(top_pokemon.index)\n",
    "    axes[0, 0].set_title('Top 15 Pokemon M√°s Utilizados')\n",
    "    axes[0, 0].set_xlabel('N√∫mero de Usos')\n",
    "    \n",
    "    # 2. Distribuci√≥n de niveles\n",
    "    axes[0, 1].hist(df_pokemon['level'].dropna(), bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[0, 1].set_title('Distribuci√≥n de Niveles de Pokemon')\n",
    "    axes[0, 1].set_xlabel('Nivel')\n",
    "    axes[0, 1].set_ylabel('Frecuencia')\n",
    "    \n",
    "    # 3. HP vs Nivel\n",
    "    hp_level_data = df_pokemon.dropna(subset=['hp', 'level'])\n",
    "    if len(hp_level_data) > 0:\n",
    "        axes[1, 0].scatter(hp_level_data['level'], hp_level_data['hp'], alpha=0.6, color='purple')\n",
    "        axes[1, 0].set_title('HP vs Nivel de Pokemon')\n",
    "        axes[1, 0].set_xlabel('Nivel')\n",
    "        axes[1, 0].set_ylabel('HP')\n",
    "    \n",
    "    # 4. Distribuci√≥n por g√©nero\n",
    "    gender_counts = df_pokemon['gender'].value_counts()\n",
    "    axes[1, 1].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%')\n",
    "    axes[1, 1].set_title('Distribuci√≥n por G√©nero')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'pokemon_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Visualizaci√≥n guardada: {OUTPUT_DIR / 'pokemon_analysis.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32b256",
   "metadata": {},
   "source": [
    "## 7. Extracci√≥n de features para entrenamiento de IA\n",
    "\n",
    "**Features seleccionados:**\n",
    "- **M√©tricas de batalla**: Duraci√≥n, eventos, ratios - capturan el 'estilo' de juego\n",
    "- **Ratings de jugadores**: Proxy del nivel de habilidad, importante para el aprendizaje\n",
    "- **Informaci√≥n de equipos**: Tama√±o, niveles promedio - contexto estrat√©gico\n",
    "- **Patrones temporales**: Eventos por turno - ritmo de juego que debe aprender la IA\n",
    "- Estos features formar√°n el input del modelo de machine learning para toma de decisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACCI√ìN DE FEATURES PARA IA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Features avanzadas a nivel de batalla para IA\n",
    "battle_features = []\n",
    "\n",
    "print(\"Extrayendo features avanzadas para entrenamiento de IA...\")\n",
    "for i, battle in enumerate(battles):\n",
    "    if (i + 1) % 500 == 0:\n",
    "        print(f\"Procesadas {i + 1} batallas...\")\n",
    "    \n",
    "    # M√©tricas b√°sicas mejoradas\n",
    "    metrics = calculate_battle_metrics(battle)\n",
    "    \n",
    "    # Features de composici√≥n de equipos\n",
    "    team_features = extract_team_composition_features(battle)\n",
    "    \n",
    "    # Combinar todas las features\n",
    "    features = {\n",
    "        'battle_id': battle.get('battle_id'),\n",
    "        'total_turns': metrics['total_turns'],\n",
    "        'winner': metrics['winner'],\n",
    "        'reason': metrics['reason'],\n",
    "        'move_events': metrics['move_events'],\n",
    "        'switch_events': metrics['switch_events'],\n",
    "        'damage_events': metrics['damage_events'],\n",
    "        'effect_events': metrics['effect_events'],\n",
    "        'heal_events': metrics['heal_events'],\n",
    "        'status_events': metrics['status_events'],\n",
    "        'events_per_turn': metrics['events_per_turn'],\n",
    "        'early_game_intensity': metrics['early_game_intensity'],\n",
    "        'mid_game_intensity': metrics['mid_game_intensity'],\n",
    "        'late_game_intensity': metrics['late_game_intensity'],\n",
    "        'move_switch_ratio': metrics['move_switch_ratio'],\n",
    "        'consecutive_moves': metrics['consecutive_moves'],\n",
    "        'consecutive_switches': metrics['consecutive_switches'],\n",
    "        'action_diversity': metrics['action_diversity']\n",
    "    }\n",
    "    \n",
    "    # Informaci√≥n de jugadores\n",
    "    players = battle.get('players', {})\n",
    "    for player_id in ['p1', 'p2']:\n",
    "        player_info = players.get(player_id, {})\n",
    "        features[f'{player_id}_rating'] = player_info.get('ladder_rating_pre', 0)\n",
    "    \n",
    "    # Agregar features de composici√≥n de equipos\n",
    "    features.update(team_features)\n",
    "    \n",
    "    # Features de ventaja competitiva\n",
    "    if features['p1_rating'] and features['p2_rating']:\n",
    "        features['rating_difference'] = abs(features['p1_rating'] - features['p2_rating'])\n",
    "        features['rating_advantage_p1'] = features['p1_rating'] - features['p2_rating']\n",
    "    else:\n",
    "        features['rating_difference'] = 0\n",
    "        features['rating_advantage_p1'] = 0\n",
    "    \n",
    "    # Features de balance de equipos\n",
    "    features['team_size_difference'] = abs(features['p1_team_size'] - features['p2_team_size'])\n",
    "    features['level_advantage_p1'] = features['p1_avg_level'] - features['p2_avg_level']\n",
    "    features['hp_advantage_p1'] = features['p1_total_hp'] - features['p2_total_hp']\n",
    "    features['info_advantage_p1'] = features['p1_info_advantage'] - features['p2_info_advantage']\n",
    "    \n",
    "    battle_features.append(features)\n",
    "\n",
    "df_features = pd.DataFrame(battle_features)\n",
    "\n",
    "# Guardar features\n",
    "features_path = OUTPUT_DIR / 'battle_features.csv'\n",
    "df_features.to_csv(features_path, index=False)\n",
    "\n",
    "print(f\"Features extra√≠das: {len(df_features.columns)} columnas\")\n",
    "print(f\"Batallas procesadas: {len(df_features)} registros\")\n",
    "print(f\"Features guardadas en: {features_path}\")\n",
    "\n",
    "# Mostrar correlaciones importantes\n",
    "numeric_cols = df_features.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_cols) > 1:\n",
    "    correlations = df_features[numeric_cols].corr()\n",
    "    print(f\"\\nCorrelaciones m√°s altas con 'total_turns':\")\n",
    "    turn_corr = correlations['total_turns'].abs().sort_values(ascending=False)\n",
    "    for feature, corr in turn_corr.head(5).items():\n",
    "        if feature != 'total_turns':\n",
    "            print(f\"  - {feature}: {corr:.3f}\")\n",
    "\n",
    "print(f\"\\nPrimeras 5 filas del dataset de features:\")\n",
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f133f6",
   "metadata": {},
   "source": [
    "## 7.1 Validaci√≥n r√°pida con modelo baseline\n",
    "\n",
    "**Prop√≥sito del modelo baseline:**\n",
    "- Establece una l√≠nea base de rendimiento para comparar modelos futuros\n",
    "- Valida que las features tienen poder predictivo\n",
    "- Identifica las variables m√°s importantes\n",
    "- Detecta posibles problemas de data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"VALIDACI√ìN CON MODELO BASELINE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Preparar datos para modelo baseline\n",
    "try:\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import roc_auc_score, classification_report\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    # Seleccionar features num√©ricas para el baseline\n",
    "    numeric_features = df_features.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remover variables que no deben usarse para predicci√≥n\n",
    "    exclude_cols = ['battle_id'] if 'battle_id' in numeric_features else []\n",
    "    feature_cols = [col for col in numeric_features if col not in exclude_cols]\n",
    "    \n",
    "    # Preparar target\n",
    "    if 'winner' in df_features.columns:\n",
    "        # Filtrar solo batallas con ganador definido\n",
    "        valid_battles = df_features[df_features['winner'].isin(['p1', 'p2'])].copy()\n",
    "        \n",
    "        if len(valid_battles) > 10 and len(feature_cols) > 0:  # M√≠nimo para entrenar\n",
    "            X = valid_battles[feature_cols].fillna(0)  # Imputar nulos con 0\n",
    "            y = valid_battles['winner']\n",
    "            \n",
    "            # Codificar target\n",
    "            le = LabelEncoder()\n",
    "            y_encoded = le.fit_transform(y)\n",
    "            \n",
    "            # Split train/test\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Entrenar modelo baseline\n",
    "            clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluar\n",
    "            y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "            auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            print(f\"Modelo baseline entrenado:\")\n",
    "            print(f\"  - Features utilizadas: {len(feature_cols)}\")\n",
    "            print(f\"  - Tama√±o entrenamiento: {len(X_train):,}\")\n",
    "            print(f\"  - Tama√±o test: {len(X_test):,}\")\n",
    "            print(f\"  - ROC-AUC: {auc_score:.3f}\")\n",
    "            \n",
    "            # Importancia de features\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': feature_cols,\n",
    "                'importance': np.abs(clf.coef_[0])\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            \n",
    "            print(f\"\\nTop 10 features m√°s importantes:\")\n",
    "            for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):\n",
    "                print(f\"  {i:2d}. {row['feature']}: {row['importance']:.3f}\")\n",
    "            \n",
    "            # Guardar importancia de features\n",
    "            importance_path = OUTPUT_DIR / 'feature_importance_baseline.csv'\n",
    "            feature_importance.to_csv(importance_path, index=False)\n",
    "            print(f\"\\nImportancia guardada: {importance_path}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Datos insuficientes para entrenar modelo baseline\")\n",
    "    else:\n",
    "        print(\"Variable 'winner' no encontrada para modelo baseline\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Scikit-learn no disponible. Instalar con: pip install scikit-learn\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en modelo baseline: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93238e61",
   "metadata": {},
   "source": [
    "## 8. Matriz de correlaci√≥n de features num√©ricas\n",
    "\n",
    "**Prop√≥sito del an√°lisis de correlaciones:**\n",
    "- Identificamos features redundantes que pueden confundir al modelo\n",
    "- Detectamos relaciones no obvias entre variables que pueden ser √∫tiles\n",
    "- Ayuda a seleccionar las features m√°s informativas para el entrenamiento\n",
    "- Previene problemas de multicolinealidad en modelos lineales\n",
    "- Gu√≠a la ingenier√≠a de features y la selecci√≥n de variables para el modelo final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear matriz de correlaci√≥n para features num√©ricas\n",
    "numeric_features = df_features.select_dtypes(include=[np.number])\n",
    "\n",
    "if len(numeric_features.columns) > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = numeric_features.corr()\n",
    "    \n",
    "    # Crear heatmap\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, fmt='.2f')\n",
    "    plt.title('Matriz de Correlaci√≥n - Features Num√©ricas')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Matriz de correlaci√≥n guardada: {OUTPUT_DIR / 'correlation_matrix.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a3d5a",
   "metadata": {},
   "source": [
    "---\n",
    "# Ep√≠logo: El camino hacia la maestr√≠a\n",
    "\n",
    "**Nuestra investigaci√≥n llega a su fin, pero el verdadero viaje apenas comienza.**\n",
    "\n",
    "Hemos desentra√±ado los secretos de miles de batallas Pokemon, identificado a los campeones del meta, descubierto patrones temporales, y destilado todo este conocimiento en caracter√≠sticas que una IA puede aprender. \n",
    "\n",
    "## 9. Resumen ejecutivo para entrenamiento de IA\n",
    "\n",
    "**Los hallazgos de nuestra expedici√≥n:**\n",
    "\n",
    "Como exploradores que regresan de una tierra desconocida, traemos mapas, tesoros y sabidur√≠a. Estos son los insights que guiar√°n la creaci√≥n de nuestra IA Pokemon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46ab20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESUMEN EJECUTIVO PARA ENTRENAMIENTO DE IA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"## La Sabidur√≠a Extra√≠da de Nuestro Viaje:\n",
    "\n",
    "### 1. La Confiabilidad de Nuestros Datos:\n",
    "   - Hemos analizado {len(battles):,} batallas reales y verificadas\n",
    "   - Formato gen9randombattle: el est√°ndar competitivo actual\n",
    "   - Cada batalla cuenta una historia completa con {len(df_features.columns)} caracter√≠sticas extra√≠das\n",
    "\n",
    "### 2. Los Secretos de las Batallas Exitosas:\n",
    "   - Las batallas competitivas duran en promedio {df_battles['total_turns'].mean():.1f} turnos\n",
    "   - El momentum cambia seg√∫n la fase: early-game vs late-game tienen din√°micas diferentes\n",
    "   - Los patrones de switching y timing son m√°s predictivos que las estad√≠sticas brutas\n",
    "\n",
    "### 3. El Arsenal Avanzado de Conocimiento para Nuestra IA:\n",
    "   - **Features Temporales**: Intensidad por fase de batalla (early/mid/late game)\n",
    "   - **Patrones de Decisi√≥n**: Ratios move/switch, acciones consecutivas, diversidad de acciones\n",
    "   - **Composici√≥n de Equipos**: Diversidad de especies, distribuci√≥n de niveles, ventajas de HP\n",
    "   - **Informaci√≥n Estrat√©gica**: Habilidades conocidas, items revelados, movimientos descubiertos\n",
    "   - **Ventajas Competitivas**: Diferencias de rating, balance de equipos, ventajas de informaci√≥n\n",
    "\n",
    "### 4. La Estrategia de Entrenamiento Revolucionaria:\n",
    "   - **Aprendizaje por Fases**: La IA debe adaptar estrategias seg√∫n early/mid/late game\n",
    "   - **Momentum Awareness**: Detectar cambios en intensidad y patrones de acci√≥n\n",
    "   - **Information Advantage**: Usar conocimiento parcial del oponente estrat√©gicamente\n",
    "   - **Team Synergy**: Entender composiciones de equipo y sus fortalezas/debilidades\n",
    "   - **Adaptive Decision Making**: Cambiar entre agresi√≥n y conservaci√≥n seg√∫n el contexto\n",
    "\n",
    "### 5. El Mapa Definitivo hacia la Maestr√≠a:\n",
    "   - **Arquitectura H√≠brida**: CNN para patrones + LSTM para secuencias temporales + Attention para decisiones cr√≠ticas\n",
    "   - **Multi-Task Learning**: Predecir pr√≥ximo movimiento + resultado de batalla + timing √≥ptimo\n",
    "   - **Curriculum Learning**: Entrenar primero en batallas simples, luego en escenarios complejos\n",
    "   - **Adversarial Training**: IA vs IA para desarrollar estrategias anti-meta\n",
    "   - **Continual Learning**: Adaptaci√≥n autom√°tica a cambios en el meta competitivo\n",
    "   - **Explainable AI**: Sistema de explicaci√≥n de decisiones para an√°lisis estrat√©gico\n",
    "\n",
    "### 6. Features Cr√≠ticas Implementadas (NUEVO):\n",
    "   - **{len([c for c in df_features.columns if 'intensity' in c])} m√©tricas de intensidad** por fase de batalla\n",
    "   - **{len([c for c in df_features.columns if 'advantage' in c])} indicadores de ventaja** estrat√©gica\n",
    "   - **{len([c for c in df_features.columns if 'diversity' in c or 'ratio' in c])} m√©tricas de diversidad** y patrones\n",
    "   - **Informaci√≥n de revelaci√≥n progresiva** para decisiones bajo incertidumbre\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786833de",
   "metadata": {},
   "source": [
    "## 10. Estad√≠sticas finales y archivos generados\n",
    "\n",
    "**Importancia de la documentaci√≥n:**\n",
    "- Proporciona un inventario completo de los artefactos generados\n",
    "- Facilita la reproducibilidad del an√°lisis\n",
    "- Permite validar que todos los pasos se ejecutaron correctamente\n",
    "- Sirve como checklist para asegurar que no falta ning√∫n componente\n",
    "- Documenta el punto de partida para la siguiente fase del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"NUESTRA EXPEDICI√ìN HA CONCLUIDO\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(\"\\n** El conocimiento ha sido extra√≠do, los patrones revelados. **\")\n",
    "print(\"** Nuestra IA ahora tiene el mapa para convertirse en maestra Pokemon. **\")\n",
    "\n",
    "print(f\"\\nArchivos generados en: {OUTPUT_DIR.resolve()}\")\n",
    "output_files = list(OUTPUT_DIR.glob(\"*\"))\n",
    "for file in output_files:\n",
    "    print(f\"  - {file.name}\")\n",
    "\n",
    "print(f\"\\nTesoros de conocimiento recolectados:\")\n",
    "print(f\"  - Historias de batalla analizadas: {len(df_battles)} registros\")\n",
    "print(f\"  - Protagonistas Pokemon catalogados: {len(df_pokemon)} registros\")\n",
    "print(f\"  - Caracter√≠sticas estrat√©gicas extra√≠das: {len(df_features)} registros\")\n",
    "print(f\"  - Features avanzadas implementadas: {len(df_features.columns)} dimensiones\")\n",
    "print(f\"  - M√©tricas de momentum y timing: Implementadas\")\n",
    "print(f\"  - An√°lisis de composici√≥n de equipos: Completo\")\n",
    "print(f\"  - Sistema de ventajas competitivas: Operativo\")\n",
    "print(f\"\\n** La IA ahora tiene acceso a patrones temporales, momentum de batalla,\")\n",
    "print(f\"   composici√≥n de equipos y ventajas estrat√©gicas - todo lo necesario\")\n",
    "print(f\"   para decisiones de nivel maestro Pokemon. **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32049b42",
   "metadata": {},
   "source": [
    "---\n",
    "# Cap√≠tulo 5: ¬øCu√°ndo ocurren las batallas?\n",
    "\n",
    "**El tiempo revela secretos que las estad√≠sticas b√°sicas no pueden mostrar.**\n",
    "\n",
    "¬øHay momentos del d√≠a donde los entrenadores m√°s h√°biles est√°n activos? ¬øCambian las estrategias con el tiempo? ¬øEvoluciona el meta de formas que nuestra IA debe anticipar?\n",
    "\n",
    "## 11. An√°lisis temporal de batallas\n",
    "\n",
    "**Explorando los ritmos del combate:**\n",
    "- ¬øCu√°ndo luchan los entrenadores m√°s dedicados?\n",
    "- ¬øHay patrones estacionales en las estrategias Pokemon?\n",
    "- ¬øC√≥mo evoluciona el meta a trav√©s del tiempo?\n",
    "- ¬øDebe nuestra IA adaptarse a diferentes \"√©pocas\" del juego?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"AN√ÅLISIS TEMPORAL DE BATALLAS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(df_battles) > 0 and 'timestamp' in df_battles.columns:\n",
    "    # Convertir timestamp a datetime\n",
    "    df_battles['datetime'] = pd.to_datetime(df_battles['timestamp'], unit='s', errors='coerce')\n",
    "    \n",
    "    if df_battles['datetime'].notna().sum() > 0:\n",
    "        # An√°lisis por d√≠a de la semana\n",
    "        df_battles['day_of_week'] = df_battles['datetime'].dt.day_name()\n",
    "        battles_by_day = df_battles['day_of_week'].value_counts()\n",
    "        \n",
    "        print(\"Distribuci√≥n de batallas por d√≠a de la semana:\")\n",
    "        for day, count in battles_by_day.items():\n",
    "            print(f\"  - {day}: {count:,} batallas\")\n",
    "        \n",
    "        # An√°lisis por hora del d√≠a\n",
    "        df_battles['hour'] = df_battles['datetime'].dt.hour\n",
    "        battles_by_hour = df_battles['hour'].value_counts().sort_index()\n",
    "        \n",
    "        print(f\"\\nHoras pico de actividad:\")\n",
    "        top_hours = battles_by_hour.head(3)\n",
    "        for hour, count in top_hours.items():\n",
    "            print(f\"  - {hour:02d}:00: {count:,} batallas\")\n",
    "        \n",
    "        # Evoluci√≥n temporal de duraci√≥n promedio\n",
    "        df_battles['date'] = df_battles['datetime'].dt.date\n",
    "        daily_avg_turns = df_battles.groupby('date')['total_turns'].mean()\n",
    "        \n",
    "        if len(daily_avg_turns) > 1:\n",
    "            trend = \"creciente\" if daily_avg_turns.iloc[-1] > daily_avg_turns.iloc[0] else \"decreciente\"\n",
    "            print(f\"\\nTendencia en duraci√≥n de batallas: {trend}\")\n",
    "            print(f\"  - Primer d√≠a: {daily_avg_turns.iloc[0]:.1f} turnos promedio\")\n",
    "            print(f\"  - √öltimo d√≠a: {daily_avg_turns.iloc[-1]:.1f} turnos promedio\")\n",
    "        \n",
    "        # Visualizaci√≥n temporal\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Batallas por d√≠a de la semana\n",
    "        battles_by_day.plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "        axes[0].set_title('Batallas por D√≠a de la Semana')\n",
    "        axes[0].set_xlabel('D√≠a')\n",
    "        axes[0].set_ylabel('N√∫mero de Batallas')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Batallas por hora\n",
    "        battles_by_hour.plot(kind='line', ax=axes[1], color='orange', marker='o')\n",
    "        axes[1].set_title('Actividad por Hora del D√≠a')\n",
    "        axes[1].set_xlabel('Hora')\n",
    "        axes[1].set_ylabel('N√∫mero de Batallas')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / 'temporal_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"An√°lisis temporal guardado: {OUTPUT_DIR / 'temporal_analysis.png'}\")\n",
    "    else:\n",
    "        print(\"No se encontraron timestamps v√°lidos para an√°lisis temporal\")\n",
    "else:\n",
    "    print(\"Columna 'timestamp' no disponible para an√°lisis temporal\")\n",
    "\n",
    "print(f\"\\nEl an√°lisis est√° listo para convertir a notebook y ejecutar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4eed40",
   "metadata": {},
   "source": [
    "## 12. Exportaci√≥n de datasets limpios y diccionario de datos\n",
    "\n",
    "**Artefactos generados:**\n",
    "{{ ... }}\n",
    "- Dataset limpio en formato Parquet para modelado\n",
    "- Diccionario de datos con metadatos completos\n",
    "- Auditor√≠as de calidad de datos\n",
    "- Features preparadas para machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76301e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"EXPORTACI√ìN DE ARTEFACTOS FINALES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Crear diccionario de datos completo\n",
    "if len(df_features) > 0:\n",
    "    data_dict = (df_features.dtypes.to_frame('dtype')\n",
    "                .assign(\n",
    "                    nunique=df_features.nunique(),\n",
    "                    n_null=df_features.isnull().sum(),\n",
    "                    pct_null=(df_features.isnull().sum()/len(df_features)*100).round(2),\n",
    "                    sample_values=df_features.astype(str).apply(\n",
    "                        lambda s: ', '.join(s.dropna().unique()[:3])\n",
    "                    )\n",
    "                )\n",
    "                .sort_values('nunique', ascending=False))\n",
    "    \n",
    "    # Guardar diccionario de datos\n",
    "    dict_path = OUTPUT_DIR / 'data_dictionary.csv'\n",
    "    data_dict.to_csv(dict_path)\n",
    "    print(f\"Diccionario de datos guardado: {dict_path}\")\n",
    "    \n",
    "    # Guardar dataset limpio\n",
    "    clean_dataset_path = OUTPUT_DIR / 'dataset_limpio_features.parquet'\n",
    "    df_features.to_parquet(clean_dataset_path, index=False)\n",
    "    print(f\"Dataset limpio guardado: {clean_dataset_path}\")\n",
    "    \n",
    "    # Guardar dataset de batallas\n",
    "    battles_clean_path = OUTPUT_DIR / 'dataset_batallas_limpio.parquet'\n",
    "    df_battles.to_parquet(battles_clean_path, index=False)\n",
    "    print(f\"Dataset de batallas guardado: {battles_clean_path}\")\n",
    "    \n",
    "    # Si hay datos de Pokemon, guardarlos tambi√©n\n",
    "    if len(df_pokemon) > 0:\n",
    "        pokemon_clean_path = OUTPUT_DIR / 'dataset_pokemon_limpio.parquet'\n",
    "        df_pokemon.to_parquet(pokemon_clean_path, index=False)\n",
    "        print(f\"Dataset de Pokemon guardado: {pokemon_clean_path}\")\n",
    "\n",
    "print(f\"\\nEl an√°lisis est√° listo para convertir a notebook y ejecutar.\")\n",
    "\n",
    "if len(df_battles) > 0 and 'timestamp' in df_battles.columns:\n",
    "    # Convertir timestamp a datetime\n",
    "    df_battles['datetime'] = pd.to_datetime(df_battles['timestamp'], unit='s', errors='coerce')\n",
    "    \n",
    "    if df_battles['datetime'].notna().sum() > 0:\n",
    "        # An√°lisis por d√≠a de la semana\n",
    "        df_battles['day_of_week'] = df_battles['datetime'].dt.day_name()\n",
    "        battles_by_day = df_battles['day_of_week'].value_counts()\n",
    "        \n",
    "        print(\"Distribuci√≥n de batallas por d√≠a de la semana:\")\n",
    "        for day, count in battles_by_day.items():\n",
    "            print(f\"  - {day}: {count:,} batallas\")\n",
    "        \n",
    "        # An√°lisis por hora del d√≠a\n",
    "        df_battles['hour'] = df_battles['datetime'].dt.hour\n",
    "        battles_by_hour = df_battles['hour'].value_counts().sort_index()\n",
    "        \n",
    "        print(f\"\\nHoras pico de actividad:\")\n",
    "        top_hours = battles_by_hour.head(3)\n",
    "        for hour, count in top_hours.items():\n",
    "            print(f\"  - {hour:02d}:00: {count:,} batallas\")\n",
    "        \n",
    "        # Evoluci√≥n temporal de duraci√≥n promedio\n",
    "        df_battles['date'] = df_battles['datetime'].dt.date\n",
    "        daily_avg_turns = df_battles.groupby('date')['total_turns'].mean()\n",
    "        \n",
    "        if len(daily_avg_turns) > 1:\n",
    "            trend = \"creciente\" if daily_avg_turns.iloc[-1] > daily_avg_turns.iloc[0] else \"decreciente\"\n",
    "            print(f\"\\nTendencia en duraci√≥n de batallas: {trend}\")\n",
    "            print(f\"  - Primer d√≠a: {daily_avg_turns.iloc[0]:.1f} turnos promedio\")\n",
    "            print(f\"  - √öltimo d√≠a: {daily_avg_turns.iloc[-1]:.1f} turnos promedio\")\n",
    "        \n",
    "        # Visualizaci√≥n temporal\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Batallas por d√≠a de la semana\n",
    "        battles_by_day.plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "        axes[0].set_title('Batallas por D√≠a de la Semana')\n",
    "        axes[0].set_xlabel('D√≠a')\n",
    "        axes[0].set_ylabel('N√∫mero de Batallas')\n",
    "        axes[0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Batallas por hora\n",
    "        battles_by_hour.plot(kind='line', ax=axes[1], color='orange', marker='o')\n",
    "        axes[1].set_title('Actividad por Hora del D√≠a')\n",
    "        axes[1].set_xlabel('Hora')\n",
    "        axes[1].set_ylabel('N√∫mero de Batallas')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / 'temporal_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"An√°lisis temporal guardado: {OUTPUT_DIR / 'temporal_analysis.png'}\")\n",
    "    else:\n",
    "        print(\"No se encontraron timestamps v√°lidos para an√°lisis temporal\")\n",
    "else:\n",
    "    print(\"Columna 'timestamp' no disponible para an√°lisis temporal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d8ef6d",
   "metadata": {},
   "source": [
    "## 13. An√°lisis de tipos de Pokemon\n",
    "\n",
    "**Relevancia para la IA:**\n",
    "- Los tipos determinan efectividad de movimientos\n",
    "- Crucial para decisiones estrat√©gicas\n",
    "- Identifica combinaciones de tipos dominantes\n",
    "- Informa sobre balance del meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d4802",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"AN√ÅLISIS DE TIPOS DE POKEMON\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if len(df_pokemon) > 0:\n",
    "    # Simular tipos basados en especies conocidas (esto deber√≠a venir de los datos reales)\n",
    "    # En un caso real, extraer√≠as los tipos de la estructura JSON\n",
    "    type_mapping = {\n",
    "        'Charizard': ['Fire', 'Flying'], 'Blastoise': ['Water'], 'Venusaur': ['Grass', 'Poison'],\n",
    "        'Pikachu': ['Electric'], 'Garchomp': ['Dragon', 'Ground'], 'Metagross': ['Steel', 'Psychic'],\n",
    "        'Tyranitar': ['Rock', 'Dark'], 'Dragonite': ['Dragon', 'Flying'], 'Salamence': ['Dragon', 'Flying'],\n",
    "        'Lucario': ['Fighting', 'Steel'], 'Gengar': ['Ghost', 'Poison'], 'Alakazam': ['Psychic']\n",
    "    }\n",
    "    \n",
    "    # Expandir tipos para an√°lisis\n",
    "    type_analysis = []\n",
    "    for _, pokemon in df_pokemon.iterrows():\n",
    "        species = pokemon['species']\n",
    "        if species in type_mapping:\n",
    "            for ptype in type_mapping[species]:\n",
    "                type_analysis.append({\n",
    "                    'species': species,\n",
    "                    'type': ptype,\n",
    "                    'player': pokemon['player'],\n",
    "                    'winner': pokemon['winner']\n",
    "                })\n",
    "    \n",
    "    if type_analysis:\n",
    "        df_types = pd.DataFrame(type_analysis)\n",
    "        \n",
    "        # Tipos m√°s comunes\n",
    "        type_counts = df_types['type'].value_counts()\n",
    "        print(\"Top 10 tipos m√°s utilizados:\")\n",
    "        for i, (ptype, count) in enumerate(type_counts.head(10).items(), 1):\n",
    "            print(f\"  {i:2d}. {ptype}: {count:,} usos\")\n",
    "        \n",
    "        # An√°lisis de efectividad por tipo\n",
    "        if 'winner' in df_types.columns:\n",
    "            type_winrates = df_types.groupby('type').apply(\n",
    "                lambda x: (x['winner'] == x['player']).mean() if len(x) > 10 else None\n",
    "            ).dropna().sort_values(ascending=False)\n",
    "            \n",
    "            if len(type_winrates) > 0:\n",
    "                print(f\"\\nTipos con mejor winrate (m√≠n. 10 usos):\")\n",
    "                for ptype, winrate in type_winrates.head(5).items():\n",
    "                    print(f\"  - {ptype}: {winrate:.1%}\")\n",
    "        \n",
    "        # Visualizaci√≥n de tipos\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Distribuci√≥n de tipos\n",
    "        type_counts.head(12).plot(kind='barh', ax=axes[0], color='lightcoral')\n",
    "        axes[0].set_title('Distribuci√≥n de Tipos de Pokemon')\n",
    "        axes[0].set_xlabel('N√∫mero de Usos')\n",
    "        \n",
    "        # Winrates por tipo (si disponible)\n",
    "        if len(type_winrates) > 0:\n",
    "            type_winrates.head(10).plot(kind='bar', ax=axes[1], color='lightgreen')\n",
    "            axes[1].set_title('Winrate por Tipo de Pokemon')\n",
    "            axes[1].set_ylabel('Winrate')\n",
    "            axes[1].tick_params(axis='x', rotation=45)\n",
    "            axes[1].axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='50%')\n",
    "            axes[1].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTPUT_DIR / 'type_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"An√°lisis de tipos guardado: {OUTPUT_DIR / 'type_analysis.png'}\")\n",
    "    else:\n",
    "        print(\"No se pudieron mapear tipos para las especies encontradas\")\n",
    "else:\n",
    "    print(\"No hay datos de Pokemon disponibles para an√°lisis de tipos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4550f55c",
   "metadata": {},
   "source": [
    "---\n",
    "# Estrategia Final: El Blueprint para la IA Maestra\n",
    "\n",
    "**Despu√©s de nuestro exhaustivo viaje por los datos, es momento de trazar el mapa definitivo hacia la creaci√≥n de una IA Pokemon de nivel maestro.**\n",
    "\n",
    "Hemos extra√≠do cada secreto de las batallas, analizado cada patr√≥n, y destilado todo el conocimiento en caracter√≠sticas que una IA puede dominar. Ahora, presentamos la estrategia revolucionaria que transformar√° estos insights en inteligencia artificial superior.\n",
    "\n",
    "## Estrategia de Entrenamiento Revolucionaria\n",
    "\n",
    "### Arquitectura Recomendada\n",
    "\n",
    "**Modelo H√≠brido Multi-Componente:**\n",
    "- **CNN (Convolutional Neural Network)**: Para patrones espaciales de equipos y composiciones\n",
    "- **LSTM (Long Short-Term Memory)**: Para secuencias temporales de batalla y momentum\n",
    "- **Attention Mechanism**: Para decisiones cr√≠ticas por turno y timing √≥ptimo\n",
    "- **Transformer Blocks**: Para relaciones complejas entre Pokemon y movimientos\n",
    "\n",
    "### Enfoques de Aprendizaje Avanzados\n",
    "\n",
    "**Multi-Task Learning:**\n",
    "- Predecir pr√≥ximo movimiento √≥ptimo\n",
    "- Estimar probabilidad de victoria\n",
    "- Calcular timing perfecto para switches\n",
    "- Evaluar riesgo/recompensa de cada acci√≥n\n",
    "\n",
    "**Curriculum Learning:**\n",
    "- Fase 1: Batallas simples y directas\n",
    "- Fase 2: Escenarios con switches complejos\n",
    "- Fase 3: Batallas de alta intensidad y momentum\n",
    "- Fase 4: Meta-game y estrategias anti-competitivas\n",
    "\n",
    "**Adversarial Training:**\n",
    "- IA vs IA para desarrollar estrategias anti-meta\n",
    "- Generaci√≥n de escenarios adversos\n",
    "- Robustez contra estrategias impredecibles\n",
    "\n",
    "**Continual Learning:**\n",
    "- Adaptaci√≥n autom√°tica a cambios en el meta competitivo\n",
    "- Aprendizaje incremental de nuevas estrategias\n",
    "- Preservaci√≥n de conocimiento previo\n",
    "\n",
    "## Impacto Revolucionario en el Rendimiento\n",
    "\n",
    "**Con nuestras mejoras implementadas, la IA ahora puede:**\n",
    "\n",
    "**1. Detectar Momentum y Cambiar Estrategias Seg√∫n la Fase**\n",
    "- Reconocer patrones de early-game vs late-game\n",
    "- Adaptar agresividad seg√∫n intensidad de batalla\n",
    "- Optimizar decisiones por fase temporal\n",
    "\n",
    "**2. Evaluar Ventajas de Informaci√≥n y Composici√≥n de Equipos**\n",
    "- Calcular ventajas de HP, nivel y diversidad\n",
    "- Aprovechar informaci√≥n parcial del oponente\n",
    "- Optimizar team synergy y balance\n",
    "\n",
    "**3. Predecir Patrones de Decisi√≥n del Oponente**\n",
    "- Analizar ratios move/switch hist√≥ricos\n",
    "- Detectar tendencias en acciones consecutivas\n",
    "- Anticipar cambios de estrategia\n",
    "\n",
    "**4. Optimizar Timing de Switches y Movimientos Cr√≠ticos**\n",
    "- Calcular momentos √≥ptimos para cambios\n",
    "- Maximizar impacto de movimientos especiales\n",
    "- Minimizar riesgos en decisiones cr√≠ticas\n",
    "\n",
    "**5. Adaptarse Din√°micamente a Diferentes Estilos de Juego**\n",
    "- Reconocer estilos agresivos vs defensivos\n",
    "- Ajustar estrategia seg√∫n rating del oponente\n",
    "- Evolucionar t√°ctica durante la batalla\n",
    "\n",
    "## El Legado de Nuestro An√°lisis\n",
    "\n",
    "**Hemos transformado datos crudos en sabidur√≠a estrat√©gica.**\n",
    "\n",
    "Cada feature extra√≠da, cada patr√≥n descubierto, cada insight revelado contribuye a crear una IA que no solo juega Pokemon, sino que comprende la esencia misma del combate estrat√©gico. \n",
    "\n",
    "**La IA resultante ser√° capaz de:**\n",
    "- Tomar decisiones con la intuici√≥n de un maestro\n",
    "- Adaptarse con la flexibilidad de un experto\n",
    "- Aprender con la velocidad de una m√°quina\n",
    "- Competir con la precisi√≥n de un campe√≥n\n",
    "\n",
    "**El futuro del combate Pokemon ha comenzado.**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
