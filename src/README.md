# Source Code Structure

## M√≥dulos

### `agents/` - Agentes de Reinforcement Learning
- `base_agent.py` - Clase base abstracta para todos los agentes
- `dqn_agent.py` - Deep Q-Network agent (Fase 3)
- `ppo_agent.py` - Proximal Policy Optimization agent (Fase 4)
- `random_agent.py` - ‚úÖ Agente random para baseline

### `data/` - Procesamiento de Datos
- `feature_extractor.py` - ‚úÖ Extracci√≥n de features para ML (Fase 1)
- `battle_parser.py` - Parser de batallas JSON (Fase 2)
- `state_builder.py` - Construcci√≥n de estados para RL (Fase 2)
- `pokemon_data.py` - Base de datos Pokemon (tipos, BST)

### `environment/` - Entorno de Batalla
- `battle_env.py` - Gym environment principal (Fase 3)
- `battle_state.py` - Representaci√≥n de estado (Fase 3)
- `action_space.py` - Definici√≥n de acciones (Fase 3)
- `showdown_client.py` - Cliente Pokemon Showdown (Fase 4)

### `models/` - Redes Neuronales
- `networks.py` - ‚úÖ Arquitecturas de redes neuronales
- `baseline_models.py` - Modelos ML cl√°sicos (Fase 1)

### `training/` - Sistemas de Entrenamiento
- `rl_trainer.py` - Entrenador para agentes RL (Fase 3)
- `self_play.py` - Sistema de self-play (Fase 3)
- `evaluator.py` - Evaluaci√≥n de agentes (Fase 3)
- `ml_trainer.py` - Entrenador ML cl√°sico (Fase 1)

### `utils/` - Utilidades
- `replay_buffer.py` - ‚úÖ Buffer de experiencias para RL
- `logger.py` - Logging personalizado
- `metrics.py` - M√©tricas de evaluaci√≥n
- `visualization.py` - Visualizaci√≥n de entrenamiento

## Estado Actual

‚úÖ = Implementado
üîÑ = En progreso
‚è∏Ô∏è = Pendiente

**Fase 1 (Completada):**
- ‚úÖ `data/feature_extractor.py`
- ‚úÖ `models/networks.py`
- ‚úÖ `utils/replay_buffer.py`
- ‚úÖ `agents/base_agent.py`
- ‚úÖ `agents/random_agent.py`

**Fase 2 (Pr√≥xima):**
- ‚è∏Ô∏è `data/battle_parser.py`
- ‚è∏Ô∏è `data/state_builder.py`

**Fase 3+ (Futuro):**
- ‚è∏Ô∏è `agents/dqn_agent.py`
- ‚è∏Ô∏è `environment/battle_env.py`
- ‚è∏Ô∏è `training/rl_trainer.py`
- ‚è∏Ô∏è `training/self_play.py`
