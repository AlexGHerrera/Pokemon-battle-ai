# %% [markdown]
# # Pokemon Battle Dataset - An√°lisis Exploratorio de Datos (EDA)
# 
# ## Alcance del Proyecto
# 
# Este proyecto tiene como objetivo desarrollar un **modelo de inteligencia artificial capaz de jugar Pokemon de forma aut√≥noma** contra usuarios humanos. Para lograr esto, necesitamos comprender profundamente los patrones de batalla, estrategias ganadoras y comportamientos de los jugadores expertos.
# 
# ### Finalidad del EDA
# 
# **Objetivo Principal**: Extraer insights del dataset de batallas Pokemon Showdown para entrenar un modelo de IA competitivo.
# 
# **Objetivos Espec√≠ficos**:
# 1. **An√°lisis de Calidad**: Validar la integridad y completitud del dataset de batallas
# 2. **Patrones Estrat√©gicos**: Identificar comportamientos que llevan al √©xito en batalla
# 3. **Feature Engineering**: Extraer caracter√≠sticas relevantes para el aprendizaje autom√°tico
# 4. **An√°lisis del Meta**: Entender qu√© Pokemon y estrategias dominan el formato competitivo
# 5. **Optimizaci√≥n de Datos**: Preparar el dataset para entrenamiento eficiente del modelo
# 
# ### Contexto del Dataset
# 
# - **Fuente**: Batallas reales de Pokemon Showdown (formato gen9randombattle)
# - **Volumen**: ~14,000 batallas individuales en formato JSON
# - **Contenido**: Turnos secuenciales, eventos de batalla, estados del juego, resultados
# - **Aplicaci√≥n**: Entrenamiento de modelo de IA para toma de decisiones en tiempo real
# 
# ### Metodolog√≠a
# 
# Este EDA est√° estructurado para maximizar la extracci√≥n de conocimiento √∫til para el modelo de IA:
# - **An√°lisis incremental** desde datos b√°sicos hasta patrones complejos
# - **Visualizaciones explicativas** que revelen insights estrat√©gicos
# - **Optimizaciones de rendimiento** para manejo eficiente de grandes vol√∫menes de datos
# - **Features estructuradas** listas para algoritmos de machine learning
# 
# ---
# 
# # %% [markdown]
# ## Importaci√≥n de librer√≠as y configuraci√≥n inicial
# 
# **Objetivo de esta secci√≥n:**
# - Importamos las librer√≠as necesarias para el an√°lisis de datos y visualizaci√≥n
# - Configuramos matplotlib y seaborn para generar gr√°ficas consistentes y profesionales
# - Establecemos warnings para evitar mensajes innecesarios durante el procesamiento
# - Estas configuraciones son fundamentales para un EDA reproducible y visualmente atractivo

# %%
from __future__ import annotations
import json
from collections import Counter, defaultdict
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import random

# Configuraci√≥n de visualizaciones
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

print("‚úÖ Librer√≠as importadas correctamente")
print("‚úÖ Configuraci√≥n de visualizaci√≥n establecida")

# %% [markdown]
# ## Configuraci√≥n de rutas y constantes
# 
# **Prop√≥sito de la configuraci√≥n:**
# - Centralizamos la gesti√≥n de archivos para facilitar el mantenimiento del c√≥digo
# - `BATTLES_DIR`: Contiene los archivos JSON individuales de cada batalla
# - `ALL_BATTLES_JSON`: Archivo consolidado que mejora la velocidad de carga
# - `OUTPUT_DIR`: Directorio donde guardaremos visualizaciones y resultados
# - Esta organizaci√≥n es crucial para un flujo de trabajo ordenado y escalable

# %%
DATA_DIR = Path("data")
BATTLES_DIR = DATA_DIR / "battles"
ALL_BATTLES_JSON = DATA_DIR / "all_battles.json"
OUTPUT_DIR = Path("output")
OUTPUT_DIR.mkdir(exist_ok=True)

print(f"üìÅ Directorio de datos: {DATA_DIR}")
print(f"üìÅ Directorio de batallas: {BATTLES_DIR}")
print(f"üìÑ Archivo consolidado: {ALL_BATTLES_JSON}")
print(f"üìä Directorio de salida: {OUTPUT_DIR}")

# %% [markdown]
# ## Funciones auxiliares para procesamiento de datos
# 
# **Funciones implementadas:**
# - `get_in()`: Navega estructuras JSON anidadas de forma segura, evitando errores por claves faltantes
# - `extract_pokemon_info()`: Extrae informaci√≥n espec√≠fica de Pokemon que ser√° clave para el modelo de IA
# - `calculate_battle_metrics()`: Calcula m√©tricas estrat√©gicas como eventos por turno, tipos de acciones, etc.
# - Estas funciones nos permiten transformar datos complejos en features estructuradas para machine learning

# %%
def get_in(d: Any, path: List[str], default: Any = None) -> Any:
    """Extrae valores anidados de diccionarios de forma segura."""
    cur = d
    for k in path:
        if isinstance(cur, dict) and k in cur:
            cur = cur[k]
        else:
            return default
    return cur

def extract_pokemon_info(battle: dict) -> List[dict]:
    """Extrae informaci√≥n detallada de Pokemon de una batalla."""
    pokemon_info = []
    teams = get_in(battle, ["team_revelation", "teams"], {})
    
    for player_id, team in teams.items():
        if isinstance(team, list):
            for pokemon in team:
                info = {
                    'battle_id': battle.get('battle_id'),
                    'player': player_id,
                    'species': pokemon.get('species'),
                    'level': pokemon.get('level'),
                    'gender': pokemon.get('gender'),
                    'hp': get_in(pokemon, ['base_stats', 'hp']),
                    'first_seen_turn': pokemon.get('first_seen_turn'),
                    'revelation_status': pokemon.get('revelation_status')
                }
                pokemon_info.append(info)
    return pokemon_info

def calculate_battle_metrics(battle: dict) -> dict:
    """Calcula m√©tricas clave de una batalla para an√°lisis."""
    metadata = battle.get('metadata', {})
    turns = battle.get('turns', [])
    
    # M√©tricas b√°sicas
    total_turns = len(turns)
    winner = get_in(metadata, ['outcome', 'winner'])
    reason = get_in(metadata, ['outcome', 'reason'])
    
    # An√°lisis de eventos por turno
    total_events = sum(len(turn.get('events', [])) for turn in turns)
    move_events = 0
    switch_events = 0
    damage_events = 0
    
    for turn in turns:
        events = turn.get('events', [])
        for event in events:
            event_type = event.get('type')
            if event_type == 'move':
                move_events += 1
            elif event_type == 'switch':
                switch_events += 1
            elif event_type == 'damage':
                damage_events += 1
    
    return {
        'battle_id': battle.get('battle_id'),
        'total_turns': total_turns,
        'total_events': total_events,
        'move_events': move_events,
        'switch_events': switch_events,
        'damage_events': damage_events,
        'winner': winner,
        'reason': reason,
        'events_per_turn': total_events / max(total_turns, 1),
        'timestamp': metadata.get('timestamp_unix')
    }

print("‚úÖ Funciones auxiliares definidas correctamente")

# %% [markdown]
# ## Funciones de optimizaci√≥n para datasets grandes
# 
# **Estrategias implementadas:**
# - Muestreo aleatorio para desarrollo r√°pido
# - Conversi√≥n a formato Parquet (m√°s eficiente)
# - Carga por chunks para evitar problemas de memoria
# - Procesamiento incremental de batallas

# %%
def create_sample_dataset(sample_size: int = 1000, force_recreate: bool = False) -> List[dict]:
    """
    Crea un dataset de muestra para desarrollo r√°pido.
    
    Args:
        sample_size: N√∫mero de batallas a incluir en la muestra
        force_recreate: Si True, recrea la muestra aunque ya exista
    """
    sample_path = DATA_DIR / f"battles_sample_{sample_size}.json"
    
    if sample_path.exists() and not force_recreate:
        print(f"Cargando muestra existente: {sample_path}")
        with open(sample_path, "r") as f:
            return json.load(f)
    
    print(f"Creando nueva muestra de {sample_size} batallas...")
    
    # Cargar dataset completo y tomar muestra aleatoria
    with open(ALL_BATTLES_JSON, "r") as f:
        all_battles = json.load(f)
    
    import random
    random.seed(42)  # Para reproducibilidad
    sample_battles = random.sample(all_battles, min(sample_size, len(all_battles)))
    
    # Guardar muestra
    with open(sample_path, "w") as f:
        json.dump(sample_battles, f, indent=2)
    
    print(f"Muestra guardada: {sample_path}")
    print(f"Tama√±o de muestra: {len(sample_battles)} batallas")
    
    return sample_battles

def convert_to_parquet() -> None:
    """
    Convierte el dataset a formato Parquet para acceso m√°s r√°pido.
    """
    parquet_path = DATA_DIR / "battles_optimized.parquet"
    
    if parquet_path.exists():
        print(f"Archivo Parquet ya existe: {parquet_path}")
        return
    
    print("Convirtiendo a formato Parquet...")
    
    # Cargar y procesar por chunks
    chunk_size = 1000
    all_metrics = []
    
    with open(ALL_BATTLES_JSON, "r") as f:
        battles = json.load(f)
    
    for i in range(0, len(battles), chunk_size):
        chunk = battles[i:i+chunk_size]
        chunk_metrics = [calculate_battle_metrics(battle) for battle in chunk]
        all_metrics.extend(chunk_metrics)
        
        if (i + chunk_size) % 5000 == 0:
            print(f"Procesadas {i + chunk_size} batallas...")
    
    # Convertir a DataFrame y guardar
    df = pd.DataFrame(all_metrics)
    df.to_parquet(parquet_path, index=False)
    
    print(f"Dataset convertido a Parquet: {parquet_path}")
    print(f"Tama√±o original JSON: {ALL_BATTLES_JSON.stat().st_size / 1024 / 1024:.1f} MB")
    print(f"Tama√±o Parquet: {parquet_path.stat().st_size / 1024 / 1024:.1f} MB")

def load_battles_optimized(use_sample: bool = True, sample_size: int = 1000) -> List[dict]:
    """
    Carga optimizada de datos con opciones de muestreo.
    
    Args:
        use_sample: Si True, usa una muestra para desarrollo r√°pido
        sample_size: Tama√±o de la muestra si use_sample=True
    """
    if use_sample:
        print(f"Modo desarrollo: usando muestra de {sample_size} batallas")
        return create_sample_dataset(sample_size)
    else:
        print("Modo producci√≥n: cargando dataset completo")
        if ALL_BATTLES_JSON.exists():
            with open(ALL_BATTLES_JSON, "r") as f:
                return json.load(f)
        else:
            raise FileNotFoundError(f"No existe {ALL_BATTLES_JSON}")

def load_parquet_if_exists() -> Optional[pd.DataFrame]:
    """
    Carga el archivo Parquet si existe, para an√°lisis r√°pido.
    """
    parquet_path = DATA_DIR / "battles_optimized.parquet"
    
    if parquet_path.exists():
        print(f"Cargando datos desde Parquet: {parquet_path}")
        return pd.read_parquet(parquet_path)
    else:
        print("Archivo Parquet no encontrado. Usa convert_to_parquet() primero.")
        return None

# %% [markdown]
# ## 1. Carga y consolidaci√≥n de datos
# 
# **Justificaci√≥n de la consolidaci√≥n:**
# - Los datos vienen en miles de archivos JSON individuales, lo que es ineficiente para an√°lisis
# - La consolidaci√≥n mejora significativamente la velocidad de carga y procesamiento
# - Nos permite validar la integridad de los datos y detectar archivos corruptos
# - Facilita el an√°lisis posterior al tener todos los datos en una estructura unificada
# - Es un paso fundamental antes de cualquier an√°lisis exploratorio serio

# %%
def load_battles_data() -> List[dict]:
    """Carga y consolida todos los datos de batallas."""
    if ALL_BATTLES_JSON.exists():
        with open(ALL_BATTLES_JSON, "r") as f:
            return json.load(f)
    
    # Si no existe el archivo consolidado, lo creamos
    json_files = sorted(BATTLES_DIR.glob("*.json"))
    battles_data = []
    
    print(f"Consolidando {len(json_files)} archivos JSON...")
    
    for i, file in enumerate(json_files):
        try:
            with open(file, "r") as f:
                battle = json.load(f)
                battles_data.append(battle)
        except Exception as e:
            print(f"Error procesando {file.name}: {e}")
            continue
        
        if (i + 1) % 1000 == 0:
            print(f"Procesados {i + 1} archivos...")
    
    # Guardar archivo consolidado
    with open(ALL_BATTLES_JSON, "w") as f:
        json.dump(battles_data, f, indent=2)
    
    print(f"Datos consolidados: {len(battles_data)} batallas")
    return battles_data

# Cargar datos
battles = load_battles_optimized(use_sample=True, sample_size=2000)  # Modo desarrollo por defecto
print(f"Total de batallas cargadas: {len(battles):,}")

# %% [markdown]
# ### Configuraci√≥n de modo de trabajo
# 
# **Para cambiar entre modos:**
# - **Desarrollo r√°pido**: `battles = load_battles_optimized(use_sample=True, sample_size=2000)`
# - **Dataset completo**: `battles = load_battles_optimized(use_sample=False)`
# - **Desde Parquet**: `df_battles = load_parquet_if_exists()`

# %% [markdown]
# ## 2. An√°lisis de calidad de datos
# 
# **Importancia del an√°lisis de calidad:**
# - Identificamos problemas de datos antes de invertir tiempo en an√°lisis incorrectos
# - Validamos que las batallas tengan la estructura esperada (battle_id, metadata, turns)
# - Detectamos patrones de datos faltantes que podr√≠an sesgar nuestro modelo
# - Entendemos la distribuci√≥n de formatos de batalla para enfocar el entrenamiento
# - La calidad de datos determina directamente la calidad del modelo de IA resultante

# %%
print("=" * 60)
print("AN√ÅLISIS DE CALIDAD DE DATOS")
print("=" * 60)

# Estad√≠sticas b√°sicas
total_battles = len(battles)
print(f"Total de batallas: {total_battles:,}")

# Validaci√≥n de estructura
valid_battles = 0
incomplete_battles = 0

required_keys = ['battle_id', 'metadata', 'turns']
for battle in battles:
    if all(key in battle for key in required_keys):
        valid_battles += 1
    else:
        incomplete_battles += 1

print(f"Batallas con estructura completa: {valid_battles:,} ({valid_battles/total_battles*100:.1f}%)")
print(f"Batallas incompletas: {incomplete_battles:,} ({incomplete_battles/total_battles*100:.1f}%)")

# An√°lisis de formatos
formats = Counter(battle.get('format_id') for battle in battles)
print(f"\nFormatos de batalla encontrados:")
for format_id, count in formats.most_common():
    print(f"  - {format_id}: {count:,} batallas")

# %% [markdown]
# ## 3. An√°lisis de resultados de batalla
# 
# **Relevancia del an√°lisis de resultados:**
# - Verificamos si hay balance entre jugadores (p1 vs p2) para evitar sesgos en el entrenamiento
# - Las razones de finalizaci√≥n nos indican qu√© estrategias son m√°s efectivas
# - La duraci√≥n de batallas revela patrones de juego defensivo vs agresivo
# - Estos patrones son fundamentales para que la IA aprenda estrategias ganadoras
# - Un dataset balanceado asegura que el modelo no favorezca injustamente a un jugador

# %%
print("\n" + "=" * 60)
print("AN√ÅLISIS DE RESULTADOS DE BATALLA")
print("=" * 60)

# Extraer m√©tricas de batalla
battle_metrics = [calculate_battle_metrics(battle) for battle in battles]
df_battles = pd.DataFrame(battle_metrics)

# An√°lisis de ganadores
winner_counts = df_battles['winner'].value_counts()
print(f"Distribuci√≥n de ganadores:")
for winner, count in winner_counts.items():
    print(f"  - {winner}: {count:,} ({count/len(df_battles)*100:.1f}%)")

# Razones de victoria
reason_counts = df_battles['reason'].value_counts()
print(f"\nRazones de finalizaci√≥n:")
for reason, count in reason_counts.items():
    print(f"  - {reason}: {count:,} ({count/len(df_battles)*100:.1f}%)")

# Estad√≠sticas de duraci√≥n
print(f"\nEstad√≠sticas de duraci√≥n de batalla:")
print(f"  - Turnos promedio: {df_battles['total_turns'].mean():.1f}")
print(f"  - Turnos mediana: {df_battles['total_turns'].median():.1f}")
print(f"  - Turnos min/max: {df_battles['total_turns'].min()}/{df_battles['total_turns'].max()}")

# Mostrar primeras filas del DataFrame
print(f"\nPrimeras 5 batallas procesadas:")
print(df_battles[['battle_id', 'total_turns', 'winner', 'reason', 'move_events', 'switch_events']].head())

# %% [markdown]
# ## 4. An√°lisis de patrones de batalla
# 
# **Valor del an√°lisis de patrones:**
# - Los eventos por batalla (movimientos, switches, da√±o) son las acciones que debe aprender la IA
# - La correlaci√≥n turnos-eventos nos indica la intensidad estrat√©gica de las batallas
# - Los patrones por ganador revelan qu√© comportamientos llevan al √©xito
# - El ratio movimientos/switches indica agresividad vs cautela en las estrategias
# - Estos insights guiar√°n el dise√±o de la funci√≥n de recompensa del modelo de IA

# %%
print("\n" + "=" * 60)
print("AN√ÅLISIS DE PATRONES DE BATALLA")
print("=" * 60)

# An√°lisis de eventos por batalla
print(f"Eventos por batalla:")
print(f"  - Eventos totales promedio: {df_battles['total_events'].mean():.1f}")
print(f"  - Movimientos promedio: {df_battles['move_events'].mean():.1f}")
print(f"  - Switches promedio: {df_battles['switch_events'].mean():.1f}")
print(f"  - Eventos de da√±o promedio: {df_battles['damage_events'].mean():.1f}")

# Relaci√≥n entre duraci√≥n y eventos
correlation = df_battles['total_turns'].corr(df_battles['total_events'])
print(f"\nCorrelaci√≥n turnos-eventos: {correlation:.3f}")

# An√°lisis por ganador
print(f"\nPatrones por ganador:")
for winner in ['p1', 'p2']:
    winner_data = df_battles[df_battles['winner'] == winner]
    if len(winner_data) > 0:
        print(f"  {winner}:")
        print(f"    - Turnos promedio: {winner_data['total_turns'].mean():.1f}")
        print(f"    - Eventos promedio: {winner_data['total_events'].mean():.1f}")
        print(f"    - Ratio movimientos/switches: {winner_data['move_events'].mean() / max(winner_data['switch_events'].mean(), 1):.2f}")

# %% [markdown]
# ## 5. An√°lisis de uso de Pokemon
# 
# **Importancia del an√°lisis de Pokemon:**
# - Identificamos el 'meta' actual: qu√© Pokemon son m√°s populares y por qu√©
# - Los niveles y HP nos dan informaci√≥n sobre el balance del juego
# - La frecuencia de uso indica qu√© Pokemon debe priorizar la IA en sus decisiones
# - Esta informaci√≥n es crucial para que la IA entienda amenazas y oportunidades
# - Los Pokemon m√°s utilizados probablemente tienen estrategias m√°s desarrolladas en los datos

# %%
print("\n" + "=" * 60)
print("AN√ÅLISIS DE USO DE POKEMON")
print("=" * 60)

# Extraer informaci√≥n de Pokemon
all_pokemon = []
for battle in battles:
    pokemon_info = extract_pokemon_info(battle)
    for pokemon in pokemon_info:
        pokemon['winner'] = get_in(battle, ['metadata', 'outcome', 'winner'])
        all_pokemon.append(pokemon)

df_pokemon = pd.DataFrame(all_pokemon)

if len(df_pokemon) > 0:
    # Pokemon m√°s utilizados
    species_counts = df_pokemon['species'].value_counts()
    print(f"Top 10 Pokemon m√°s utilizados:")
    for i, (species, count) in enumerate(species_counts.head(10).items(), 1):
        print(f"  {i:2d}. {species}: {count:,} usos")
    
    # An√°lisis de niveles
    print(f"\nDistribuci√≥n de niveles:")
    print(f"  - Nivel promedio: {df_pokemon['level'].mean():.1f}")
    print(f"  - Nivel mediana: {df_pokemon['level'].median():.1f}")
    print(f"  - Rango de niveles: {df_pokemon['level'].min()}-{df_pokemon['level'].max()}")
    
    # An√°lisis de HP
    hp_data = df_pokemon.dropna(subset=['hp'])
    if len(hp_data) > 0:
        print(f"\nEstad√≠sticas de HP:")
        print(f"  - HP promedio: {hp_data['hp'].mean():.1f}")
        print(f"  - HP mediana: {hp_data['hp'].median():.1f}")
        print(f"  - Rango HP: {hp_data['hp'].min()}-{hp_data['hp'].max()}")

print(f"\nDataFrame de Pokemon - Shape: {df_pokemon.shape}")
print(df_pokemon.head())

# %% [markdown]
# ## 6. Visualizaciones clave para entrenamiento de IA
# 
# **Visualizaciones seleccionadas:**
# - **Distribuci√≥n de duraci√≥n**: Muestra la variabilidad de estrategias (r√°pidas vs largas)
# - **Eventos vs turnos**: Revela la intensidad de acci√≥n, clave para modelar decisiones
# - **Patrones por ganador**: Identifica comportamientos exitosos que la IA debe imitar
# - **Razones de finalizaci√≥n**: Ense√±a a la IA los diferentes caminos hacia la victoria
# - Estas gr√°ficas nos ayudan a validar hip√≥tesis y comunicar insights del dataset

# %%
# Configurar subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('An√°lisis de Patrones de Batalla Pokemon', fontsize=16, fontweight='bold')

# 1. Distribuci√≥n de duraci√≥n de batallas
axes[0, 0].hist(df_battles['total_turns'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
axes[0, 0].set_title('Distribuci√≥n de Duraci√≥n de Batallas')
axes[0, 0].set_xlabel('N√∫mero de Turnos')
axes[0, 0].set_ylabel('Frecuencia')
axes[0, 0].axvline(df_battles['total_turns'].mean(), color='red', linestyle='--', 
                   label=f'Media: {df_battles["total_turns"].mean():.1f}')
axes[0, 0].legend()

# 2. Eventos por turno
axes[0, 1].scatter(df_battles['total_turns'], df_battles['events_per_turn'], 
                   alpha=0.6, color='green')
axes[0, 1].set_title('Eventos por Turno vs Duraci√≥n')
axes[0, 1].set_xlabel('N√∫mero de Turnos')
axes[0, 1].set_ylabel('Eventos por Turno')

# 3. Comparaci√≥n de patrones por ganador
winner_data = df_battles.groupby('winner').agg({
    'total_turns': 'mean',
    'move_events': 'mean',
    'switch_events': 'mean'
}).reset_index()

x = range(len(winner_data))
width = 0.25
axes[1, 0].bar([i - width for i in x], winner_data['total_turns'], width, 
               label='Turnos Promedio', alpha=0.8)
axes[1, 0].bar(x, winner_data['move_events'], width, 
               label='Movimientos Promedio', alpha=0.8)
axes[1, 0].bar([i + width for i in x], winner_data['switch_events'], width, 
               label='Switches Promedio', alpha=0.8)
axes[1, 0].set_title('Patrones por Ganador')
axes[1, 0].set_xlabel('Ganador')
axes[1, 0].set_ylabel('Cantidad')
axes[1, 0].set_xticks(x)
axes[1, 0].set_xticklabels(winner_data['winner'])
axes[1, 0].legend()

# 4. Raz√≥n de finalizaci√≥n
reason_counts = df_battles['reason'].value_counts()
axes[1, 1].pie(reason_counts.values, labels=reason_counts.index, autopct='%1.1f%%')
axes[1, 1].set_title('Razones de Finalizaci√≥n')

plt.tight_layout()
plt.savefig(OUTPUT_DIR / 'battle_patterns_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

print(f"Visualizaci√≥n guardada: {OUTPUT_DIR / 'battle_patterns_analysis.png'}")

# %% [markdown]
# ## 7. An√°lisis visual de Pokemon
# 
# **Enfoque del an√°lisis visual:**
# - **Top Pokemon**: La IA debe conocer las amenazas m√°s comunes del meta
# - **Distribuci√≥n de niveles**: Entiende el rango de poder esperado en batallas
# - **HP vs Nivel**: Revela la relaci√≥n entre estad√≠sticas, crucial para c√°lculos de da√±o
# - **Distribuci√≥n por g√©nero**: Algunos movimientos y habilidades dependen del g√©nero
# - Estas visualizaciones informan las decisiones de selecci√≥n de equipo de la IA

# %%
if len(df_pokemon) > 0:
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('An√°lisis de Pokemon en Batallas', fontsize=16, fontweight='bold')
    
    # 1. Top Pokemon m√°s utilizados
    top_pokemon = df_pokemon['species'].value_counts().head(15)
    axes[0, 0].barh(range(len(top_pokemon)), top_pokemon.values)
    axes[0, 0].set_yticks(range(len(top_pokemon)))
    axes[0, 0].set_yticklabels(top_pokemon.index)
    axes[0, 0].set_title('Top 15 Pokemon M√°s Utilizados')
    axes[0, 0].set_xlabel('N√∫mero de Usos')
    
    # 2. Distribuci√≥n de niveles
    axes[0, 1].hist(df_pokemon['level'].dropna(), bins=20, alpha=0.7, color='orange', edgecolor='black')
    axes[0, 1].set_title('Distribuci√≥n de Niveles de Pokemon')
    axes[0, 1].set_xlabel('Nivel')
    axes[0, 1].set_ylabel('Frecuencia')
    
    # 3. HP vs Nivel
    hp_level_data = df_pokemon.dropna(subset=['hp', 'level'])
    if len(hp_level_data) > 0:
        axes[1, 0].scatter(hp_level_data['level'], hp_level_data['hp'], alpha=0.6, color='purple')
        axes[1, 0].set_title('HP vs Nivel de Pokemon')
        axes[1, 0].set_xlabel('Nivel')
        axes[1, 0].set_ylabel('HP')
    
    # 4. Distribuci√≥n por g√©nero
    gender_counts = df_pokemon['gender'].value_counts()
    axes[1, 1].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%')
    axes[1, 1].set_title('Distribuci√≥n por G√©nero')
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'pokemon_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"Visualizaci√≥n guardada: {OUTPUT_DIR / 'pokemon_analysis.png'}")

# %% [markdown]
# ## 8. Extracci√≥n de features para entrenamiento de IA
# 
# **Features seleccionados:**
# - **M√©tricas de batalla**: Duraci√≥n, eventos, ratios - capturan el 'estilo' de juego
# - **Ratings de jugadores**: Proxy del nivel de habilidad, importante para el aprendizaje
# - **Informaci√≥n de equipos**: Tama√±o, niveles promedio - contexto estrat√©gico
# - **Patrones temporales**: Eventos por turno - ritmo de juego que debe aprender la IA
# - Estos features formar√°n el input del modelo de machine learning para toma de decisiones

# %%
print("\n" + "=" * 60)
print("EXTRACCI√ìN DE FEATURES PARA IA")
print("=" * 60)

# Features a nivel de batalla
battle_features = []

for battle in battles:
    # M√©tricas b√°sicas
    metrics = calculate_battle_metrics(battle)
    
    # Features adicionales
    features = {
        'battle_id': battle.get('battle_id'),
        'total_turns': metrics['total_turns'],
        'winner': metrics['winner'],
        'reason': metrics['reason'],
        'move_events': metrics['move_events'],
        'switch_events': metrics['switch_events'],
        'events_per_turn': metrics['events_per_turn'],
    }
    
    # Informaci√≥n de jugadores
    players = battle.get('players', {})
    for player_id in ['p1', 'p2']:
        player_data = players.get(player_id, {})
        features[f'{player_id}_rating'] = player_data.get('ladder_rating_pre', 0)
    
    # Informaci√≥n de equipos
    teams = get_in(battle, ['team_revelation', 'teams'], {})
    for player_id in ['p1', 'p2']:
        team = teams.get(player_id, [])
        features[f'{player_id}_team_size'] = len(team) if isinstance(team, list) else 0
        
        # Nivel promedio del equipo
        if isinstance(team, list) and team:
            levels = [p.get('level', 0) for p in team if p.get('level')]
            features[f'{player_id}_avg_level'] = np.mean(levels) if levels else 0
        else:
            features[f'{player_id}_avg_level'] = 0
    
    battle_features.append(features)

df_features = pd.DataFrame(battle_features)

# Guardar features
features_path = OUTPUT_DIR / 'battle_features.csv'
df_features.to_csv(features_path, index=False)

print(f"Features extra√≠das: {len(df_features.columns)} columnas")
print(f"Batallas procesadas: {len(df_features)} registros")
print(f"Features guardadas en: {features_path}")

# Mostrar correlaciones importantes
numeric_cols = df_features.select_dtypes(include=[np.number]).columns
if len(numeric_cols) > 1:
    correlations = df_features[numeric_cols].corr()
    print(f"\nCorrelaciones m√°s altas con 'total_turns':")
    turn_corr = correlations['total_turns'].abs().sort_values(ascending=False)
    for feature, corr in turn_corr.head(5).items():
        if feature != 'total_turns':
            print(f"  - {feature}: {corr:.3f}")

print(f"\nPrimeras 5 filas del dataset de features:")
print(df_features.head())

# %% [markdown]
# ## 9. Matriz de correlaci√≥n de features num√©ricas
# 
# **Prop√≥sito del an√°lisis de correlaciones:**
# - Identificamos features redundantes que pueden confundir al modelo
# - Detectamos relaciones no obvias entre variables que pueden ser √∫tiles
# - Ayuda a seleccionar las features m√°s informativas para el entrenamiento
# - Previene problemas de multicolinealidad en modelos lineales
# - Gu√≠a la ingenier√≠a de features y la selecci√≥n de variables para el modelo final

# %%
# Crear matriz de correlaci√≥n para features num√©ricas
numeric_features = df_features.select_dtypes(include=[np.number])

if len(numeric_features.columns) > 1:
    plt.figure(figsize=(12, 10))
    correlation_matrix = numeric_features.corr()
    
    # Crear heatmap
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, 
                square=True, fmt='.2f')
    plt.title('Matriz de Correlaci√≥n - Features Num√©ricas')
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'correlation_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print(f"Matriz de correlaci√≥n guardada: {OUTPUT_DIR / 'correlation_matrix.png'}")

# %% [markdown]
# ## 10. Resumen ejecutivo para entrenamiento de IA
# 
# **Valor del resumen ejecutivo:**
# - Consolida todos los hallazgos en recomendaciones accionables
# - Define la estrategia de modelado basada en los insights del EDA
# - Identifica los pr√≥ximos pasos t√©cnicos para implementar la IA
# - Establece expectativas realistas sobre el rendimiento del modelo
# - Sirve como documento de referencia durante el desarrollo del modelo

# %%
print("\n" + "=" * 60)
print("RESUMEN EJECUTIVO PARA ENTRENAMIENTO DE IA")
print("=" * 60)

print(f"""
## Hallazgos Clave para el Modelo de IA:

### 1. Caracter√≠sticas del Dataset:
   - Total de batallas analizadas: {len(battles):,}
   - Formato principal: gen9randombattle
   - Estructura de datos consistente y completa

### 2. Patrones de Batalla Identificados:
   - Duraci√≥n promedio: {df_battles['total_turns'].mean():.1f} turnos
   - Balance entre jugadores: Distribuci√≥n equilibrada de victorias
   - Eventos clave: Movimientos, switches, y efectos de estado

### 3. Features Relevantes para IA:
   - M√©tricas de turnos y eventos: {len(numeric_features.columns)} features num√©ricas
   - Informaci√≥n de equipos Pokemon
   - Ratings de jugadores
   - Patrones de decisi√≥n por turno

### 4. Recomendaciones para Entrenamiento:
   - Usar secuencias de turnos como input temporal
   - Incorporar estado del campo y Pokemon activos
   - Considerar ratings como proxy de skill level
   - Balancear dataset por duraci√≥n de batalla

### 5. Pr√≥ximos Pasos:
   - Implementar feature engineering avanzado
   - Crear pipeline de preprocessing
   - Dise√±ar arquitectura de red neuronal
   - Establecer m√©tricas de evaluaci√≥n
""")

# %% [markdown]
# ## 11. Estad√≠sticas finales y archivos generados
# 
# **Importancia de la documentaci√≥n:**
# - Proporciona un inventario completo de los artefactos generados
# - Facilita la reproducibilidad del an√°lisis
# - Permite validar que todos los pasos se ejecutaron correctamente
# - Sirve como checklist para asegurar que no falta ning√∫n componente
# - Documenta el punto de partida para la siguiente fase del proyecto

# %%
print(f"\n{'='*80}")
print("EDA COMPLETADO EXITOSAMENTE")
print(f"{'='*80}")

print(f"\nArchivos generados en: {OUTPUT_DIR.resolve()}")
output_files = list(OUTPUT_DIR.glob("*"))
for file in output_files:
    print(f"  - {file.name}")

print(f"\nDatasets procesados:")
print(f"  - Batallas: {len(df_battles)} registros")
print(f"  - Pokemon: {len(df_pokemon)} registros")
print(f"  - Features: {len(df_features)} registros")

print(f"\nEl an√°lisis est√° listo para convertir a notebook y ejecutar.")
